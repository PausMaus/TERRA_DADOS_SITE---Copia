from django.core.management.base import BaseCommand
from umbrella360.FERRAMENTAS.umbrellab import Wialon
from umbrella360.FERRAMENTAS.umbrellab.Wialon import *
from umbrella360.models import Empresa, Unidade, Viagem_Base, CheckPoint, Infra√ß√µes, Veiculo, ConfiguracaoSistema, Viagem_eco
import json
import pandas as pd
import time
from termcolor import colored
from datetime import datetime
from decimal import Decimal
from dataclasses import dataclass
from tqdm import tqdm
import decimal
from django.utils import timezone
from datetime import timedelta
import pytz





deposito = rf"C:\TERRA DADOS\laboratorium\Site\Deposito"

# frotas
#+-------------------------------------------------------------+
#| Nome da Frota       | ID da Frota  |
frt_cpbr =              401914599
frt_plac =              401929585
frt_sfre =              401939414
#+-------------------------------------------------------------+


WIALON_TOKEN_UMBR = "fcc5baae18cdbea20200265b6b8a4af142DD8BF34CF94701039765308B2527031174B00A"
##################################################

class Command(BaseCommand):
    help = 'Importa dados da API Wialon'
    def handle(self, *args, **kwargs):
        ##################################################
        # Start timing
        start_time = datetime.now()
        self.stdout.write(self.style.SUCCESS(f'Iniciando comando √†s {start_time.strftime("%H:%M:%S")}'))
        ###############################################
        # PRINCIPAL #

        self.PRINCIPAL()
        ##################################################
        # TESTE #
        

        #self.TESTE_MENSAGENS(1)
        #self.TESTE_MENSAGENS_02(7)
        self.TESTE_MENSAGENS_03(3)

        ##################################################
        # ESTUDO #

        #self.ESTUDO_01()
        #self.ESTUDO_02()
        #self.ESTUDO_03()
        ##################################################
        # End timing and display results
        end_time = datetime.now()
        execution_time = end_time - start_time
        self.stdout.write(self.style.SUCCESS(f'Comando conclu√≠do √†s {end_time.strftime("%H:%M:%S")}'))
        self.stdout.write(self.style.SUCCESS(f'Tempo total de execu√ß√£o: {execution_time}'))
        #salva o tempo de execu√ß√£o como uma nova linha numerada e datada em um arquivo .txt
        with open("tempo_execucao.txt", "a") as f:
            f.write(f'{datetime.now().strftime("%Y-%m-%d %H:%M:%S")} - Tempo total de execu√ß√£o: {execution_time}\n')
        print("--------------------------------------------------")
    #######################################################################################
    

    def PRINCIPAL(self):
        """Main function to execute the command workflow."""
        
        
        # Execute main workflow
        self.Limpeza() 
        #self.atualizador()
        #self.CLTDR_UMBRELLA_02(cor1="blue", cor2="green")
        self.CLTDR_UMBRELLA_03(cor1="blue", cor2="green")
        
       


    def CLTDR_UMBRELLA_02(self, cor1, cor2, tool="CLTDR_UMBRELLA"):
        def comm(msg):
            print(colored("="*30, cor1))
            print(colored(tool, cor2))
            print(f"{msg}")
            print(colored("="*30, cor1))
        comm("Iniciando processamento global...")
        sid = Wialon.authenticate_with_wialon(WIALON_TOKEN_UMBR)
        if not sid:
                self.stdout.write(self.style.ERROR('Falha ao iniciar sess√£o Wialon.'))
                return

        Wialon.set_locale()
        #busca os relatorios
        usu√°rios = Wialon.buscadora_reports(sid)
        print(usu√°rios)


        ###__CARGO__POLO__###
        comm("Processando CARGO POLO...")
        self.CARGO_POLO(sid, recurso=401756219, template=9, flag=16777218, Objeto=frt_cpbr)
        comm("CARGO POLO processado.")
        ###__PLACIDO__###
        comm("Processando PLACIDO...")
        self.PLACIDO(sid, recurso=401756219, template=59, flag=16777218, Objeto=frt_plac)
        comm("PLACIDO processado.")
        ###__SFRESGATE__###
        comm("Processando SFRESGATE...")
        self.SFRESGATE(sid, recurso=401756219, template=59, flag=16777218, Objeto=frt_sfre)
        comm("SFRESGATE processado.")

        ###__checkpoints e infra√ß√µes__###
        processamento_df = pd.DataFrame()
        self.CLTDR_CP_01(sid, processamento_df, recurso=401755650, template=1, flag=16777218, Objeto=401946382, dias=30)
        processamento_df = pd.DataFrame()
        self.CLTDR_INFRA_01(sid, processamento_df, recurso=401872803, template=7, flag=16777218, Objeto=401929585, dias=30)
        processamento_df = pd.DataFrame()

        print("Usu√°rios encontrados:", colored(f'{len(usu√°rios)}', 'green'))
        print("Usu√°rios:", usu√°rios)
    
        Wialon.wialon_logout(sid)

    def CLTDR_UMBRELLA_03(self, cor1, cor2, tool="CLTDR_UMBRELLA"):
        def comm(msg):
            print(colored("="*30, cor1))
            print(colored(tool, cor2))
            print(f"{msg}")
            print(colored("="*30, cor1))
        comm("Iniciando processamento global...")
        sid = Wialon.authenticate_with_wialon(WIALON_TOKEN_UMBR)
        if not sid:
                self.stdout.write(self.style.ERROR('Falha ao iniciar sess√£o Wialon.'))
                return

        Wialon.set_locale()
        #busca os relatorios
        usu√°rios = Wialon.buscadora_reports(sid)
        comm(usu√°rios)

        ###__ATUALIZADOR_UNIDADES__###
        self.atualizador_04(sid, id_criador=401756218)
        self.atualizador_04(sid, id_criador=401768998)
        self.atualizador_04(sid, id_criador=401872802)
        self.atualizador_04(sid, id_criador=401824174)



        ###__CARGO__POLO__###
        comm("Processando CARGO POLO...")
        self.CARGO_POLO(sid, recurso=401756219, template=9, flag=16777218, Objeto=frt_cpbr,)
        comm("CARGO POLO processado.")

        ###__PLACIDO__###
        comm("Processando PLACIDO...")
        self.PLACIDO(sid, recurso=401756219, template=59, flag=16777218, Objeto=frt_plac)
        comm("PLACIDO processado.")

        ###__SFRESGATE__###
        comm("Processando SFRESGATE...")
        self.SFRESGATE(sid, recurso=401756219, template=59, flag=16777218, Objeto=frt_sfre)
        comm("SFRESGATE processado.")

        ###__PETITTO__###
        comm("Processando PETITTO...")
        self.PETITTO(sid, recurso=401756219, template=59, flag=16777218, Objeto=401904974)
        comm("PETITTO processado.")

        ###__checkpoints e infra√ß√µes__###
        self.CH_INFRA(sid)

        

        comm(f'{colored("Resumo:", "magenta")}\n'
            f'Usu√°rios encontrados: {colored(len(usu√°rios), "green")}\n'
            f'Usu√°rios: {usu√°rios}'
        )

        Wialon.wialon_logout(sid)

    def CH_INFRA(self, sid):
        processamento_df = pd.DataFrame()
        self.CLTDR_CP_01(sid, processamento_df, recurso=401755650, template=1, flag=16777218, Objeto=401946382, dias=30)
        processamento_df = pd.DataFrame()
        self.CLTDR_INFRA_01(sid, processamento_df, recurso=401872803, template=7, flag=16777218, Objeto=401929585, dias=30)
        processamento_df = pd.DataFrame()




    def atualizador(self,nome="atualizador_unidades"):
            def comm(msg):
                print(colored("="*30, "yellow"))
                print(colored(f"{nome}:","green"))
                print(f"{msg}")
                print(colored("="*30, "yellow"))
            #lista as empresas registradas
            contador_sessoes = 0
            empresas = Empresa.objects.all()
            for empresa in empresas:
                comm(f'Empresa: {empresa.nome}')
                # Inicia a sess√£o Wialon para cada empresa
                sid=Wialon.authenticate_with_wialon(empresa.token)
                comm(f'Sess√£o Wialon iniciada para {empresa.nome}, ID de recurso: {empresa.id_recurso}')
                if not sid:
                    self.stdout.write(self.style.ERROR('Falha ao iniciar sess√£o Wialon.'))
                    continue
                if sid:
                    contador_sessoes += 1


                unidades = Wialon.unidades_simples_03(sid,empresa)
                if not unidades:
                    self.stdout.write(self.style.ERROR('Nenhuma unidade encontrada.'))
                    return

                comm(f'Unidades encontradas: {len(unidades)}')
                #
                #+-----
                #print(f'Unidades: {colored(f"{unidades}", "green")}')
                #+-----
                #

                #coloca os dados em um dataframe
                df_unidades = pd.DataFrame(unidades)
                comm(f'Unidades encontradas: {len(df_unidades)}')
                comm(f'Unidades: {df_unidades}')
                #
                #+-----
                #df_unidades.to_excel(f'{deposito}/{empresa.nome}_unidades.xlsx', index=False)
                #comm(f'Arquivo {deposito}/{empresa.nome}_unidades.xlsx salvo.')
                #+-----
                #
                

                for unidade in df_unidades.itertuples(index=False):
                    id=unidade.unit_id
                    nome=unidade.unit_name
                    marca=unidade.brand
                    modelo=unidade.model
                    ano=unidade.year
                    cor=unidade.color
                    placa=unidade.registration_plate
                    cls = 'Ve√≠culo'
                    unidade_id = f"{empresa.nome}_{id}"

                    #
                    #+---
                    #comm(f'Nome da unidade: {nome}, Marca: {marca}, Modelo: {modelo}, Ano: {ano}, Cor: {cor}, Placa: {placa}')
                    #+---
                    #

                    # Atualiza a unidade no banco de dados
                    Veiculo.objects.update_or_create(
                        id=unidade_id,
                        defaults={
                            'nm': nome,
                            'placa': placa,
                            'marca': marca,
                            'cls': cls,
                            'empresa': empresa,
                            'cor': cor,
                            'modelo': modelo,
                            'id_wialon': id,
                        }
                    )
                    comm(f'Ve√≠culo {nome} atualizado/criado com ID {unidade_id}.')
                
                #adiciona tamb√©m os motoristas

                motoristas = Wialon.motoristas_simples2(sid)
                df_motoristas = pd.DataFrame(motoristas)
                comm(f'Motoristas encontrados: {len(df_motoristas)}')
                comm(f'Motoristas: {df_motoristas}')
                for motorista in df_motoristas.itertuples(index=False):
                    motorista_id = motorista.driver_id
                    motorista_nome = motorista.driver_name
                    cls = 'Motorista'


                    motorista_id = f"{empresa.nome}_{motorista_id}"

                    comm(f'Motorista: {motorista_nome} | ID: {motorista_id} | Classe: {cls} | Empresa: {empresa.nome}')

                    # Atualiza o motorista no banco de dados
                    Unidade.objects.update_or_create(
                        id=motorista_id,
                        defaults={
                            'nm': motorista_nome,
                            'cls': cls,
                            'empresa': empresa,
                            'id_wialon': motorista_id,
                        }
                        
                    )
            #faz logout
            Wialon.wialon_logout(sid)
            return contador_sessoes

            #-------------------------------------------------------------------------------------------------------------#

    def atualizador_02(self,sid, nome="atualizador_unidades", empresa='CPBracell', flags=8388609):
            def comm(msg):
                print(colored("="*30, "yellow"))
                print(colored(f"{nome}:","green"))
                print(f"{msg}")
                print(colored("="*30, "yellow"))


            unidades = Wialon.unidades_simples_04(sid, empresa=empresa, flags=flags)
            if not unidades:
                self.stdout.write(self.style.ERROR('Nenhuma unidade encontrada.'))
                return

            comm(f'Unidades encontradas: {len(unidades)}')
            #
            #+-----
            #print(f'Unidades: {colored(f"{unidades}", "green")}')
            #+-----
            #

            #coloca os dados em um dataframe
            df_unidades = pd.DataFrame(unidades)
            comm(f'Unidades encontradas: {len(df_unidades)}')
            comm(f'Unidades: {df_unidades}')
            #
            #+-----
            #df_unidades.to_excel(f'{deposito}/{empresa.nome}_unidades.xlsx', index=False)
            #comm(f'Arquivo {deposito}/{empresa.nome}_unidades.xlsx salvo.')
            #+-----
            #
            

            for unidade in df_unidades.itertuples(index=False):
                id=unidade.unit_id
                nome=unidade.unit_name
                marca=unidade.brand
                modelo=unidade.model
                ano=unidade.year
                cor=unidade.color
                placa=unidade.registration_plate
                cls = 'Ve√≠culo'
                unidade_id = f"{empresa}_{id}"

                #
                #+---
                #comm(f'Nome da unidade: {nome}, Marca: {marca}, Modelo: {modelo}, Ano: {ano}, Cor: {cor}, Placa: {placa}')
                #+---
                #

                # Atualiza a unidade no banco de dados
                Veiculo.objects.update_or_create(
                    id=unidade_id,
                    defaults={
                        'nm': nome,
                        'placa': placa,
                        'marca': marca,
                        'cls': cls,
                        'empresa': empresa,
                        'cor': cor,
                        'modelo': modelo,
                        'id_wialon': id,
                    }
                )
                comm(f'Ve√≠culo {nome} atualizado/criado com ID {unidade_id}.')
            
            #adiciona tamb√©m os motoristas

            motoristas = Wialon.motoristas_simples2(sid)
            df_motoristas = pd.DataFrame(motoristas)
            comm(f'Motoristas encontrados: {len(df_motoristas)}')
            comm(f'Motoristas: {df_motoristas}')
            for motorista in df_motoristas.itertuples(index=False):
                motorista_id = motorista.driver_id
                motorista_nome = motorista.driver_name
                cls = 'Motorista'


                motorista_id = f"{empresa}_{motorista_id}"

                comm(f'Motorista: {motorista_nome} | ID: {motorista_id} | Classe: {cls} | Empresa: {empresa}')

                # Atualiza o motorista no banco de dados
                Unidade.objects.update_or_create(
                    id=motorista_id,
                    defaults={
                        'nm': motorista_nome,
                        'cls': cls,
                        'empresa': empresa,
                        'id_wialon': motorista_id,
                    }
                    
                )

    def atualizador_03(self,sid,id_criador,  flags=8388613):
        

        def comm(msg):
            print(colored("="*30, "yellow"))
            print(colored(f"Atualizador de Unidades:","green"))
            print(f"{msg}")
            print(colored("="*30, "yellow"))


        unidades = Wialon.unidades_simples_05(sid,  flags=flags)
        if not unidades:
            self.stdout.write(self.style.ERROR('Nenhuma unidade encontrada.'))
            return

        comm(f'Unidades encontradas: {len(unidades)}')
        #coloca os dados em um dataframe
        df_unidades = pd.DataFrame(unidades)
        comm(f'Unidades encontradas: {len(df_unidades)}')
        comm(f'Unidades: {df_unidades}')

        for unidade in df_unidades.itertuples(index=False):
            id=unidade.unit_id
            nome=unidade.unit_name
            marca=unidade.brand
            modelo=unidade.model
            ano=unidade.year
            cor=unidade.color
            placa=unidade.registration_plate
            cls = 'Ve√≠culo'
            id_criador_unidade = unidade.id_criador
            if id_criador_unidade == id_criador:
                print(f'A unidade {nome} pertence √† empresa CARGO POLO.')
                empresa = Empresa.objects.get(id_criador=id_criador)
                print(colored(f'Empresa encontrada: {empresa.nome}, ID Criador: {empresa.id_criador}', 'red'))
                empresa_nome = empresa.nome
                unidade_id = f"{empresa.nome}_{id}"


                comm(f'Nome da unidade: {nome}, Marca: {marca}, Modelo: {modelo}, Ano: {ano}, Cor: {cor}, Placa: {placa}')
                #+---
                # Atualiza a unidade no banco de dados
                Veiculo.objects.update_or_create(
                    id=unidade_id,
                    defaults={
                        'nm': nome,
                        'placa': placa,
                        'marca': marca,
                        'cls': cls,
                        'empresa': empresa,
                        'cor': cor,
                        'modelo': modelo,
                        'id_wialon': id,
                    }
                )
                comm(f'Ve√≠culo {nome} atualizado/criado com ID {unidade_id}.')
            else:
                comm(f'A unidade {nome} n√£o pertence √† empresa CARGO POLO. ID Criador: {id_criador_unidade}')

            #adiciona tamb√©m os motoristas

            motoristas = Wialon.motoristas_simples_03(sid, flags=5)
            df_motoristas = pd.DataFrame(motoristas)
            comm(f'Motoristas encontrados: {len(df_motoristas)}')
            comm(f'Motoristas: {df_motoristas}')


            for motorista in df_motoristas.itertuples(index=False):
                motorista_id = motorista.driver_id
                motorista_nome = motorista.driver_name
                cls = 'Motorista'
                id_criador_unidade = unidade.id_criador
                if id_criador_unidade == id_criador:
                    print(f'A unidade {nome} pertence √† empresa CARGO POLO.')
                    empresa = Empresa.objects.get(id_criador=id_criador)
                    print(colored(f'Empresa encontrada: {empresa.nome}, ID Criador: {empresa.id_criador}', 'red'))
                    empresa_nome = empresa.nome
                    unidade_id = f"{empresa.nome}_{id}"


                    motorista_id = f"{empresa}_{motorista_id}"

                    comm(f'Motorista: {motorista_nome} | ID: {motorista_id} | Classe: {cls} | Empresa: {empresa}')

                    # Atualiza o motorista no banco de dados
                    Unidade.objects.update_or_create(
                        id=motorista_id,
                        defaults={
                            'nm': motorista_nome,
                            'cls': cls,
                            'empresa': empresa,
                            'id_wialon': motorista_id,
                        }
                        
                    )
                else:
                    comm(f'A unidade {nome} n√£o pertence √† empresa CARGO POLO. ID Criador: {id_criador_unidade}')



    def atualizador_04(self,sid,id_criador,  flags=8388613):
        

        def comm(msg):
            print(colored("="*30, "yellow"))
            print(colored(f"Atualizador de Unidades V4:","green"))
            print(f"{msg}")
            print(colored("="*30, "yellow"))
                
                
        empresa = Empresa.objects.get(id_criador=id_criador)

        vcl_processados = 0
        vcl_excludentes = 0
        mtr_processados = 0
        mtr_excludentes = 0


        unidades = Wialon.unidades_simples_05(sid,  flags=flags)
        if not unidades:
            self.stdout.write(self.style.ERROR('Nenhuma unidade encontrada.'))
            return

        #coloca os dados em um dataframe
        df_unidades = pd.DataFrame(unidades)
        #+---
        #comm(f'Unidades encontradas: {len(df_unidades)}')
        #comm(f'Unidades: {df_unidades}')
        #+---

        for unidade in df_unidades.itertuples(index=False):
            id=unidade.unit_id
            nome=unidade.unit_name
            marca=unidade.brand
            modelo=unidade.model
            ano=unidade.year
            cor=unidade.color
            placa=unidade.registration_plate
            cls = 'Ve√≠culo'
            id_criador_unidade = unidade.id_criador
            if id_criador_unidade == id_criador:

                #+---
                #print(f'A unidade {nome} pertence √† empresa {empresa.nome}')
                #print(colored(f'Empresa encontrada: {empresa.nome}, ID Criador: {empresa.id_criador}', 'red'))
                #+---
                #+---   
                #comm(f'Nome da unidade: {nome}, Marca: {marca}, Modelo: {modelo}, Ano: {ano}, Cor: {cor}, Placa: {placa}')
                #+---
                
                # Atualiza a unidade no banco de dados
                Veiculo.objects.update_or_create(
                    id=f"{empresa.nome}_{id}",
                    defaults={
                        'nm': nome,
                        'placa': placa,
                        'marca': marca,
                        'cls': cls,
                        'empresa': empresa,
                        'cor': cor,
                        'modelo': modelo,
                        'id_wialon': id,
                    }
                )
                vcl_processados += 1
                #+---
                #comm(f'Ve√≠culo {nome} atualizado/criado com ID {unidade_id}.')
                #+---

            else:
                vcl_excludentes += 1
                #+---
                #comm(f'A unidade {nome} n√£o pertence √† empresa CARGO POLO. ID Criador: {id_criador_unidade}')
                #+---

        #adiciona tamb√©m os motoristas

        motoristas = Wialon.motoristas_simples_03(sid, flags=261)
        df_motoristas = pd.DataFrame(motoristas)

        #+---
        #comm(f'Motoristas encontrados: {len(df_motoristas)}')
        #comm(f'Motoristas: {df_motoristas}')
        #+---

        

        for motorista in df_motoristas.itertuples(index=False):
            if motorista.creator_id == id_criador:
                #+---
                #comm(f'O motorista {motorista.driver_name} pertence √† empresa CARGO POLO.')
                #+---
                Unidade.objects.update_or_create(
                    id=f"{empresa.nome}_{motorista.driver_id}",
                    defaults={
                        'nm': motorista.driver_name,
                        'cls': 'Motorista',
                        'empresa': empresa,
                        'id_wialon': f"{motorista.driver_name}_{motorista.driver_id}",
                    }
                )
                mtr_processados += 1
                #+---
                #comm(f'Motorista {motorista.driver_name} atualizado/criado com ID {empresa.nome}_{motorista.driver_id}.')
                #+---
                

            else:
                mtr_excludentes += 1
                #+---
                #comm(f'O motorista {motorista.driver_name} n√£o pertence √† empresa CARGO POLO. ID Criador: {motorista.creator_id}')
                #+---
                
            

        comm(f'{colored("Resumo:", "magenta")}\n'
            f'Ve√≠culos processados: {colored(vcl_processados, "green")}\n'
            f'Ve√≠culos exclu√≠dos: {colored(vcl_excludentes, "red")}\n'
            f'Motoristas processados: {colored(mtr_processados, "green")}\n'
            f'Motoristas exclu√≠dos: {colored(mtr_excludentes, "red")}\n'
            f'Motoristas encontrados: {len(df_motoristas)}\n'
            f'{df_motoristas.head()}'
        )


    def atualizador_teste(self, sid, nome="atualizador_unidades_04", flags=8388613):
        def comm(msg):
            print(colored("="*30, "yellow"))
            print(colored(f"{nome}:", "green"))
            print(f"{msg}")
            print(colored("="*30, "yellow"))

        unidades = Wialon.unidades_simples_05(sid, flags=flags)
        if not unidades:
            self.stdout.write(self.style.ERROR('Nenhuma unidade encontrada.'))
            return

        comm(f'Unidades encontradas: {len(unidades)}')
        
        # Coloca os dados em um dataframe
        df_unidades = pd.DataFrame(unidades)
        comm(f'Unidades encontradas: {len(df_unidades)}')
        
        # Busca todas as empresas cadastradas com seus id_criador
        empresas_dict = {}
        empresas = Empresa.objects.all()
        
        for empresa in empresas:
            if empresa.id_criador:
                empresas_dict[empresa.id_criador] = empresa
                comm(f'Empresa cadastrada: {empresa.nome} - ID Criador: {empresa.id_criador}')

        if not empresas_dict:
            comm("‚ö†Ô∏è Nenhuma empresa com id_criador encontrada. Verifique o cadastro das empresas.")
            return

        # Contadores para estat√≠sticas
        unidades_processadas = 0
        unidades_vinculadas = 0
        unidades_sem_empresa = 0

        for unidade in df_unidades.itertuples(index=False):
            unidades_processadas += 1
            
            # Extrai dados da unidade
            unit_id = unidade.unit_id
            unit_name = unidade.unit_name
            id_criador_unidade = unidade.id_criador
            
            # Extrai campos do profile se existirem
            brand = getattr(unidade, 'brand', '')
            model = getattr(unidade, 'model', '')
            year = getattr(unidade, 'year', '')
            color = getattr(unidade, 'color', '')
            registration_plate = getattr(unidade, 'registration_plate', '')
            
            # Verifica se a unidade pertence a alguma empresa cadastrada
            empresa_vinculada = empresas_dict.get(id_criador_unidade)
            
            if empresa_vinculada:
                unidades_vinculadas += 1
                cls = 'Ve√≠culo'
                
                # Cria o ID √∫nico da unidade
                unidade_id = f"{empresa_vinculada.nome}_{unit_id}"
                
                comm(f'‚úÖ Unidade {unit_name} pertence √† empresa {empresa_vinculada.nome}')
                comm(f'   Marca: {brand}, Modelo: {model}, Ano: {year}, Cor: {color}, Placa: {registration_plate}')
                
                # Atualiza/cria a unidade no banco de dados
                try:
                    veiculo, created = Veiculo.objects.update_or_create(
                        id=unidade_id,
                        defaults={
                            'nm': unit_name,
                            'placa': registration_plate,
                            'marca': brand,
                            'cls': cls,
                            'empresa': empresa_vinculada,
                            'cor': color,
                            'modelo': model,
                            'ano': int(year) if year and str(year).isdigit() else None,
                            'id_wialon': unit_id,
                            'id_criador': id_criador_unidade,
                        }
                    )
                    
                    action = "criado" if created else "atualizado"
                    comm(f'‚úÖ Ve√≠culo {unit_name} {action} com ID {unidade_id}')
                    
                except Exception as e:
                    comm(f'‚ùå Erro ao processar ve√≠culo {unit_name}: {e}')
                    
            else:
                unidades_sem_empresa += 1
                comm(f'‚ö†Ô∏è Unidade {unit_name} (ID Criador: {id_criador_unidade}) n√£o pertence a nenhuma empresa cadastrada')

        # Processamento dos motoristas (se necess√°rio)
        comm("Processando motoristas...")
        motoristas = Wialon.motoristas_simples2(sid)
        df_motoristas = pd.DataFrame(motoristas)
        
        motoristas_processados = 0
        motoristas_vinculados = 0
        
        for motorista in df_motoristas.itertuples(index=False):
            motoristas_processados += 1
            
            motorista_id_wialon = motorista.driver_id
            motorista_nome = motorista.driver_name
            resource_id = motorista.resource_id
            
            # Tenta identificar a empresa do motorista pelo resource_id
            # (assumindo que o resource corresponde ao id_criador da empresa)
            empresa_motorista = empresas_dict.get(str(resource_id))
            
            if empresa_motorista:
                motoristas_vinculados += 1
                cls = 'Motorista'
                motorista_id = f"{empresa_motorista.nome}_{motorista_id_wialon}"

                comm(f'‚úÖ Motorista {motorista_nome} pertence √† empresa {empresa_motorista.nome}')

                try:
                    unidade, created = Unidade.objects.update_or_create(
                        id=motorista_id,
                        defaults={
                            'nm': motorista_nome,
                            'cls': cls,
                            'empresa': empresa_motorista,
                            'id_wialon': motorista_id_wialon,
                        }
                    )
                    
                    action = "criado" if created else "atualizado"
                    comm(f'‚úÖ Motorista {motorista_nome} {action} com ID {motorista_id}')
                    
                except Exception as e:
                    comm(f'‚ùå Erro ao processar motorista {motorista_nome}: {e}')
            else:
                comm(f'‚ö†Ô∏è Motorista {motorista_nome} (Resource ID: {resource_id}) n√£o pertence a nenhuma empresa cadastrada')

        # Relat√≥rio final
        comm("="*50)
        comm("RELAT√ìRIO FINAL:")
        comm(f"üìä Unidades processadas: {unidades_processadas}")
        comm(f"‚úÖ Unidades vinculadas: {unidades_vinculadas}")
        comm(f"‚ö†Ô∏è Unidades sem empresa: {unidades_sem_empresa}")
        comm(f"üìä Motoristas processados: {motoristas_processados}")
        comm(f"‚úÖ Motoristas vinculados: {motoristas_vinculados}")
        comm("="*50)

        # Salva log detalhado se necess√°rio
        if unidades_sem_empresa > 0:
            comm(f"‚ö†Ô∏è {unidades_sem_empresa} unidades n√£o puderam ser vinculadas.")
            comm("Verifique se os id_criador das empresas est√£o corretos no banco de dados.")

    ############################################################################################

    def CARGO_POLO(self, sid,  recurso, template, flag, Objeto,  empresa='CPBRACELL'):
        #self.teste(sid, recurso, template, flag, Objeto)
        #+---
        #self.atualizador_02(sid, nome="atualizador_unidades", empresa=empresa.nome, flags=8388609)
        #self.atualizador_03(sid, id_criador=id_criador, flags=8388613)
        #+---

        #
        self.prsr_vcl(sid, recurso, template, flag, Objeto)
        #
        self.prsr_mtr(sid, flag)
        #


    def teste(self, sid, recurso, template, flag, Objeto):
        processamento_df = pd.DataFrame()
        self.CLTDR_05(sid, processamento_df, recurso=recurso, template=template, flag=flag, Objeto=Objeto, dias=1, periodo="Ontem")
        self.CLTDR_05(sid, processamento_df, recurso=recurso, template=template, flag=flag, Objeto=Objeto, dias=2, periodo="Anteontem")
        self.CLTDR_05(sid, processamento_df, recurso=recurso, template=template, flag=flag, Objeto=Objeto, dias=3, periodo="Dois Dias atr√°s")

    def prsr_mtr(self, sid, flag):
        processamento_df = pd.DataFrame()
        self.CLTDR_MOT_01(sid, processamento_df, Objeto=401756219, flag=flag, dias=1, periodo="Ontem")
        self.CLTDR_MOT_01(sid, processamento_df, Objeto=401756219, flag=flag, dias=7, periodo="√öltimos 7 dias")
        self.CLTDR_MOT_01(sid, processamento_df, Objeto=401756219, flag=flag, dias=30, periodo="√öltimos 30 dias")

    def prsr_vcl(self, sid, recurso, template, flag, Objeto):
        processamento_df = pd.DataFrame()
        self.CLTDR_04(sid, processamento_df, recurso=recurso, template=template, flag=flag, Objeto=Objeto, dias=1, periodo="Ontem")
        self.CLTDR_04(sid, processamento_df, recurso=recurso, template=template, flag=flag, Objeto=Objeto, dias=7, periodo="√öltimos 7 dias")
        self.CLTDR_04(sid, processamento_df, recurso=recurso, template=template, flag=flag, Objeto=Objeto, dias=30, periodo="√öltimos 30 dias")

### ############################################################################################

    def PLACIDO(self, sid, recurso, template, flag, Objeto):
        processamento_df = pd.DataFrame()
        self.CLTDR_03(sid, processamento_df, recurso=recurso, template=template, flag=flag, Objeto=Objeto, dias=1, periodo="Ontem")
        self.CLTDR_03(sid, processamento_df, recurso=recurso, template=template, flag=flag, Objeto=Objeto, dias=7, periodo="√öltimos 7 dias")
        self.CLTDR_03(sid, processamento_df, recurso=recurso, template=template, flag=flag, Objeto=Objeto, dias=30, periodo="√öltimos 30 dias")
        #
        processamento_df = pd.DataFrame()
        self.CLTDR_MOT_02(sid, processamento_df, recurso=401768999, template=48, Objeto=401768999, flag=flag, dias=1, periodo="Ontem")
        self.CLTDR_MOT_02(sid, processamento_df, recurso=401768999, template=48, Objeto=401768999, flag=flag, dias=7, periodo="√öltimos 7 dias")
        self.CLTDR_MOT_02(sid, processamento_df, recurso=401768999, template=48, Objeto=401768999, flag=flag, dias=30, periodo="√öltimos 30 dias")

### ############################################################################################

    def SFRESGATE(self, sid, recurso, template, flag, Objeto):
        processamento_df = pd.DataFrame()
        self.CLTDR_03(sid, processamento_df, recurso=recurso, template=template, flag=flag, Objeto=Objeto, dias=1, periodo="Ontem")
        self.CLTDR_03(sid, processamento_df, recurso=recurso, template=template, flag=flag, Objeto=Objeto, dias=7, periodo="√öltimos 7 dias")
        self.CLTDR_03(sid, processamento_df, recurso=recurso, template=template, flag=flag, Objeto=Objeto, dias=30, periodo="√öltimos 30 dias")
        #
        processamento_df = pd.DataFrame()
        self.CLTDR_MOT_02(sid, processamento_df, recurso=401872803, template=48, Objeto=401872803, flag=flag, dias=1, periodo="Ontem")
        self.CLTDR_MOT_02(sid, processamento_df, recurso=401872803, template=48, Objeto=401872803, flag=flag, dias=7, periodo="√öltimos 7 dias")
        self.CLTDR_MOT_02(sid, processamento_df, recurso=401872803, template=48, Objeto=401872803, flag=flag, dias=30, periodo="√öltimos 30 dias")



### ############################################################################################

    def PETITTO(self, sid,  recurso, template, flag, Objeto):

        processamento_df = pd.DataFrame()
        self.CLTDR_03(sid, processamento_df, recurso=recurso, template=template, flag=flag, Objeto=Objeto, dias=1, periodo="Ontem")
        self.CLTDR_03(sid, processamento_df, recurso=recurso, template=template, flag=flag, Objeto=Objeto, dias=7, periodo="√öltimos 7 dias")
        self.CLTDR_03(sid, processamento_df, recurso=recurso, template=template, flag=flag, Objeto=Objeto, dias=30, periodo="√öltimos 30 dias")
        #
        processamento_df = pd.DataFrame()
        self.CLTDR_MOT_02(sid, processamento_df, recurso=401756219, template=48, Objeto=401824175, flag=flag, dias=1, periodo="Ontem")
        self.CLTDR_MOT_02(sid, processamento_df, recurso=401756219, template=48, Objeto=401824175, flag=flag, dias=7, periodo="√öltimos 7 dias")
        self.CLTDR_MOT_02(sid, processamento_df, recurso=401756219, template=48, Objeto=401824175, flag=flag, dias=30, periodo="√öltimos 30 dias")


#### ############################################################################################
   


    def Limpeza(self):
        # Limpa os dados antigos
        Unidade.objects.all().delete()
        Infra√ß√µes.objects.all().delete()
        CheckPoint.objects.all().delete()
        Viagem_Base.objects.all().delete()
        Viagem_eco.objects.all().delete()


    #+---
    def atualizar_01(self):
        #lista as empresas registradas
        empresas = Empresa.objects.all()
        for empresa in empresas:
            print(f'Empresa: {empresa.nome}')
            # Inicia a sess√£o Wialon para cada empresa
            sid=Wialon.authenticate_with_wialon(empresa.token)
            print(f'Sess√£o Wialon iniciada para {empresa.nome}, ID de recurso: {empresa.id_recurso}')
            if not sid:
                self.stdout.write(self.style.ERROR('Falha ao iniciar sess√£o Wialon.'))
                continue

            Wialon.set_locale()

            #busca relat√≥rios
            relat√≥rios = Wialon.buscadora_reports(sid)
            print(f'Relat√≥rios encontrados: {colored(len(relat√≥rios), "green")}')
            relat√≥rios = json.dumps(relat√≥rios, indent=4)
            print(f'Relat√≥rios: {relat√≥rios}')
            #-------
            #salva os relatorios em .txt no deposito
            #with open(f'{deposito}/{empresa.nome}_relatorios.txt', 'w') as f:
            #    f.write(json.dumps(relat√≥rios, indent=4))
            #-------
            unidades = Wialon.unidades_simples(sid)
            print(f'Unidades encontradas: {colored(len(unidades), "green")}')
            #-------
            #for unidade in unidades:
            #    print(f'Unidade: {unidade}')
            #-------
            df_unidades = pd.DataFrame(unidades)
            print(f'Unidades: {df_unidades}')


            motoristas = Wialon.motoristas_simples2(sid)
            df_motoristas = pd.DataFrame(motoristas)
            print(f'Motoristas encontrados:' , colored(f'{len(df_motoristas)}', 'green'))
            print(f'Motoristas: {df_motoristas}')
            
            # Atualiza as unidades
            self.atualiza_unidades(sid, empresa.nome)
            ###

            #faz logout
            Wialon.wialon_logout(sid)
    #+---


    def processamento_global(self):
        print("Iniciando processamento global...")
        sid = Wialon.authenticate_with_wialon(WIALON_TOKEN_UMBR)
        if not sid:
                self.stdout.write(self.style.ERROR('Falha ao iniciar sess√£o Wialon.'))
                return

        Wialon.set_locale()
        processamento_df = pd.DataFrame()

        ###__UNIDADES__TODAS__###
        print("Processando Unidades...")
        self.processador_unidades_totais(sid, processamento_df)
        print("Unidades processadas.")
        ###

        processamento_df = pd.DataFrame()

        ###__CARGO__POLO__###
        #motoristas 
        self.CLTDR_MOT_01(sid, processamento_df, Objeto=401756219, flag=16777218, dias=1, periodo="Ontem")
        self.CLTDR_MOT_01(sid, processamento_df, Objeto=401756219, flag=16777220, dias=1, periodo="√öltimos 7 dias")
        self.CLTDR_MOT_01(sid, processamento_df, Objeto=401756219, flag=16777224, dias=1, periodo="√öltimos 30 dias")

        processamento_df = pd.DataFrame()

        ###__PLACIDO__###
        #Motoristas 
        self.CLTDR_MOT_02(sid, processamento_df, recurso=401768999, template=48, Objeto=401768999, flag=16777218, dias=1, periodo="Ontem")
        self.CLTDR_MOT_02(sid, processamento_df, recurso=401768999, template=48, Objeto=401768999, flag=16777220, dias=1, periodo="√öltimos 7 dias")
        self.CLTDR_MOT_02(sid, processamento_df, recurso=401768999, template=48, Objeto=401768999, flag=16777224, dias=1, periodo="√öltimos 30 dias")

        processamento_df = pd.DataFrame()


        ###__SFRESGATE__###
        #motoristas 
        self.CLTDR_MOT_02(sid, processamento_df, recurso=401872803, template=48, Objeto=401872803, flag=16777218, dias=1, periodo="Ontem")
        self.CLTDR_MOT_02(sid, processamento_df, recurso=401872803, template=48, Objeto=401872803, flag=16777220, dias=1, periodo="√öltimos 7 dias")
        self.CLTDR_MOT_02(sid, processamento_df, recurso=401872803, template=48, Objeto=401872803, flag=16777224, dias=1, periodo="√öltimos 30 dias")
        processamento_df = pd.DataFrame()

        #checkpoints e infra√ß√µes
        self.CLTDR_CP_01(sid, processamento_df, recurso=401755650, template=1, flag=16777218, Objeto=401946382, dias=30)
        processamento_df = pd.DataFrame()   

        self.CLTDR_INFRA_01(sid, processamento_df, recurso=401872803, template=7, flag=16777218, Objeto=401929585, dias=30)
        processamento_df = pd.DataFrame()

    def processador_unidades_totais(self, sid, processamento_df):
        print("Processando Unidades...")
        # Coleta de dados para o relat√≥rio
        
        self.CLTDR_01(sid, processamento_df, flag=16777218, dias=1, periodo="Ontem")
        self.CLTDR_01(sid, processamento_df, flag=16777218, dias=7, periodo="√öltimos 7 dias")
        self.CLTDR_01(sid, processamento_df, flag=16777218, dias=30, periodo="√öltimos 30 dias")
        #
        #self.CLTDR_02(sid, processamento_df, flag=16777224, Objeto=401939410, dias=1, periodo="√öltimos 30 dias")
        #self.CLTDR_02(sid, processamento_df, flag=16777224, Objeto=401939414, dias=1, periodo="√öltimos 30 dias")
        #self.CLTDR_02(sid, processamento_df, flag=16777224, Objeto=401929585, dias=1, periodo="√öltimos 30 dias")
        #
        processamento_df = pd.DataFrame()

        
#######################################################################################
    def CLTDR_01(self, sid, processamento_df, flag, dias, periodo):
        print(colored("="*30,'yellow'))
        print(colored(f'Coletando dados de unidades para ({periodo})','cyan'))

        relatorio = Wialon.Colheitadeira_JSON_03(sid, flag=flag, reportResourceId=401756219, reportTemplateId=59, reportObjectId=401946382, reportObjectSecId=0, unit_id="CLTDR_01",  tempo_dias=dias, periodo=periodo)

        if relatorio is not None:
            #---
            #print(f'Relat√≥rio coletado: {relatorio}')
            #----
            processamento_df = pd.concat([processamento_df, relatorio], ignore_index=True)

            print(processamento_df)
            self.update_or_create_trip(processamento_df)
            Wialon.clean_up_result(sid)

    def CLTDR_02(self, sid, processamento_df, flag, Objeto, dias, periodo):
        print(f'Coletando dados de relat√≥rio para ({periodo})')

        relatorio = Wialon.Colheitadeira_JSON_03(sid, flag=flag, reportResourceId=401756219, reportTemplateId=59, reportObjectId=Objeto, reportObjectSecId=0, unit_id="teste",  tempo_dias=dias, periodo=periodo)

        if relatorio is not None:
            #----
            #print(f'Relat√≥rio coletado: {relatorio}')
            #----
            processamento_df = pd.concat([processamento_df, relatorio], ignore_index=True)

            print(processamento_df)
            self.update_or_create_trip(processamento_df)
            Wialon.clean_up_result(sid)

    def CLTDR_03(self, sid, processamento_df, recurso, template, flag, Objeto, dias, periodo):
        #Adicionado resource, template
        print(f'Coletando dados de relat√≥rio para ({periodo})')

        relatorio = Wialon.Colheitadeira_JSON_03(sid, flag=flag, reportResourceId=recurso, reportTemplateId=template, reportObjectId=Objeto, reportObjectSecId=0, unit_id="teste",  tempo_dias=dias, periodo=periodo)

        if relatorio is not None:
            #----
            #print(f'Relat√≥rio coletado: {relatorio}')
            #----
            processamento_df = pd.concat([processamento_df, relatorio], ignore_index=True)

            print(processamento_df)
            self.update_or_create_trip(processamento_df)
            Wialon.clean_up_result(sid)


    def CLTDR_04(self, sid, processamento_df, recurso, template, flag, Objeto, dias, periodo):
        #Modificado de update or create trip para viagem
        print(f'Coletando dados de relat√≥rio para ({periodo})')

        relatorio = Wialon.Colheitadeira_JSON_03(sid, flag=flag, reportResourceId=recurso, reportTemplateId=template, reportObjectId=Objeto, reportObjectSecId=0, unit_id="teste",  tempo_dias=dias, periodo=periodo)

        if relatorio is not None:
            #----
            #print(f'Relat√≥rio coletado: {relatorio}')
            #----
            processamento_df = pd.concat([processamento_df, relatorio], ignore_index=True)

            print(processamento_df)

            self.viagem(processamento_df)
            Wialon.clean_up_result(sid)

    def CLTDR_05(self, sid, processamento_df, recurso, template, flag, Objeto,  periodo, interval_from, interval_to):
        #Modificado de update or create trip para viagem
        print(f'Coletando dados de relat√≥rio para ({periodo})')

        relatorio = Wialon.Colheitadeira_JSON_04(sid, flag=flag, reportResourceId=recurso, reportTemplateId=template, reportObjectId=Objeto, reportObjectSecId=0, unit_id="teste", interval_from=interval_from, interval_to=interval_to, periodo=periodo)

        if relatorio is not None:
            #----
            #print(f'Relat√≥rio coletado: {relatorio}')
            #----
            processamento_df = pd.concat([processamento_df, relatorio], ignore_index=True)

            print(processamento_df)

            #self.viagem(processamento_df)
            Wialon.clean_up_result(sid)


    def CLTDR_TESTE(self, sid, processamento_df, recurso, template, flag, Objeto, dias, periodo):
        print(f'Coletando dados de relat√≥rio para ({periodo})')

        relatorio = Wialon.Colheitadeira_JSON_03(sid, flag=flag, reportResourceId=recurso, reportTemplateId=template, reportObjectId=Objeto, reportObjectSecId=0, unit_id="teste",  tempo_dias=dias, periodo=periodo)

        if relatorio is not None:
            #----
            #print(f'Relat√≥rio coletado: {relatorio}')
            #----
            processamento_df = pd.concat([processamento_df, relatorio], ignore_index=True)

            print(processamento_df)
            # salva em xlsx no deposito
            processamento_df.to_excel(f'{deposito}/relatorio_[UMBR]TESTE.xlsx', index=False)

            Wialon.clean_up_result(sid)

    def CLTDR_CP_01(self, sid, processamento_df, recurso, template, flag, Objeto, dias):
        #Adicionado resource, template
        print(f'Coletando dados de relat√≥rio [Cercas]')

        relatorio = Wialon.Colheitadeira_JSON_CP_01(sid, flag=flag, reportResourceId=recurso, reportTemplateId=template, reportObjectId=Objeto, reportObjectSecId=0, unit_id="teste",  tempo_dias=dias)

        if relatorio is not None:
            #----
            #print(f'Relat√≥rio coletado: {relatorio}')
            #----
            processamento_df = pd.concat([processamento_df, relatorio], ignore_index=True)

            print(processamento_df)
            #processamento_df.to_excel(f'{deposito}/relatorio_[UMBR]CERCAS.xlsx', index=False)
            self.update_or_create_checkpoint(processamento_df)
            Wialon.clean_up_result(sid)

    def CLTDR_MOT_01(self, sid, processamento_df, Objeto, flag, dias, periodo):
        print(f'Coletando dados de relat√≥rio para ({periodo})')

        relatorio = Wialon.Colheitadeira_JSON_03(sid, flag, reportResourceId=401756219, reportTemplateId=58, reportObjectId=Objeto, reportObjectSecId=2, unit_id="teste",  tempo_dias=dias, periodo=periodo)

        if relatorio is not None:
            #----
            #print(f'Relat√≥rio coletado: {relatorio}')
            #---
            processamento_df = pd.concat([processamento_df, relatorio], ignore_index=True)

            print(processamento_df)
            self.update_or_create_trip(processamento_df)
            Wialon.clean_up_result(sid)
    
    def CLTDR_MOT_02(self, sid, processamento_df, recurso, template, Objeto, flag, dias, periodo):
        #adicionado recurso e template
        print(f'Coletando dados de relat√≥rio para ({periodo})')

        relatorio = Wialon.Colheitadeira_JSON_03(sid, flag, reportResourceId=recurso, reportTemplateId=template, reportObjectId=Objeto, reportObjectSecId=1, unit_id="teste",  tempo_dias=dias, periodo=periodo)

        if relatorio is not None:
            #-----
            #print(f'Relat√≥rio coletado: {relatorio}')
            #----
            processamento_df = pd.concat([processamento_df, relatorio], ignore_index=True)

            print(processamento_df)
            self.update_or_create_trip(processamento_df)
            Wialon.clean_up_result(sid)

    def CLTDR_INFRA_01(self, sid, processamento_df, recurso, template, flag, Objeto, dias):
        #Adicionado resource, template
        print(f'Coletando dados de relat√≥rio [INFRA√á√ïES]')

        relatorio = Wialon.Colheitadeira_JSON_INFRA_02(sid, flag=flag, reportResourceId=recurso, reportTemplateId=template, reportObjectId=Objeto, reportObjectSecId=0, unit_id="teste",  tempo_dias=dias)

        if relatorio is not None:
            #----
            #print(f'Relat√≥rio coletado: {relatorio}')
            #----
            processamento_df = pd.concat([processamento_df, relatorio], ignore_index=True)

            print(processamento_df)
            #-----
            #processamento_df.to_excel(f'{deposito}/relatorio_[UMBR]INFRA.xlsx', index=False)
            #-----
            self.update_or_create_infra√ß√£o(processamento_df)
            Wialon.clean_up_result(sid)




    def processamento_teste(self, empresa):
        if empresa.nome == 'CPBRACELL':
        #processa as unidades
            processamento_df = pd.DataFrame()
            self.CLTDR_02(sid, processamento_df, flag=16777218, Objeto=401756235, dias=1, periodo="Ontem")
            self.CLTDR_02(sid, processamento_df, flag=16777220, Objeto=401756235, dias=1, periodo="√öltimos 7 dias")
            self.CLTDR_02(sid, processamento_df, flag=16777224, Objeto=401756235, dias=1, periodo="√öltimos 30 dias")

        #processa os motoristas
            processamento_df = pd.DataFrame()
            self.CLTDR_MOT_01(sid, processamento_df, Objeto=401756219, flag=16777218, dias=1, periodo="Ontem")
            self.CLTDR_MOT_01(sid, processamento_df, Objeto=401756219, flag=16777220, dias=1, periodo="√öltimos 7 dias")
            self.CLTDR_MOT_01(sid, processamento_df, Objeto=401756219, flag=16777224, dias=1, periodo="√öltimos 30 dias")

        elif empresa.nome == 'PLACIDO':
            #processa as unidades
            self.CLTDR_03(sid, processamento_df, recurso=401756235, template=59, flag=16777218, Objeto=401756235, dias=1, periodo="Ontem")
            self.CLTDR_03(sid, processamento_df, recurso=401756235, template=59, flag=16777220, Objeto=401756235, dias=1, periodo="√öltimos 7 dias")
            self.CLTDR_03(sid, processamento_df, recurso=401756235, template=59, flag=16777224, Objeto=401756235, dias=1, periodo="√öltimos 30 dias")
            

        elif empresa.nome == 'S√£o Francisco Resgate':
            #processa as unidades
            processamento_df = pd.DataFrame()
            self.CLTDR_03(sid, processamento_df, recurso=401756235, template=59, flag=16777218, Objeto=401756235, dias=1, periodo="Ontem")
            self.CLTDR_03(sid, processamento_df, recurso=401756235, template=59, flag=16777220, Objeto=401756235, dias=1, periodo="√öltimos 7 dias")
            self.CLTDR_03(sid, processamento_df, recurso=401756235, template=59, flag=16777224, Objeto=401756235, dias=1, periodo="√öltimos 30 dias")




########################################################################################
###+---

    def principal(self, token, empresa_nome):
        self.stdout.write(self.style.SUCCESS(f'Iniciando importa√ß√£o de dados para a empresa: {empresa_nome}'))


        # Inicia a sess√£o Wialon
        self.stdout.write(self.style.SUCCESS(f'Iniciando sess√£o Wialon para {empresa_nome}...'))

        sid = Wialon.authenticate_with_wialon(token)
        if not sid:
                self.stdout.write(self.style.ERROR('Falha ao iniciar sess√£o Wialon.'))
                return

        self.atualiza_unidades(sid, empresa_nome)

        #busca os relatorios
        print(Wialon.buscadora_reports(sid))

        if empresa_nome == 'CPBRACELL':
            self.process_units_CP(sid)
            #self.process_motoristas_CP_2(sid)

        if empresa_nome == 'PLACIDO':
            self.process_units_PLAC(sid)

        elif empresa_nome == 'S√£o Francisco Resgate':
            self.process_units_SF(sid)

        # Encerra a sess√£o Wialon
        Wialon.wialon_logout(sid)

        self.stdout.write(self.style.SUCCESS(f'Sess√£o Wialon encerrada para {empresa_nome}.'))

        ###+---

########################################################################################


        #######################################################################################

    def localizzare(self, token):
        sid = Wialon.authenticate_with_wialon(token)
        if not sid:
                self.stdout.write(self.style.ERROR('Falha ao iniciar sess√£o Wialon.'))
                return

        #busca os relatorios
        relat√≥rios = Wialon.buscadora_reports(sid)
        #salva os relatorios em .txt no deposito
        with open(f'{deposito}/localizzare_relatorios.txt', 'w') as f:
            f.write(json.dumps(relat√≥rios, indent=4))

        unidades = unidades_simples(sid)
        if not unidades:
            self.stdout.write(self.style.ERROR('Nenhuma unidade encontrada.'))
            return
        
        #coloca os dados em um dataframe
        df_unidades = pd.DataFrame(unidades)
        print(f'Unidades encontradas:' , colored(f'{len(df_unidades)}', 'green'))
        print(f'Unidades: {df_unidades}')
        #salva as unidades em um excel
        df_unidades.to_excel(f'{deposito}/localizzare_unidades.xlsx', index=False)
        #
        motoristas = Wialon.motoristas_simples2(sid)
        df_motoristas = pd.DataFrame(motoristas)
        print(f'Motoristas encontrados:' , colored(f'{len(df_motoristas)}', 'green'))
        print(f'Motoristas: {df_motoristas}')
        df_motoristas.to_excel(f'{deposito}/localizzare_motoristas.xlsx', index=False)

        #####

        unidades_db = Unidade.objects.all()
        unidades_db_ids = [unidade.id for unidade in unidades_db]
        if unidades_db_ids:
            unidades_db = unidades_db.filter(cls__icontains='Ve√≠culo')  # Filtra por classe que cont√©m "Ve√≠culo"

        processamento_df = pd.DataFrame()
        unidades_db = unidades_db
        unidades_db = unidades_db[:5]# Limita a 5 ve√≠culos para teste
        # Coleta dados de relat√≥rio para 1 dia
        
        processamento_df = self.retrieve_unit_data(sid, 401756219, unidades_db, 59, processamento_df, tempo_dias=1, periodo='Ontem')
        print(f'Relat√≥rios coletados para {len(processamento_df)} unidades.')
        print(processamento_df)

        processamento_df.to_excel(f'{deposito}/localizzare_veiculos.xlsx', index=False)
#######
        unidades_db = Unidade.objects.all()
        unidades_db_ids = [unidade.id for unidade in unidades_db]
        if unidades_db_ids:
            unidades_db = unidades_db.filter(cls__icontains='Motorista')  # Filtra por classe que cont√©m "Motorista"
            unidades_db = unidades_db.filter(empresa__nome='CPBRACELL')  # Filtra por empresa CPBRACELL
        processamento_df = pd.DataFrame()
        unidades_db = unidades_db
        unidades_db = unidades_db[:5]  # Limita a 5 motoristas para teste
        # Coleta dados de relat√≥rio para 1 dia
        
        processamento_df = self.retrieve_unit_data(sid, 401756219, unidades_db, 58, processamento_df, tempo_dias=1, periodo='Ontem')
        print(f'Relat√≥rios coletados para {len(processamento_df)} unidades.')
        print(processamento_df)

        processamento_df.to_excel(f'{deposito}/localizzare_motoristas.xlsx', index=False)

        motoristas = Wialon.motoristas_simples2(sid)
        df_motoristas = pd.DataFrame(motoristas)
        print(f'Motoristas encontrados:' , colored(f'{len(df_motoristas)}', 'green'))
        print(f'Motoristas: {df_motoristas}')
        #seleciona os 10 primeiros motoristas do dataframe
        df_motoristas = df_motoristas.head(10)
        for motorista in df_motoristas.itertuples(index=False):
            motorista_id = motorista.driver_id

            relatorio = Wialon.Colheitadeira_JSON_02(sid, 401756219, motorista_id, 5, tempo_dias=1, periodo="teste")
            print(relatorio)
            Wialon.clean_up_result(sid)
            relatorio = Wialon.Colheitadeira_JSON_02(sid, 401756219, motorista_id, 58, tempo_dias=1, periodo="teste")
            print(relatorio)
            Wialon.clean_up_result(sid)





        Wialon.wialon_logout(sid)

    def localizzare2(self, token):
        sid = Wialon.authenticate_with_wialon(token)
        if not sid:
                self.stdout.write(self.style.ERROR('Falha ao iniciar sess√£o Wialon.'))
                return

        Wialon.set_locale()

        ###__UNIDADES__TODAS__###

        relatorio = Wialon.Colheitadeira_JSON_03(sid, flag=16777218, reportResourceId=401756219, reportTemplateId=59, reportObjectId=401939391, reportObjectSecId=0, unit_id="teste",  tempo_dias=1, periodo="Ontem")
        print(f'Relat√≥rio coletado: {relatorio}')
        if relatorio is not None:
            relatorio.to_excel(f'{deposito}/relatorio_[UMBR]UNIDADES_ontem.xlsx', index=False)
        Wialon.clean_up_result(sid)

        relatorio = Wialon.Colheitadeira_JSON_03(sid, flag=16777218, reportResourceId=401756219, reportTemplateId=59, reportObjectId=401939391, reportObjectSecId=0, unit_id="teste",  tempo_dias=7, periodo="Semana")
        print(f'Relat√≥rio coletado: {relatorio}')
        if relatorio is not None:
            relatorio.to_excel(f'{deposito}/relatorio_[UMBR]UNIDADES_semana.xlsx', index=False)
        Wialon.clean_up_result(sid)

        relatorio = Wialon.Colheitadeira_JSON_03(sid, flag=16777218, reportResourceId=401756219, reportTemplateId=59, reportObjectId=401939391, reportObjectSecId=0, unit_id="teste",  tempo_dias=30, periodo="M√™s")
        print(f'Relat√≥rio coletado: {relatorio}')
        if relatorio is not None:
            relatorio.to_excel(f'{deposito}/relatorio_[UMBR]UNIDADES_mes.xlsx', index=False)
        Wialon.clean_up_result(sid)

        ###__MOTORISTAS__CPBrascell__###

        relatorio = Wialon.Colheitadeira_JSON_03(sid, flag=16777218, reportResourceId=401756219, reportTemplateId=58, reportObjectId=401756219, reportObjectSecId=1, unit_id="teste",  tempo_dias=1, periodo="Ontem")
        print(f'Relat√≥rio coletado: {relatorio}')
        if relatorio is not None:
            relatorio.to_excel(f'{deposito}/relatorio_[CPB]MOTORISTAS_ontem.xlsx', index=False)
        Wialon.clean_up_result(sid)

        relatorio = Wialon.Colheitadeira_JSON_03(sid, flag=16777218, reportResourceId=401756219, reportTemplateId=58, reportObjectId=401756219, reportObjectSecId=1, unit_id="teste",  tempo_dias=7, periodo="Semana")
        print(f'Relat√≥rio coletado: {relatorio}')
        if relatorio is not None:
            relatorio.to_excel(f'{deposito}/relatorio_[CPB]MOTORISTAS_semana.xlsx', index=False)
        Wialon.clean_up_result(sid)
        
        relatorio = Wialon.Colheitadeira_JSON_03(sid, flag=16777218, reportResourceId=401756219, reportTemplateId=58, reportObjectId=401756219, reportObjectSecId=1, unit_id="teste",  tempo_dias=30, periodo="M√™s")
        print(f'Relat√≥rio coletado: {relatorio}')
        if relatorio is not None:
            relatorio.to_excel(f'{deposito}/relatorio_[CPB]MOTORISTAS_mes.xlsx', index=False)
        Wialon.clean_up_result(sid)

        ###__MOTORISTAS__PLACIDO__###

        relatorio = Wialon.Colheitadeira_JSON_03(sid, flag=16777218, reportResourceId=401768999, reportTemplateId=48, reportObjectId=401768999, reportObjectSecId=1, unit_id="teste",  tempo_dias=1, periodo="Ontem")
        print(f'Relat√≥rio coletado: {relatorio}')
        if relatorio is not None:
            relatorio.to_excel(f'{deposito}/relatorio_[PLA]MOTORISTAS_ontem.xlsx', index=False)
        Wialon.clean_up_result(sid)

        relatorio = Wialon.Colheitadeira_JSON_03(sid, flag=16777218, reportResourceId=401768999, reportTemplateId=48, reportObjectId=401768999, reportObjectSecId=1, unit_id="teste",  tempo_dias=7, periodo="Semana")
        print(f'Relat√≥rio coletado: {relatorio}')
        if relatorio is not None:
            relatorio.to_excel(f'{deposito}/relatorio_[PLA]MOTORISTAS_semana.xlsx', index=False)
        Wialon.clean_up_result(sid)
        
        relatorio = Wialon.Colheitadeira_JSON_03(sid, flag=16777218, reportResourceId=401768999, reportTemplateId=48, reportObjectId=401768999, reportObjectSecId=1, unit_id="teste",  tempo_dias=30, periodo="M√™s")
        print(f'Relat√≥rio coletado: {relatorio}')
        if relatorio is not None:
            relatorio.to_excel(f'{deposito}/relatorio_[PLA]MOTORISTAS_mes.xlsx', index=False)
        Wialon.clean_up_result(sid)


        Wialon.wialon_logout(sid)

    
    def localizzare3(self, token):
        sid = Wialon.authenticate_with_wialon(token)
        if not sid:
                self.stdout.write(self.style.ERROR('Falha ao iniciar sess√£o Wialon.'))
                return

        Wialon.set_locale()
        processamento_df = pd.DataFrame()

        ###__UNIDADES__TODAS__###

        relatorio = Wialon.Colheitadeira_JSON_03(sid, flag=16777218, reportResourceId=401756219, reportTemplateId=59, reportObjectId=401939391, reportObjectSecId=0, unit_id="teste",  tempo_dias=1, periodo="Ontem")
        print(f'Relat√≥rio coletado: {relatorio}')

        if relatorio is not None:
            relatorio.to_excel(f'{deposito}/relatorio_[UMBR]UNIDADES_ontem.xlsx', index=False)
            processamento_df = pd.concat([processamento_df, relatorio], ignore_index=True)
            print("RESULTADO:")
            print(processamento_df)

        Wialon.clean_up_result(sid)

        relatorio = Wialon.Colheitadeira_JSON_03(sid, flag=16777218, reportResourceId=401756219, reportTemplateId=59, reportObjectId=401939391, reportObjectSecId=0, unit_id="teste",  tempo_dias=7, periodo="Semana")
        print(f'Relat√≥rio coletado: {relatorio}')
        if relatorio is not None:
            relatorio.to_excel(f'{deposito}/relatorio_[UMBR]UNIDADES_semana.xlsx', index=False)
        Wialon.clean_up_result(sid)

        relatorio = Wialon.Colheitadeira_JSON_03(sid, flag=16777218, reportResourceId=401756219, reportTemplateId=59, reportObjectId=401939391, reportObjectSecId=0, unit_id="teste",  tempo_dias=30, periodo="M√™s")
        print(f'Relat√≥rio coletado: {relatorio}')
        if relatorio is not None:
            relatorio.to_excel(f'{deposito}/relatorio_[UMBR]UNIDADES_mes.xlsx', index=False)
        Wialon.clean_up_result(sid)

        ###__MOTORISTAS__CPBrascell__###

        relatorio = Wialon.Colheitadeira_JSON_03(sid, flag=16777218, reportResourceId=401756219, reportTemplateId=58, reportObjectId=401756219, reportObjectSecId=1, unit_id="teste",  tempo_dias=1, periodo="Ontem")
        print(f'Relat√≥rio coletado: {relatorio}')
        if relatorio is not None:
            relatorio.to_excel(f'{deposito}/relatorio_[CPB]MOTORISTAS_ontem.xlsx', index=False)
        Wialon.clean_up_result(sid)

        relatorio = Wialon.Colheitadeira_JSON_03(sid, flag=16777218, reportResourceId=401756219, reportTemplateId=58, reportObjectId=401756219, reportObjectSecId=1, unit_id="teste",  tempo_dias=7, periodo="Semana")
        print(f'Relat√≥rio coletado: {relatorio}')
        if relatorio is not None:
            relatorio.to_excel(f'{deposito}/relatorio_[CPB]MOTORISTAS_semana.xlsx', index=False)
        Wialon.clean_up_result(sid)
        
        relatorio = Wialon.Colheitadeira_JSON_03(sid, flag=16777218, reportResourceId=401756219, reportTemplateId=58, reportObjectId=401756219, reportObjectSecId=1, unit_id="teste",  tempo_dias=30, periodo="M√™s")
        print(f'Relat√≥rio coletado: {relatorio}')
        if relatorio is not None:
            relatorio.to_excel(f'{deposito}/relatorio_[CPB]MOTORISTAS_mes.xlsx', index=False)
        Wialon.clean_up_result(sid)

        ###__MOTORISTAS__PLACIDO__###

        relatorio = Wialon.Colheitadeira_JSON_03(sid, flag=16777218, reportResourceId=401768999, reportTemplateId=48, reportObjectId=401768999, reportObjectSecId=1, unit_id="teste",  tempo_dias=1, periodo="Ontem")
        print(f'Relat√≥rio coletado: {relatorio}')
        if relatorio is not None:
            relatorio.to_excel(f'{deposito}/relatorio_[PLA]MOTORISTAS_ontem.xlsx', index=False)
        Wialon.clean_up_result(sid)

        relatorio = Wialon.Colheitadeira_JSON_03(sid, flag=16777218, reportResourceId=401768999, reportTemplateId=48, reportObjectId=401768999, reportObjectSecId=1, unit_id="teste",  tempo_dias=7, periodo="Semana")
        print(f'Relat√≥rio coletado: {relatorio}')
        if relatorio is not None:
            relatorio.to_excel(f'{deposito}/relatorio_[PLA]MOTORISTAS_semana.xlsx', index=False)
        Wialon.clean_up_result(sid)
        
        relatorio = Wialon.Colheitadeira_JSON_03(sid, flag=16777218, reportResourceId=401768999, reportTemplateId=48, reportObjectId=401768999, reportObjectSecId=1, unit_id="teste",  tempo_dias=30, periodo="M√™s")
        print(f'Relat√≥rio coletado: {relatorio}')
        if relatorio is not None:
            relatorio.to_excel(f'{deposito}/relatorio_[PLA]MOTORISTAS_mes.xlsx', index=False)
        Wialon.clean_up_result(sid)


        Wialon.wialon_logout(sid)

        #######################################################################################

    def atualiza_unidades(self, sid, empresa_nome):
                 # Busca unidades
        unidades = unidades_simples(sid)
        if not unidades:
            self.stdout.write(self.style.ERROR('Nenhuma unidade encontrada.'))
            return
        
        #coloca os dados em um dataframe
        df_unidades = pd.DataFrame(unidades)
        print(f'Unidades encontradas:' , colored(f'{len(df_unidades)}', 'green'))
        print(f'Unidades: {df_unidades}')
        for unidade in df_unidades.itertuples(index=False):
            unidade_id = unidade.id
            unidade_nome = unidade.nm
            #separa o nome da unidade por delimitadores '_'(underline). a primeira parte antes do primeiro underline √© a placa, que devemos considerar como o novo nome do ve√≠culo.
            partes_nome = unidade_nome.split('_')
            placa = partes_nome[0].strip() if partes_nome else ''
            restante_nome = ' '.join([parte.strip() for parte in partes_nome[1:]]) if len(partes_nome) > 1 else ''
    
            #checa se 'restante_nome' possui o valor 'Scania', se sim, define 'marca' como Scania
            if 'Scania' in restante_nome:
                marca = 'Scania'
            else:
                marca = 'Volvo'

            cls = 'Ve√≠culo'
            #retorna a inst√¢ncia da empresa correspondente
            empresa = Empresa.objects.filter(nome=empresa_nome).first()
            if not empresa:
                self.stdout.write(self.style.ERROR(f'Empresa {empresa_nome} n√£o encontrada no banco de dados.'))
                return
            if empresa.nome == 'PLACIDO':
                marca = 'DAF'
            if empresa.nome == 'S√£o Francisco Resgate':
                marca = 'Fiat'
            unidade_id = f"{empresa_nome}_{unidade_id}"

            #+---
            print(f'Unidade: {placa} | ID: {unidade_id} | Restante do nome: {restante_nome} | Marca: {marca} | Classe: {cls} | Empresa: {empresa.nome}')
            #+---

            # Atualiza a unidade no banco de dados
            Unidade.objects.update_or_create(
                id=unidade_id,
                defaults={
                    'nm': unidade_nome,
                    'placa': placa,
                    'marca': marca,
                    'cls': cls,
                    'descricao': restante_nome if restante_nome else placa,
                    'empresa': empresa
                }
            )
        #adiciona tamb√©m os motoristas

        motoristas = Wialon.motoristas_simples2(sid)
        df_motoristas = pd.DataFrame(motoristas)
        print(f'Motoristas encontrados:' , colored(f'{len(df_motoristas)}', 'green'))
        print(f'Motoristas: {df_motoristas}')
        for motorista in df_motoristas.itertuples(index=False):
            motorista_id = motorista.driver_id
            motorista_nome = motorista.driver_name
            cls = 'Motorista'
            empresa = Empresa.objects.filter(nome=empresa_nome).first()
            if not empresa:
                self.stdout.write(self.style.ERROR(f'Empresa {empresa_nome} n√£o encontrada no banco de dados.'))
                return

            motorista_id = f"{empresa_nome}_{motorista_id}"

            print(f'Motorista: {motorista_nome} | ID: {motorista_id} | Classe: {cls} | Empresa: {empresa.nome}')

            # Atualiza o motorista no banco de dados
            Unidade.objects.update_or_create(
                id=motorista_id,
                defaults={
                    'nm': motorista_nome,
                    'cls': cls,
                    'empresa': empresa,
                }
            )





    def process_units_CP(self, sid):
        # CAMINHOES BRASCELL#######################
        unidades_db = Unidade.objects.all()
        unidades_db_ids = [unidade.id for unidade in unidades_db]
        if unidades_db_ids:
            unidades_db = unidades_db.filter(empresa__nome='CPBRASCELL')
            unidades_db = unidades_db.filter(cls__icontains='Ve√≠culo')  # Filtra por classe que cont√©m "Ve√≠culo"

        processamento_df = pd.DataFrame()
        unidades_db = unidades_db
        # Coleta dados de relat√≥rio para 1 dia
        
        processamento_df = self.retrieve_unit_data(sid, 401756219, unidades_db, 59, processamento_df, tempo_dias=1, periodo='Ontem')
        print(f'Relat√≥rios coletados para {len(processamento_df)} unidades.')
        print(processamento_df)
        processamento_df = self.retrieve_unit_data(sid, 401756219, unidades_db, 59, processamento_df, tempo_dias=7, periodo='√öltimos 7 dias')
        print(f'Relat√≥rios coletados para {len(processamento_df)} unidades.')
        print(processamento_df)
        processamento_df = self.retrieve_unit_data(sid, 401756219, unidades_db, 59, processamento_df, tempo_dias=30, periodo='√öltimos 30 dias')
        print(f'Relat√≥rios coletados para {len(processamento_df)} unidades.')
        print(processamento_df)
        




        # Atualiza ou cria as viagens no model Viagem_Base

        self.update_or_create_trip(processamento_df)



    def process_units_PLAC(self, sid):
        # CAMINHOES PLACIDO#######################
        unidades_db = Unidade.objects.all()
        unidades_db_ids = [unidade.id for unidade in unidades_db]
        if unidades_db_ids:
            unidades_db = unidades_db.filter(empresa__nome='PLACIDO')
            unidades_db = unidades_db.filter(cls__icontains='Ve√≠culo')  # Filtra por classe que cont√©m "Ve√≠culo"

        processamento_df = pd.DataFrame()

        # Coleta dados de relat√≥rio para 1 dia
        processamento_df = self.retrieve_unit_data(sid, 401768999, unidades_db, 45, processamento_df, tempo_dias=1, periodo='Ontem')
        processamento_df = self.retrieve_unit_data(sid, 401768999, unidades_db, 45, processamento_df, tempo_dias=7, periodo='√öltimos 7 dias')
        processamento_df = self.retrieve_unit_data(sid, 401768999, unidades_db, 45, processamento_df, tempo_dias=30, periodo='√öltimos 30 dias')
        print(f'Relat√≥rios coletados para {len(processamento_df)} unidades.')

        # Atualiza ou cria as viagens no model Viagem_Base
        self.update_or_create_trip(processamento_df)
        print(processamento_df)

    def process_units_SF(self, sid):
        # CAMINHOES S√ÉO FRANCISCO#######################
        unidades_db = Unidade.objects.all()
        unidades_db_ids = [unidade.id for unidade in unidades_db]
        if unidades_db_ids:
            unidades_db = unidades_db.filter(empresa__nome='S√£o Francisco Resgate')
            unidades_db = unidades_db.filter(cls__icontains='Ve√≠culo')  # Filtra por classe que cont√©m "Ve√≠culo"

        processamento_df = pd.DataFrame()
        unidades_db = unidades_db
        # Coleta dados de relat√≥rio para 1 dia
        
        processamento_df = self.retrieve_unit_data(sid, 401756219, unidades_db, 59, processamento_df, tempo_dias=1, periodo='Ontem')
        print(f'Relat√≥rios coletados para {len(processamento_df)} unidades.')
        print(processamento_df)
        processamento_df = self.retrieve_unit_data(sid, 401756219, unidades_db, 59, processamento_df, tempo_dias=7, periodo='√öltimos 7 dias')
        print(f'Relat√≥rios coletados para {len(processamento_df)} unidades.')
        print(processamento_df)
        processamento_df = self.retrieve_unit_data(sid, 401756219, unidades_db, 59, processamento_df, tempo_dias=30, periodo='√öltimos 30 dias')
        print(f'Relat√≥rios coletados para {len(processamento_df)} unidades.')
        print(processamento_df)
        




        # Atualiza ou cria as viagens no model Viagem_Base

        self.update_or_create_trip(processamento_df)



    def process_motoristas_CP(self, sid):
        #MOTORISTAS BRASCELL####################################################################################
        unidades_db = Unidade.objects.all()
        unidades_db_ids = [unidade.id for unidade in unidades_db]
        if unidades_db_ids:
            unidades_db = unidades_db.filter(empresa__nome='CPBRACELL')
            unidades_db = unidades_db.filter(cls__icontains='Motorista')  # Filtra por classe que cont√©m "Motorista"

        processamento_df = pd.DataFrame()
        #pega as primmeiras 5 unidades
        unidades_db = unidades_db[:5]
        print(f"ids_motoristas: {unidades_db}")
        # Coleta dados de relat√≥rio para 7 dias
        processamento_df = self.retrieve_unit_data_motorista(sid, 401756219, unidades_db, 58, processamento_df, tempo_dias=7, periodo='Ultimos 7 dias')
        print(f'Relat√≥rios coletados para {len(processamento_df)} motoristas.')
        print(processamento_df)

    def process_motoristas_CP_2(self, sid):
        # motoristas BRASCELL#######################
        unidades_db = Unidade.objects.all()
        unidades_db_ids = [unidade.id for unidade in unidades_db]
        if unidades_db_ids:
            unidades_db = unidades_db.filter(empresa__nome='CPBRACELL')
            unidades_db = unidades_db.filter(cls__icontains='Motorista')  # Filtra por classe que cont√©m "Motorista"

        processamento_df = pd.DataFrame()
        unidades_db = unidades_db
        # Coleta dados de relat√≥rio para 1 dia
        
        processamento_df = self.retrieve_unit_data(sid, 401756219, unidades_db, 58, processamento_df, tempo_dias=1, periodo='Ontem')
        print(f'Relat√≥rios coletados para {len(processamento_df)} unidades.')
        print(processamento_df)
        #processamento_df = self.retrieve_unit_data(sid, 401756219, unidades_db, 58, processamento_df, tempo_dias=7, periodo='√öltimos 7 dias')
        #print(f'Relat√≥rios coletados para {len(processamento_df)} unidades.')
        #print(processamento_df)
        #processamento_df = self.retrieve_unit_data(sid, 401756219, unidades_db, 58, processamento_df, tempo_dias=30, periodo='√öltimos 30 dias')
        #print(f'Relat√≥rios coletados para {len(processamento_df)} unidades.')
        #print(processamento_df)
        




        # Atualiza ou cria as viagens no model Viagem_Base

        self.update_or_create_trip(processamento_df)

    def update_or_create_trip(self, processamento_df):
        if not processamento_df.empty:
            for index, row in processamento_df.iterrows():
                try:
                    unidades = Unidade.objects.filter(nm=row['Grouping'])
                    
                    if not unidades.exists():
                        self.stdout.write(self.style.ERROR(f'Unidade com nome "{row["Grouping"]}" n√£o encontrada no banco de dados.'))
                        continue
                    
                    if unidades.count() > 1:
                        self.stdout.write(self.style.WARNING(f'M√∫ltiplas unidades encontradas com nome "{colored(row["Grouping"], "red")}". Usando a primeira.'))
                        # Log das unidades duplicadas para an√°lise
                        for unidade in unidades:
                            self.stdout.write(self.style.WARNING(f'  - ID: {unidade.id}, Empresa: {unidade.empresa.nome if unidade.empresa else "N/A"}'))
                    
                    unidade_instance = unidades.first()
                    
                    # Processa os valores numericos
                    quilometragem = self.processar_valor_numerico(row.get('Quilometragem', '0'))
                    consumo = self.processar_valor_numerico(row.get('Consumido por AbsFCS', '0'))
                    km_media = self.processar_valor_numerico(row.get('Quilometragem m√©dia por unidade de combust√≠vel por AbsFCS', '0'))
                    velocidade_media = self.processar_valor_numerico(row.get('Velocidade m√©dia', '0'))
                    rpm_medio = self.processar_valor_numerico(row.get('RPM m√©dio do motor', '0'))
                    temperatura_media = self.processar_valor_numerico(row.get('Temperatura m√©dia', '0'))
                    co2 = self.processar_valor_numerico(row.get('Emiss√µes de CO2', '0'))


                    try:
                        quilometragem_value = float(quilometragem)
                        consumo_value = float(consumo)
                        km_media_value = Decimal(km_media)
                        velocidade_media_value = float(velocidade_media)
                        rpm_medio_value = float(rpm_medio)
                        temperatura_media_value = float(temperatura_media)
                        co2_value = float(co2)
                    except (ValueError, TypeError):
                        quilometragem_value = 0.00
                        consumo_value = 0.00
                        km_media_value = 0.00
                        velocidade_media_value = 0.00
                        rpm_medio_value = 0.00
                        temperatura_media_value = 0.00
                        co2_value = 0.00

                    
                    Viagem_Base.objects.update_or_create(
                        unidade=unidade_instance,
                        per√≠odo=row['periodo'],
                        defaults={
                            'quilometragem': quilometragem_value,
                            'Consumido': consumo_value,
                            'Quilometragem_m√©dia': km_media_value,
                            'Velocidade_m√©dia': velocidade_media_value,
                            'RPM_m√©dio': rpm_medio_value,
                            'Temperatura_m√©dia': temperatura_media_value,
                            'Emiss√µes_CO2': co2_value,

                        }
                    )
                    self.stdout.write(self.style.SUCCESS(f'Viagem: {colored(row["Grouping"], "cyan")} - {colored(row["periodo"], "magenta")} - {colored(quilometragem_value, "green")}'))

                except Unidade.DoesNotExist:
                    self.stdout.write(self.style.ERROR(f'Unidade com nome "{row["Grouping"]}" n√£o encontrada no banco de dados.'))
                    continue



    def viagem(self, processamento_df):
        if not processamento_df.empty:
            for index, row in processamento_df.iterrows():
                try:
                    unidades = Unidade.objects.filter(nm=row['Grouping'])
                    
                    if not unidades.exists():
                        self.stdout.write(self.style.ERROR(f'Unidade com nome "{row["Grouping"]}" n√£o encontrada no banco de dados.'))
                        continue
                    
                    if unidades.count() > 1:
                        self.stdout.write(self.style.WARNING(f'M√∫ltiplas unidades encontradas com nome "{colored(row["Grouping"], "red")}". Usando a primeira.'))
                        # Log das unidades duplicadas para an√°lise
                        for unidade in unidades:
                            self.stdout.write(self.style.WARNING(f'  - ID: {unidade.id}, Empresa: {unidade.empresa.nome if unidade.empresa else "N/A"}'))
                    
                    unidade_instance = unidades.first()
                    
                    # Processa os valores numericos
                    quilometragem = self.processar_valor_numerico(row.get('Quilometragem Percorrida', '0'))
                    consumo = self.processar_valor_numerico(row.get('Consumido por AbsFCS', '0'))
                    km_media = self.processar_valor_numerico(row.get('M√©dia de Consumo de Combustivel em Movimento', '0'))
                    velocidade_media = self.processar_valor_numerico(row.get('Velocidade m√©dia', '0'))
                    rpm_medio = self.processar_valor_numerico(row.get('RPM m√©dio do motor', '0'))
                    temperatura_media = self.processar_valor_numerico(row.get('Temperatura m√©dia', '0'))
                    co2 = self.processar_valor_numerico(row.get('Emiss√µes de CO2', '0'))
                    odometro = self.processar_valor_numerico(row.get('Hodometro Atual', '0'))


                    try:
                        quilometragem_value = float(quilometragem)
                        consumo_value = float(consumo)
                        km_media_value = Decimal(km_media)
                        velocidade_media_value = float(velocidade_media)
                        rpm_medio_value = float(rpm_medio)
                        temperatura_media_value = float(temperatura_media)
                        co2_value = float(co2)
                        odometro_value = float(odometro)
                    except (ValueError, TypeError):
                        quilometragem_value = 0.00
                        consumo_value = 0.00
                        km_media_value = 0.00
                        velocidade_media_value = 0.00
                        rpm_medio_value = 0.00
                        temperatura_media_value = 0.00
                        co2_value = 0.00
                        odometro_value = 0.00

                    
                    Viagem_Base.objects.update_or_create(
                        unidade=unidade_instance,
                        per√≠odo=row['periodo'],
                        defaults={
                            'quilometragem': quilometragem_value,
                            'Consumido': consumo_value,
                            'Quilometragem_m√©dia': km_media_value,
                            'Velocidade_m√©dia': velocidade_media_value,
                            'RPM_m√©dio': rpm_medio_value,
                            'Temperatura_m√©dia': temperatura_media_value,
                            'Emiss√µes_CO2': co2_value,

                        }
                    )
                    Unidade.objects.filter(id=unidade_instance.id).update(odometro=odometro_value)

                    self.stdout.write(self.style.SUCCESS(f'Viagem: {colored(row["Grouping"], "cyan")} - {colored(row["periodo"], "magenta")} - {colored(quilometragem_value, "green")}'))

                except Unidade.DoesNotExist:
                    self.stdout.write(self.style.ERROR(f'Unidade com nome "{row["Grouping"]}" n√£o encontrada no banco de dados.'))
                    continue



    def update_or_create_checkpoint(self, processamento_df):
        if not processamento_df.empty:
            for index, row in processamento_df.iterrows():
                try:
                    # CORRE√á√ÉO: Obter uma inst√¢ncia √∫nica em vez de QuerySet
                    unidades = Unidade.objects.filter(nm=row['Grouping'])
                    
                    if not unidades.exists():
                        self.stdout.write(self.style.ERROR(f'Unidade com nome "{row["Grouping"]}" n√£o encontrada no banco de dados.'))
                        continue
                    
                    if unidades.count() > 1:
                        self.stdout.write(self.style.WARNING(f'M√∫ltiplas unidades encontradas com nome "{colored(row["Grouping"], "red")}". Usando a primeira.'))
                        # Log das unidades duplicadas para an√°lise
                        for unidade in unidades:
                            self.stdout.write(self.style.WARNING(f'  - ID: {unidade.id}, Empresa: {unidade.empresa.nome if unidade.empresa else "N/A"}'))
                    
                    unidade_instance = unidades.first()  # Obter a inst√¢ncia √∫nica
                    
                    # Processa os valores de data/hora
                    hora_entrada = self.processar_datetime2(row.get('Hora de entrada'))
                    hora_saida = self.processar_datetime2(row.get('Hora de sa√≠da'))
                    duracao = self.processar_duracao(row.get('Dura√ß√£o em', ''))



                    # Processa a cerca eletr√¥nica (texto)
                    cerca_eletronica = str(row.get('Cerca eletr√¥nica', '')).strip()

                    CheckPoint.objects.update_or_create(
                        unidade=unidade_instance,  # CORRE√á√ÉO: Usar a inst√¢ncia em vez do QuerySet
                        cerca=cerca_eletronica,
                        data_entrada=hora_entrada,
                        data_saida=hora_saida,
                        duracao=duracao
                    )
                    #+---
                    #self.stdout.write(self.style.SUCCESS(f'CheckPoint  {colored(row["Grouping"], "cyan")} -  - Cerca: {colored(cerca_eletronica, "green")} - Hora de entrada: {colored(hora_entrada, "blue")} - Hora de sa√≠da: {colored(hora_saida, "blue")}. - Dura√ß√£o: {colored(duracao, "green")}'))
                    #+---
                except Unidade.DoesNotExist:
                    self.stdout.write(self.style.ERROR(f'Unidade com nome "{row["Grouping"]}" n√£o encontrada no banco de dados.'))
                    continue
                except Exception as e:
                    self.stdout.write(self.style.ERROR(f'Erro ao processar linha {index + 1}: {str(e)}'))
                    continue



    def update_or_create_infra√ß√£o(self, processamento_df):
        if not processamento_df.empty:
            for index, row in processamento_df.iterrows():
                try:
                    # CORRE√á√ÉO: Obter uma inst√¢ncia √∫nica em vez de QuerySet
                    unidades = Unidade.objects.filter(nm=row['Grouping'])
                    
                    if not unidades.exists():
                        self.stdout.write(self.style.ERROR(f'Unidade com nome "{row["Grouping"]}" n√£o encontrada no banco de dados.'))
                        continue
                    
                    if unidades.count() > 1:
                        self.stdout.write(self.style.WARNING(f'M√∫ltiplas unidades encontradas com nome "{colored(row["Grouping"], "red")}". Usando a primeira.'))
                        # Log das unidades duplicadas para an√°lise
                        for unidade in unidades:
                            self.stdout.write(self.style.WARNING(f'  - ID: {unidade.id}, Empresa: {unidade.empresa.nome if unidade.empresa else "N/A"}'))
                    
                    unidade_instance = unidades.first()  # Obter a inst√¢ncia √∫nica
                    #remove "km/h‚Äù
                    velocidade=row.get('Velocidade m√©dia', '').replace("km/h", "").strip()
                    limite = row.get('Limite de velocidade', '').replace("km/h", "").strip()
                    data = row.get('In√≠cio', '').strip()

                    latitude = row.get('Latitude', '')
                    longitude = row.get('Longitude', '')
                    
                    maps = f"https://www.google.com/maps?q={latitude},{longitude}"

                    # Processa os valores de data/hora
                    #hora_entrada = self.processar_datetime(row.get('Hora de entrada'))
                    #hora_saida = self.processar_datetime(row.get('Hora de sa√≠da'))
                    #duracao = self.processar_duracao(row.get('Dura√ß√£o em', ''))

                    Infra√ß√µes.objects.update_or_create(
                        unidade=unidade_instance,
                        velocidade=velocidade,
                        limite=limite,  
                        data=self.processar_datetime2(data),
                        localizacao=maps,
                    )
                    self.stdout.write(self.style.SUCCESS(f'WORKED!'))

                except Unidade.DoesNotExist:
                    self.stdout.write(self.style.ERROR(f'Unidade com nome "{row["Grouping"]}" n√£o encontrada no banco de dados.'))
                    continue
                except Exception as e:
                    self.stdout.write(self.style.ERROR(f'Erro ao processar linha {index + 1}: {str(e)}'))
                    continue

    def processar_datetime(self, valor_datetime):
        """
        Processa valores de data/hora do Excel e aplica fuso hor√°rio GMT-03 (Bras√≠lia)
        """
        try:
            if pd.isna(valor_datetime) or valor_datetime == '' or valor_datetime is None:
                return None
            

            
            # Se j√° √© um datetime do pandas
            if isinstance(valor_datetime, pd.Timestamp):
                dt = valor_datetime.to_pydatetime()
            elif isinstance(valor_datetime, str):
                # Se √© string, tenta converter
                dt = None
                # Tenta alguns formatos comuns - colocando o formato correto primeiro
                formatos = [
                    '%d.%m.%Y %H:%M:%S',  # 17.08.2025 15:31:02 (formato correto)
                    '%Y-%m-%d %H:%M:%S',  # 2025-08-17 15:31:02
                    '%d/%m/%Y %H:%M:%S',  # 17/08/2025 15:31:02
                    '%Y-%m-%d',           # 2025-08-17
                    '%d.%m.%Y',           # 17.08.2025
                    '%d/%m/%Y',           # 17/08/2025
                ]
                
                for formato in formatos:
                    try:
                        dt = datetime.strptime(valor_datetime.strip(), formato)
                        break
                    except ValueError:
                        continue
                
                if dt is None:
                    # Se n√£o conseguiu converter, retorna None
                    self.stdout.write(self.style.WARNING(f'Formato de data/hora n√£o reconhecido: {valor_datetime}'))
                    return None
            else:
                return None
            
            # FOR√áA BRUTA: Subtrai 3 horas diretamente
            dt_brasilia = dt - timedelta(hours=3)
            
            # Aplica o timezone de Bras√≠lia ao resultado
            brasilia_tz = pytz.timezone('America/Sao_Paulo')
            
            # Se o datetime resultante √© "naive", localiza no timezone de Bras√≠lia
            if dt_brasilia.tzinfo is None:
                dt_brasilia = brasilia_tz.localize(dt_brasilia)
            else:
                # Se j√° tem timezone, converte para Bras√≠lia
                dt_brasilia = dt_brasilia.astimezone(brasilia_tz)
            
            return dt_brasilia
            
        except Exception as e:
            self.stdout.write(self.style.WARNING(f'Erro ao processar data/hora "{valor_datetime}": {e}'))
            return None
        

    
    def processar_datetime2(self, valor_datetime):
        """
        Processa valores de data/hora do Excel e aplica fuso hor√°rio GMT-03 (Bras√≠lia)
        """
        try:
            if pd.isna(valor_datetime) or valor_datetime == '' or valor_datetime is None:
                return None
            
            from django.utils import timezone
            from datetime import timedelta
            import pytz
            
            # Se j√° √© um datetime do pandas
            if isinstance(valor_datetime, pd.Timestamp):
                dt = valor_datetime.to_pydatetime()
            elif isinstance(valor_datetime, str):
                # Se √© string, tenta converter
                dt = None
                # Tenta alguns formatos comuns - colocando o formato correto primeiro
                formatos = [
                    '%d.%m.%Y %H:%M:%S',  # 17.08.2025 15:31:02 (formato correto)
                    '%Y-%m-%d %H:%M:%S',  # 2025-08-17 15:31:02
                    '%d/%m/%Y %H:%M:%S',  # 17/08/2025 15:31:02
                    '%Y-%m-%d',           # 2025-08-17
                    '%d.%m.%Y',           # 17.08.2025
                    '%d/%m/%Y',           # 17/08/2025
                ]
                
                for formato in formatos:
                    try:
                        dt = datetime.strptime(valor_datetime.strip(), formato)
                        break
                    except ValueError:
                        continue
                
                if dt is None:
                    # Se n√£o conseguiu converter, retorna None
                    self.stdout.write(self.style.WARNING(f'Formato de data/hora n√£o reconhecido: {valor_datetime}'))
                    return None
            else:
                return None
            
            # FOR√áA BRUTA: Subtrai 3 horas diretamente
            dt_brasilia = dt - timedelta(hours=3)
            
            
            return dt_brasilia
            
        except Exception as e:
            self.stdout.write(self.style.WARNING(f'Erro ao processar data/hora "{valor_datetime}": {e}'))
            return None

    def processar_duracao(self, valor_duracao):
        """
        Processa valores de dura√ß√£o (formato "1 dias 3:20:04" ou HH:MM:SS)
        Retorna um objeto timedelta para o campo DurationField do Django
        """
        try:
            if pd.isna(valor_duracao) or valor_duracao == '' or valor_duracao is None:
                return None
            
            # Converte para string
            duracao_str = str(valor_duracao).strip()
            
            # Se est√° vazio ap√≥s strip
            if not duracao_str:
                return None
            
            # Verifica se √© o formato "X dias HH:MM:SS"
            if 'dias' in duracao_str or 'dia' in duracao_str:
                import re
                from datetime import timedelta
                
                # Regex para capturar dias e tempo
                match = re.match(r'(\d+)\s+dias?\s+(\d+):(\d+):(\d+)', duracao_str)
                if match:
                    dias = int(match.group(1))
                    horas = int(match.group(2))
                    minutos = int(match.group(3))
                    segundos = int(match.group(4))
                    
                    return timedelta(days=dias, hours=horas, minutes=minutos, seconds=segundos)
            
            # Se est√° no formato HH:MM:SS, converte para timedelta
            if ':' in duracao_str:
                from datetime import timedelta
                partes = duracao_str.split(':')
                if len(partes) == 3:
                    try:
                        horas = int(partes[0])
                        minutos = int(partes[1])
                        segundos = int(partes[2])
                        return timedelta(hours=horas, minutes=minutos, seconds=segundos)
                    except ValueError:
                        pass
                elif len(partes) == 2:
                    try:
                        horas = int(partes[0])
                        minutos = int(partes[1])
                        return timedelta(hours=horas, minutes=minutos)
                    except ValueError:
                        pass
            
            # Se √© um n√∫mero (minutos), converte para timedelta
            try:
                from datetime import timedelta
                minutos = float(duracao_str)
                return timedelta(minutes=minutos)
            except ValueError:
                pass
            
            return None
            
        except Exception as e:
            self.stdout.write(self.style.WARNING(f'Erro ao processar dura√ß√£o "{valor_duracao}": {e}'))
            return None



    def retrieve_unit_data(self, sid, resource_id, unidades_db, id_relatorio, processamento_df, tempo_dias, periodo):
        for unidade in tqdm(unidades_db, desc="Processando unidades", unit="unidade"):
            unidade_id = unidade.id

            # Coleta dados de relat√≥rio para 1 dia
            relatorio = Wialon.Colheitadeira_JSON(sid, resource_id, unidade_id, id_relatorio, tempo_dias=tempo_dias, periodo=periodo)

            processamento_df = pd.concat([processamento_df, relatorio], ignore_index=True)

            Wialon.clean_up_result(sid)
        return processamento_df

    def retrieve_unit_data_motorista(self, sid, unidades_db, id_relatorio, processamento_df, tempo_dias, periodo):
        for unidade in tqdm(unidades_db, desc="Processando unidades", unit="unidade"):
            unidade_id = unidade.id

            # Coleta dados de relat√≥rio para 1 dia
            relatorio = Wialon.Colheitadeira_JSON_motorista(sid, unidade_id, id_relatorio, tempo_dias=tempo_dias, periodo=periodo)

            processamento_df = pd.concat([processamento_df, relatorio], ignore_index=True)

            Wialon.clean_up_result(sid)
        return processamento_df



    def processar_valor_numerico(self, valor_str, unidade='', valor_padrao=0.0):
        """
        Processa valores string para num√©rico, removendo unidades e tratando casos especiais
        """
        try:
            # Verifica valores nulos ou vazios
            if pd.isna(valor_str) or valor_str == '-----' or valor_str == '' or valor_str is None:
                return Decimal('0.00')
            
            # Converte para string se n√£o for
            valor_str = str(valor_str).strip()
            
            # Verifica se √© vazio ap√≥s strip
            if not valor_str:
                return Decimal('0.00')
            
            # Remove unidades de medida comuns
            valor_limpo = valor_str.replace(' km', '').replace(' l', '').replace(' km/h', '').replace(' ¬∞C', '').replace(' t', '').replace(' g/km', '').replace(' rpm', '')
            valor_limpo = valor_limpo.replace(',', '.').strip()
            
            # Verifica se ainda tem conte√∫do v√°lido
            if not valor_limpo or valor_limpo == '.' or valor_limpo == '-':
                return Decimal('0.00')
            
            # Remove caracteres n√£o num√©ricos (exceto ponto e sinal negativo)
            import re
            valor_limpo = re.sub(r'[^\d\.\-]', '', valor_limpo)
            
            # Verifica se o valor resultante √© v√°lido
            if not valor_limpo or valor_limpo == '.' or valor_limpo == '-':
                return Decimal('0.00')
            
            # Valida√ß√£o adicional antes de criar o Decimal
            try:
                # Testa se o valor √© um n√∫mero v√°lido
                float_test = float(valor_limpo)
                if not (float_test == float_test):  # Verifica se n√£o √© NaN
                    return Decimal('0.00')
                if float_test == float('inf') or float_test == float('-inf'):  # Verifica se n√£o √© infinito
                    return Decimal('0.00')
            except (ValueError, OverflowError):
                return Decimal('0.00')
            
            # Converte para Decimal com valida√ß√£o
            decimal_value = Decimal(valor_limpo)
            
            # Verifica se o decimal √© v√°lido
            if decimal_value.is_nan() or decimal_value.is_infinite():
                return Decimal('0.00')
                
            return decimal_value
            
        except (ValueError, TypeError, decimal.InvalidOperation) as e:
            # Log do erro para debug
            self.stdout.write(self.style.WARNING(f'Erro ao processar valor "{valor_str}": {e}. Usando valor padr√£o 0.00'))
            return Decimal('0.00')



    def processar_mensagens_wialon(self, messages_data):
        """
        Processa os dados de mensagens do Wialon e retorna um DataFrame pandas
        """

        
        if not messages_data:
            return pd.DataFrame()
        
        processed_data = []
        
        for message in messages_data:
            # Dados b√°sicos da mensagem
            base_data = {
                'timestamp': message.get('t'),
                'datetime': datetime.fromtimestamp(message.get('t', 0)) if message.get('t') else None,
                'flags': message.get('f'),
                'type': message.get('tp'),
                'index': message.get('i'),
                'driver_id': message.get('dr'),
                'location_type': message.get('lc'),
                'received_time': message.get('rt'),
            }
            
            # Dados de posi√ß√£o
            if message.get('pos'):
                pos = message.get('pos', {})
                position_data = {
                    'latitude': pos.get('y'),
                    'longitude': pos.get('x'),
                    'course': pos.get('c'),
                    'altitude': pos.get('z'),
                    'speed': pos.get('s'),
                    'satellites': pos.get('sc'),
                }
            
            else:
                position_data = {
                    'latitude': None,
                    'longitude': None,
                    'course': None,
                    'altitude': None,
                    'speed': None,
                    'satellites': None,
                }
            # Dados de par√¢metros (sensores e CAN)
            params = message.get('p', {})
            
            # Dados CAN do motor
            can_data = {
                'can_rpm': params.get('can_rpm'),
                'can_speed': params.get('can_wbspeed'),
                'can_fuel_rate': params.get('can_fuel_rate'),
                'can_distance': params.get('can_distance'),
                'can_fuel_used': params.get('can_fuel_used'),
                'can_coolant_temp': params.get('can_coolant_temp'),
                'can_acc_pedal': params.get('can_acc_pedal'),
                'can_breaks': params.get('can_breaks'),
                'can_eng_plcs': params.get('can_eng_plcs'),
                'can_hfrc': params.get('can_hfrc'),
            }
            
            # Dados de I/O
            io_data = {
                'hdop': params.get('hdop'),
                'power': params.get('power'),
                'battery': params.get('battery'),
                'odometer': params.get('odometer'),
                'gsm_signal': params.get('gsm_signal'),
                'gsm_operator': params.get('gsm_operator'),
                'movement_sens': params.get('movement_sens'),
                'current_profile': params.get('current_profile'),
                'avl_driver': params.get('avl_driver'),
            }
            
            # Sensores digitais espec√≠ficos
            digital_inputs = {
                f'io_{key}': value for key, value in params.items() 
                if key.startswith('io_') and not key in ['io_caused']
            }
            
            # Combina todos os dados
            row_data = {
                **base_data,
                **position_data,
                **can_data,
                **io_data,
                **digital_inputs,
                'io_caused': params.get('io_caused'),
            }
            
            processed_data.append(row_data)
        
        df = pd.DataFrame(processed_data)
        
        # Adiciona colunas calculadas √∫teis
        if not df.empty:
            # Converte coordenadas para links do Google Maps
            df['google_maps'] = df.apply(
                lambda row: f"https://www.google.com/maps?q={row['latitude']},{row['longitude']}" 
                if pd.notna(row['latitude']) and pd.notna(row['longitude']) else None, 
                axis=1
            )
            
            # Converte RPM e velocidade CAN para valores mais leg√≠veis
            if 'can_rpm' in df.columns:
                df['can_rpm_readable'] = df['can_rpm'] * 0.25  # Ajuste conforme necess√°rio
        
            if 'can_speed' in df.columns:
                df['can_speed_kmh'] = df['can_speed'] / 256  # Ajuste conforme necess√°rio
                
            # Converte od√¥metro para km
            if 'odometer' in df.columns:
                df['odometer_km'] = df['odometer'] / 1000
    
        return df

    def TESTE_MENSAGENS(self, tempo):
        counter = 0
        # procura apenas unidade com nome que inclua "PRO"
        #lista_unidades = Veiculo.objects.filter(empresa__nome="CPBRACELL", nm__icontains="PRO").values_list('id_wialon', flat=True)  # IDs das unidades a serem processadas
        lista_unidades = Veiculo.objects.filter(empresa__nome="Petitto").values_list('id_wialon', flat=True)[:2]  # IDs das unidades a serem processadas

        n_unidades = len(lista_unidades)
        print(f"lista_unidades: {n_unidades} unidades.")
        print(lista_unidades)


        current_time = int(time.time())
        timeFrom = current_time - (tempo * 24 * 3600)  
        timeTo = current_time  # Agora
        sid = Wialon.authenticate_with_wialon(WIALON_TOKEN_UMBR)
        if not sid:
            self.stdout.write(self.style.ERROR('Falha ao iniciar sess√£o Wialon.'))
            return
        
        #################################################
        for unidade_id in lista_unidades:
            unidade_nome = Veiculo.objects.filter(id_wialon=unidade_id).first().nm
            print(f"\nProcessando unidade ID: {colored(unidade_id, 'cyan')} - Nome: {colored(unidade_nome, 'yellow')}")

            payload = {
                "svc": "render/remove_layer",
                "params": json.dumps({
                    "layerName":"messages"
                }),
                "sid": sid
            }
            try:
                response = requests.post(Wialon.API_URL, data=payload)
                response.raise_for_status()
                result = response.json()
                print("Response 01:", result)
            except requests.RequestException as e:
                print("Error:", e)
                return

                ##################################################
            
            payload = {
                "svc": "item/update_custom_property",
                "params": json.dumps({
                    #"itemId":unidade_id,"name":"lastmsgl","value":"{\"u\":401970473,\"t\":\"data\",\"s\":0}" 
                    "itemId": unidade_id, "name": "lastmsgl", "value": f'{{"u":{unidade_id},"t":"data","s":0}}'

                }),
                "sid": sid
            }
            try:
                response = requests.post(Wialon.API_URL, data=payload)
                response.raise_for_status()
                result = response.json()
                print("Response 02:", result)
            except requests.RequestException as e:
                print("Error:", e)
                return

            ##################################################

            payload = {
                "svc": "render/create_messages_layer",
                "params": json.dumps({
                    "layerName":"messages","itemId":unidade_id,"timeFrom":timeFrom,"timeTo":timeTo,"tripDetector":0,"flags":0,"trackWidth":4,"trackColor":"speed","annotations":0,"points":1,"pointColor":"cc0000ff","arrows":1
                }),
                "sid": sid
            }
            try:
                response = requests.post(Wialon.API_URL, data=payload)
                response.raise_for_status()
                result = response.json()
                print("Response 03:", result)
                #exemplo de resultado:
                #{'name': 'messages', 'bounds': [-24.1431566, -49.45541, -23.84126, -49.31901], 'units': [{'id': 401970473, 'msgs': {'count': 14499, 'first': {'time': 1757034264, 'lat': -24.1347770691, 'lon': -49.4387168884}, 'last': {'time': 1757819133, 'lat': -23.8940887451, 'lon': -49.3677978516}}, 'mileage': 3467888.96775, 'max_speed': 81}]}}
                #recuperar a contagem de mensagens
                contagem_mensagens = result.get('units', [])[0].get('msgs', {}).get('count', 0) if result.get('units') else 0
                print(f"Contagem de mensagens para a unidade {unidade_id}:", colored(contagem_mensagens, 'green'))
            except requests.RequestException as e:
                print("Error:", e)
                return

            ###################################################
            # Sua √∫ltima requisi√ß√£o que retorna as mensagens
            payload = {
                "svc": "render/get_messages",
                "params": json.dumps({
                    "indexFrom":0,"indexTo":contagem_mensagens,"layerName":"messages","unitId":unidade_id
                }),
                "sid": sid
            }
            try:
                response = requests.post(Wialon.API_URL, data=payload)
                response.raise_for_status()
                result = response.json()
                #print("Response 04:", result)
                
                # Processa as mensagens e cria o DataFrame
                if result and isinstance(result, list):
                    df_messages = self.processar_mensagens_wialon(result)

                    #atualiza o model Viagem_eco de acordo com a unidade_id = unidade_id_wialon
                    unidade_obj = Veiculo.objects.get(id_wialon=unidade_id)
                    if unidade_obj:
                        for index, row in df_messages.iterrows():
                            unidade_obj = Veiculo.objects.get(id_wialon=unidade_id)
                            timestamp = str(row['timestamp'])
                            can_rpm_readable = float(row['can_rpm_readable']) if 'can_rpm_readable' in row and pd.notna(row['can_rpm_readable']) else 0.0
                            speed = float(row['speed']) if 'speed' in row and pd.notna(row['speed']) else 0.0
                            altitude = float(row['altitude']) if 'altitude' in row and pd.notna(row['altitude']) else 0.0

                            # Atualiza ou cria a viagem correspondente
                            Viagem_eco.objects.update_or_create(
                                unidade_id=unidade_obj.id,
                                defaults={
                                    'timestamp': timestamp,
                                    'rpm': can_rpm_readable,
                                    'speed': speed,
                                    'altitude': altitude,
                                }
                            )
                    



                    print(f"\nDataFrame criado com {len(df_messages)} mensagens:")
                    print(df_messages.head())
                    
                    # Salva em Excel para an√°lise
                    df_messages.to_excel(f'{deposito}/{unidade_nome}_{unidade_id}.xlsx', index=False)
                    print(f"DataFrame salvo em {deposito}/{unidade_nome}_{unidade_id}.xlsx")

                    # Mostra algumas estat√≠sticas
                    print(f"\nEstat√≠sticas das mensagens:")
                    print(f"Per√≠odo: {df_messages['datetime'].min()} at√© {df_messages['datetime'].max()}")
                    print(f"Velocidade m√©dia: {df_messages['speed'].mean():.2f} km/h")
                    print(f"RPM m√©dio: {df_messages['can_rpm'].mean():.0f}" if 'can_rpm' in df_messages.columns else "RPM n√£o dispon√≠vel")
                    # 
                    print(f"Consumo m√©dio de combust√≠vel: {df_messages['can_fuel_rate'].mean():.2f} l/h" if 'can_fuel_rate' in df_messages.columns else "Consumo n√£o dispon√≠vel")
                    print(f"Temperatura m√©dia do motor: {df_messages['can_coolant_temp'].mean():.2f} ¬∞C" if 'can_coolant_temp' in df_messages.columns else "Temperatura n√£o dispon√≠vel")
                    print(f"Dist√¢ncia percorrida (od√¥metro): {df_messages['odometer_km'].iloc[-1] - df_messages['odometer_km'].iloc[0]:.2f} km" if 'odometer_km' in df_messages.columns else "Od√¥metro n√£o dispon√≠vel")
                    #tempo m√©dio entre mensagens
                    print(f"Tempo m√©dio entre mensagens: {((df_messages['timestamp'].iloc[-1] - df_messages['timestamp'].iloc[0]) / len(df_messages)):.2f} segundos")
                    #print(f"Dist√¢ncia CAN: {df_messages['can_distance'].iloc[-1] - df_messages['can_distance'].iloc[0]} metros" if 'can_distance' in df_messages.columns else "Dist√¢ncia n√£o dispon√≠vel")
                    
                    counter += 1
                    print("Unidades processadas com sucesso at√© agora:", colored(counter, 'yellow'), "/", colored(n_unidades, 'green'))
                else:
                    print("Nenhuma mensagem para processar")


            except requests.RequestException as e:
                print("Error:", e)
                return df_messages
        print("Total de unidades processadas com sucesso:", colored(counter, 'blue'), "/", colored(n_unidades, 'green'))
        
        #m√©dia entre mensagens
        print(f"Tempo m√©dio entre mensagens: {((df_messages['timestamp'].iloc[-1] - df_messages['timestamp'].iloc[0]) / len(df_messages)):.2f} segundos")




        Wialon.wialon_logout(sid)



    def TESTE_MENSAGENS_02(self, tempo):
        counter = 0
        # procura apenas unidade com nome que inclua "PRO"
        #lista_unidades = Veiculo.objects.filter(empresa__nome="CPBRACELL", nm__icontains="PRO").values_list('id_wialon', flat=True)  # IDs das unidades a serem processadas
        lista_unidades = Veiculo.objects.filter(empresa__nome="Petitto").values_list('id_wialon', flat=True)  # IDs das unidades a serem processadas
        #lista todos os ve√≠culos
        #lista_unidades = Veiculo.objects.all().values_list('id_wialon', flat=True)  # IDs das unidades a serem processadas

        n_unidades = len(lista_unidades)
        print(f"lista_unidades: {n_unidades} unidades.")
        print(lista_unidades)

        current_time = int(time.time())
        timeFrom = current_time - (tempo * 24 * 3600)  
        timeTo = current_time  # Agora
        sid = Wialon.authenticate_with_wialon(WIALON_TOKEN_UMBR)
        if not sid:
            self.stdout.write(self.style.ERROR('Falha ao iniciar sess√£o Wialon.'))
            return
        
        #################################################
        for unidade_id in lista_unidades:


            unidade_nome = Veiculo.objects.filter(id_wialon=unidade_id).first().nm
            print(f"\nProcessando unidade ID: {colored(unidade_id, 'cyan')} - Nome: {colored(unidade_nome, 'yellow')}")

            payload = {
                "svc": "render/remove_layer",
                "params": json.dumps({
                    "layerName":"messages"
                }),
                "sid": sid
            }
            try:
                response = requests.post(Wialon.API_URL, data=payload)
                response.raise_for_status()
                result = response.json()
                print("Response 01:", result)
            except requests.RequestException as e:
                print("Error:", e)
                continue

            ##################################################
            
            payload = {
                "svc": "item/update_custom_property",
                "params": json.dumps({
                    "itemId": unidade_id, "name": "lastmsgl", "value": f'{{"u":{unidade_id},"t":"data","s":0}}'
                }),
                "sid": sid
            }
            try:
                response = requests.post(Wialon.API_URL, data=payload)
                response.raise_for_status()
                result = response.json()
                print("Response 02:", result)
            except requests.RequestException as e:
                print("Error:", e)
                continue

            ##################################################

            payload = {
                "svc": "render/create_messages_layer",
                "params": json.dumps({
                    "layerName":"messages","itemId":unidade_id,"timeFrom":timeFrom,"timeTo":timeTo,"tripDetector":0,"flags":0,"trackWidth":4,"trackColor":"speed","annotations":0,"points":1,"pointColor":"cc0000ff","arrows":1
                }),
                "sid": sid
            }
            try:
                response = requests.post(Wialon.API_URL, data=payload)
                response.raise_for_status()
                result = response.json()
                print("Response 03:", result)
                contagem_mensagens = result.get('units', [])[0].get('msgs', {}).get('count', 0) if result.get('units') else 0
                print(f"Contagem de mensagens para a unidade {unidade_id}:", colored(contagem_mensagens, 'green'))
            except requests.RequestException as e:
                print("Error:", e)
                continue

            ###################################################
            # Requisi√ß√£o que retorna as mensagens
            payload = {
                "svc": "render/get_messages",
                "params": json.dumps({
                    "indexFrom":0,"indexTo":contagem_mensagens,"layerName":"messages","unitId":unidade_id
                }),
                "sid": sid
            }
            try:
                response = requests.post(Wialon.API_URL, data=payload)
                response.raise_for_status()
                result = response.json()

                #print("Response 04:", result)
                # salva como json
                with open(f'{deposito}/messages_{unidade_nome}_{unidade_id}.json', 'w') as f:
                    json.dump(result, f, indent=4)

                
                # Processa as mensagens e cria o DataFrame
                if result and isinstance(result, list):
                    df_messages = self.processar_mensagens_wialon(result)

                    # CORRE√á√ÉO: Atualiza o model Viagem_eco com TODOS os registros
                    unidade_obj = Veiculo.objects.get(id_wialon=unidade_id)
                    if unidade_obj and not df_messages.empty:
                        registros_criados = 0
                        registros_atualizados = 0
                        
                        for index, row in df_messages.iterrows():
                            timestamp = str(row['timestamp'])
                            can_rpm_readable = float(row['can_rpm_readable']) if 'can_rpm_readable' in row and pd.notna(row['can_rpm_readable']) else 0.0
                            

                            # Atualiza ou cria usando timestamp como chave √∫nica tamb√©m
                            viagem_eco, created = Viagem_eco.objects.update_or_create(
                                unidade_id=unidade_obj.id,
                                timestamp=timestamp,  # IMPORTANTE: Incluir timestamp na busca
                                defaults={
                                    'rpm': can_rpm_readable,
                                    'velocidade': float(row['speed']) if 'speed' in row and pd.notna(row['speed']) else 0.0,
                                    'altitude': float(row['altitude']) if 'altitude' in row and pd.notna(row['altitude']) else 0.0,
                                }
                            )
                            
                            if created:
                                registros_criados += 1
                            else:
                                registros_atualizados += 1
                        
                        print(f"‚úÖ Unidade {unidade_nome}: {colored(registros_criados, 'green')} novos registros, {colored(registros_atualizados, 'yellow')} atualizados")

                    print(f"\nDataFrame criado com {len(df_messages)} mensagens:")
                    print(df_messages.head())
                    
                    # Salva em Excel para an√°lise
                    df_messages.to_excel(f'{deposito}/{unidade_nome}_{unidade_id}.xlsx', index=False)
                    print(f"DataFrame salvo em {deposito}/{unidade_nome}_{unidade_id}.xlsx")

                    # Mostra algumas estat√≠sticas
                    print(f"\nEstat√≠sticas das mensagens:")
                    print(f"Per√≠odo: {df_messages['datetime'].min()} at√© {df_messages['datetime'].max()}")
                    print(f"Velocidade m√©dia: {df_messages['speed'].mean():.2f} km/h")
                    print(f"RPM m√©dio: {df_messages['can_rpm'].mean():.0f}" if 'can_rpm' in df_messages.columns else "RPM n√£o dispon√≠vel")
                    print(f"Consumo m√©dio de combust√≠vel: {df_messages['can_fuel_rate'].mean():.2f} l/h" if 'can_fuel_rate' in df_messages.columns else "Consumo n√£o dispon√≠vel")
                    print(f"Temperatura m√©dia do motor: {df_messages['can_coolant_temp'].mean():.2f} ¬∞C" if 'can_coolant_temp' in df_messages.columns else "Temperatura n√£o dispon√≠vel")
                    print(f"Dist√¢ncia percorrida (od√¥metro): {df_messages['odometer_km'].iloc[-1] - df_messages['odometer_km'].iloc[0]:.2f} km" if 'odometer_km' in df_messages.columns else "Od√¥metro n√£o dispon√≠vel")
                    print(f"Tempo m√©dio entre mensagens: {((df_messages['timestamp'].iloc[-1] - df_messages['timestamp'].iloc[0]) / len(df_messages)):.2f} segundos")
                    
                    counter += 1
                    print("Unidades processadas com sucesso at√© agora:", colored(counter, 'yellow'), "/", colored(n_unidades, 'green'))
                else:
                    print("Nenhuma mensagem para processar")

            except requests.RequestException as e:
                print("Error:", e)
                continue
            except Exception as e:
                print(f"Erro ao processar unidade {unidade_id}: {e}")
                continue

        print("Total de unidades processadas com sucesso:", colored(counter, 'blue'), "/", colored(n_unidades, 'green'))

        Wialon.wialon_logout(sid)


    def TESTE_MENSAGENS_03(self, tempo):
        import threading
        import time
        
        counter = 0
        # procura apenas unidade com nome que inclua "PRO"
        #lista_unidades = Veiculo.objects.filter(empresa__nome="CPBRACELL", nm__icontains="PRO").values_list('id_wialon', flat=True)  # IDs das unidades a serem processadas
        lista_unidades = Veiculo.objects.filter(empresa__nome="Petitto").values_list('id_wialon', flat=True)  # IDs das unidades a serem processadas
        #lista_unidades = Veiculo.objects.filter(nm__icontains="1023").values_list('id_wialon', flat=True)  # IDs das unidades a serem processadas
        #lista todos os ve√≠culos
        #lista_unidades = Veiculo.objects.all().values_list('id_wialon', flat=True)  # IDs das unidades a serem processadas

        n_unidades = len(lista_unidades)
        print(f"lista_unidades: {n_unidades} unidades.")
        print(lista_unidades)

        current_time = int(time.time())
        timeFrom = current_time - (tempo * 24 * 3600)  
        timeTo = current_time  # Agora
        sid = Wialon.authenticate_with_wialon(WIALON_TOKEN_UMBR)
        if not sid:
            self.stdout.write(self.style.ERROR('Falha ao iniciar sess√£o Wialon.'))
            return
        
        # Vari√°vel de controle para parar o keep-alive
        keep_alive_active = True
        
        def keep_session_alive():
            """Thread function para manter a sess√£o ativa"""
            while keep_alive_active:
                try:
                    # Aguarda 3 minutos (180 segundos)
                    time.sleep(180)
                    
                    if not keep_alive_active:
                        break
                    
                    # Faz requisi√ß√£o para manter a sess√£o
                    payload = {
                        "svc": "avl_evts",
                        "sid": sid
                    }
                    
                    response = requests.post(Wialon.API_URL, data=payload, timeout=30)
                    response.raise_for_status()
                    
                    print(f"üîÑ {colored('Keep-alive enviado', 'blue')} - {colored(datetime.now().strftime('%H:%M:%S'), 'cyan')}")
                    
                except requests.RequestException as e:
                    print(f"‚ö†Ô∏è Erro no keep-alive: {e}")
                except Exception as e:
                    print(f"‚ö†Ô∏è Erro inesperado no keep-alive: {e}")
        
        # Inicia thread do keep-alive
        keep_alive_thread = threading.Thread(target=keep_session_alive, daemon=True)
        keep_alive_thread.start()
        
        try:
            #################################################
            for unidade_id in lista_unidades:

                unidade_nome = Veiculo.objects.filter(id_wialon=unidade_id).first().nm
                print(f"\nProcessando unidade ID: {colored(unidade_id, 'cyan')} - Nome: {colored(unidade_nome, 'yellow')}")

                payload = {
                    "svc": "render/remove_layer",
                    "params": json.dumps({
                        "layerName":"messages"
                    }),
                    "sid": sid
                }
                try:
                    response = requests.post(Wialon.API_URL, data=payload)
                    response.raise_for_status()
                    result = response.json()
                    print("Response 01:", result)
                except requests.RequestException as e:
                    print("Error:", e)
                    continue

                ##################################################
                
                payload = {
                    "svc": "item/update_custom_property",
                    "params": json.dumps({
                        "itemId": unidade_id, "name": "lastmsgl", "value": f'{{"u":{unidade_id},"t":"data","s":0}}'
                    }),
                    "sid": sid
                }
                try:
                    response = requests.post(Wialon.API_URL, data=payload)
                    response.raise_for_status()
                    result = response.json()
                    print("Response 02:", result)
                except requests.RequestException as e:
                    print("Error:", e)
                    continue

                ##################################################

                payload = {
                    "svc": "render/create_messages_layer",
                    "params": json.dumps({
                        "layerName":"messages","itemId":unidade_id,"timeFrom":timeFrom,"timeTo":timeTo,"tripDetector":0,"flags":0,"trackWidth":4,"trackColor":"speed","annotations":0,"points":1,"pointColor":"cc0000ff","arrows":1
                    }),
                    "sid": sid
                }
                try:
                    response = requests.post(Wialon.API_URL, data=payload)
                    response.raise_for_status()
                    result = response.json()
                    print("Response 03:", result)
                    contagem_mensagens = result.get('units', [])[0].get('msgs', {}).get('count', 0) if result.get('units') else 0
                    print(f"Contagem de mensagens para a unidade {unidade_id}:", colored(contagem_mensagens, 'green'))
                except requests.RequestException as e:
                    print("Error:", e)
                    continue

                ###################################################
                # Requisi√ß√£o que retorna as mensagens
                payload = {
                    "svc": "render/get_messages",
                    "params": json.dumps({
                        "indexFrom":0,"indexTo":contagem_mensagens,"layerName":"messages","unitId":unidade_id
                    }),
                    "sid": sid
                }
                try:
                    response = requests.post(Wialon.API_URL, data=payload)
                    response.raise_for_status()
                    result = response.json()

                    #print("Response 04:", result)
                    # salva como json
                    with open(f'{deposito}/messages_{unidade_nome}_{unidade_id}.json', 'w') as f:
                        json.dump(result, f, indent=4)

                    
                    # Processa as mensagens e cria o DataFrame
                    if result and isinstance(result, list):
                        df_messages = self.processar_mensagens_wialon(result)

                        # CORRE√á√ÉO: Atualiza o model Viagem_eco com TODOS os registros
                        unidade_obj = Veiculo.objects.get(id_wialon=unidade_id)
                        if unidade_obj and not df_messages.empty:
                            registros_criados = 0
                            registros_atualizados = 0
                            
                            for index, row in df_messages.iterrows():
                                timestamp = str(row['timestamp'])
                                #can_rpm_readable = float(row['can_rpm_readable']) if 'can_rpm_readable' in row and pd.notna(row['can_rpm_readable']) else 0.0
                                

                                # Atualiza ou cria usando timestamp como chave √∫nica tamb√©m
                                viagem_eco, created = Viagem_eco.objects.update_or_create(
                                    unidade_id=unidade_obj.id,
                                    timestamp=timestamp,  # IMPORTANTE: Incluir timestamp na busca
                                    defaults={
                                        'rpm': float(row['can_rpm']) if 'can_rpm' in row and pd.notna(row['can_rpm']) else 0.0,
                                        'velocidade': float(row['speed']) if 'speed' in row and pd.notna(row['speed']) else 0.0,
                                        'altitude': float(row['altitude']) if 'altitude' in row and pd.notna(row['altitude']) else 0.0,
                                    }
                                )
                                
                                if created:
                                    registros_criados += 1
                                else:
                                    registros_atualizados += 1
                            
                            print(f"‚úÖ Unidade {unidade_nome}: {colored(registros_criados, 'green')} novos registros, {colored(registros_atualizados, 'yellow')} atualizados")

                        print(f"\nDataFrame criado com {len(df_messages)} mensagens:")
                        print(df_messages.head())
                        
                        # Salva em Excel para an√°lise
                        df_messages.to_excel(f'{deposito}/{unidade_nome}_{unidade_id}.xlsx', index=False)
                        print(f"DataFrame salvo em {deposito}/{unidade_nome}_{unidade_id}.xlsx")

                        # Mostra algumas estat√≠sticas
                        print(f"\nEstat√≠sticas das mensagens:")
                        print(f"Per√≠odo: {df_messages['datetime'].min()} at√© {df_messages['datetime'].max()}")
                        print(f"Velocidade m√©dia: {df_messages['speed'].mean():.2f} km/h")
                        print(f"RPM m√©dio: {df_messages['can_rpm'].mean():.0f}" if 'can_rpm' in df_messages.columns else "RPM n√£o dispon√≠vel")
                        print(f"Consumo m√©dio de combust√≠vel: {df_messages['can_fuel_rate'].mean():.2f} l/h" if 'can_fuel_rate' in df_messages.columns else "Consumo n√£o dispon√≠vel")
                        print(f"Temperatura m√©dia do motor: {df_messages['can_coolant_temp'].mean():.2f} ¬∞C" if 'can_coolant_temp' in df_messages.columns else "Temperatura n√£o dispon√≠vel")
                        print(f"Dist√¢ncia percorrida (od√¥metro): {df_messages['odometer_km'].iloc[-1] - df_messages['odometer_km'].iloc[0]:.2f} km" if 'odometer_km' in df_messages.columns else "Od√¥metro n√£o dispon√≠vel")
                        print(f"Tempo m√©dio entre mensagens: {((df_messages['timestamp'].iloc[-1] - df_messages['timestamp'].iloc[0]) / len(df_messages)):.2f} segundos")
                        
                        counter += 1
                        print("Unidades processadas com sucesso at√© agora:", colored(counter, 'yellow'), "/", colored(n_unidades, 'green'))
                    else:
                        print("Nenhuma mensagem para processar")

                except requests.RequestException as e:
                    print("Error:", e)
                    continue
                except Exception as e:
                    print(f"Erro ao processar unidade {unidade_id}: {e}")
                    continue

            print("Total de unidades processadas com sucesso:", colored(counter, 'blue'), "/", colored(n_unidades, 'green'))

        finally:
            # Para o keep-alive e aguarda a thread finalizar
            keep_alive_active = False
            if keep_alive_thread.is_alive():
                keep_alive_thread.join(timeout=5)
            
            print(f"üîÑ {colored('Keep-alive finalizado', 'blue')}")
            
            Wialon.wialon_logout(sid)




    def ESTUDO_01(self):
        """
        An√°lise estat√≠stica completa dos dados de Viagem_eco
        - Detec√ß√£o de outliers
        - An√°lise de padr√µes
        - Estat√≠sticas descritivas
        - Correla√ß√µes entre vari√°veis
        - An√°lise temporal
        """
        print(colored("="*50, 'cyan'))
        print(colored("INICIANDO ESTUDO ESTAT√çSTICO COMPLETO", 'yellow'))
        print(colored("="*50, 'cyan'))
        
        # Importa√ß√µes necess√°rias
        import numpy as np
        import matplotlib.pyplot as plt
        import seaborn as sns
        from scipy import stats
        from sklearn.preprocessing import StandardScaler
        from sklearn.cluster import KMeans
        from sklearn.ensemble import IsolationForest
        import warnings
        warnings.filterwarnings('ignore')
        
        # Configurar matplotlib para n√£o mostrar gr√°ficos
        plt.ioff()
        
        try:
            # ============= COLETA DE DADOS =============
            print(f"üìä {colored('Coletando dados do banco...', 'blue')}")
            
            # Buscar todos os dados de Viagem_eco
            viagens_eco = Viagem_eco.objects.all().select_related('unidade')
            
            if not viagens_eco.exists():
                print(f"‚ùå {colored('Nenhum dado encontrado na tabela Viagem_eco', 'red')}")
                return
            
            # Converter para DataFrame
            data_list = []
            for viagem in viagens_eco:
                try:
                    # Converter timestamp unix para datetime
                    timestamp_int = int(viagem.timestamp)
                    dt = datetime.fromtimestamp(timestamp_int)
                    
                    # Filtrar apenas dados com RPM v√°lidos (acima de 300)
                    if viagem.rpm and float(viagem.rpm) >= 300:
                        data_list.append({
                            'timestamp': timestamp_int,
                            'datetime': dt,
                            'unidade_id': viagem.unidade.id,
                            'unidade_nome': viagem.unidade.nm,
                            'empresa': viagem.unidade.empresa.nome if viagem.unidade.empresa else 'N/A',
                            'rpm': float(viagem.rpm),
                            'velocidade': float(viagem.velocidade) if viagem.velocidade else 0.0,
                            'altitude': float(viagem.altitude) if viagem.altitude else 0.0,
                            'hora': dt.hour,
                            'dia_semana': dt.weekday(),
                            'mes': dt.month,
                            'ano': dt.year,
                        })
                except (ValueError, TypeError, OSError):
                    continue
            
            if not data_list:
                print(f"‚ùå {colored('Nenhum dado v√°lido encontrado', 'red')}")
                return
            
            df = pd.DataFrame(data_list)
            print(f"‚úÖ {colored(f'Dados coletados: {len(df)} registros de {df.unidade_id.nunique()} unidades', 'green')}")
            
            # ============= AN√ÅLISE DESCRITIVA B√ÅSICA =============
            print(f"\nüìà {colored('Gerando estat√≠sticas descritivas...', 'blue')}")
            
            stats_desc = df[['rpm', 'velocidade', 'altitude']].describe()
            
            # Fun√ß√£o para calcular MAD (Mean Absolute Deviation) manualmente
            def calculate_mad(series):
                """Calcula o desvio absoluto mediano"""
                median = series.median()
                return (series - median).abs().median()
            
            # Adicionar estat√≠sticas extras
            stats_extras = pd.DataFrame({
                'rpm': [
                    df['rpm'].var(),
                    df['rpm'].skew(),
                    df['rpm'].kurtosis(),
                    calculate_mad(df['rpm'])  # CORRE√á√ÉO: Usar fun√ß√£o personalizada
                ],
                'velocidade': [
                    df['velocidade'].var(),
                    df['velocidade'].skew(),
                    df['velocidade'].kurtosis(),
                    calculate_mad(df['velocidade'])  # CORRE√á√ÉO: Usar fun√ß√£o personalizada
                ],
                'altitude': [
                    df['altitude'].var(),
                    df['altitude'].skew(),
                    df['altitude'].kurtosis(),
                    calculate_mad(df['altitude'])  # CORRE√á√ÉO: Usar fun√ß√£o personalizada
                ]
            }, index=['variancia', 'assimetria', 'curtose', 'desvio_abs_mediano'])
            
            stats_completas = pd.concat([stats_desc, stats_extras])
            
            # Salvar estat√≠sticas descritivas
            stats_completas.to_excel(f'{deposito}/estudo_01_estatisticas_descritivas.xlsx')
            print(f"üíæ Estat√≠sticas descritivas salvas em: estudo_01_estatisticas_descritivas.xlsx")
            
            # ============= DETEC√á√ÉO DE OUTLIERS =============
            print(f"\nüîç {colored('Detectando outliers...', 'blue')}")
            
            # M√©todo 1: Z-Score
            z_scores = np.abs(stats.zscore(df[['rpm', 'velocidade', 'altitude']]))
            outliers_zscore = df[(z_scores > 3).any(axis=1)].copy()
            
            # M√©todo 2: IQR (Interquartile Range)
            outliers_iqr = pd.DataFrame()
            for coluna in ['rpm', 'velocidade', 'altitude']:
                Q1 = df[coluna].quantile(0.25)
                Q3 = df[coluna].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                outliers_col = df[(df[coluna] < lower_bound) | (df[coluna] > upper_bound)]
                outliers_iqr = pd.concat([outliers_iqr, outliers_col]).drop_duplicates()
            
            # M√©todo 3: Isolation Forest
            iso_forest = IsolationForest(contamination=0.1, random_state=42)
            outliers_iso = iso_forest.fit_predict(df[['rpm', 'velocidade', 'altitude']])
            outliers_isolation = df[outliers_iso == -1].copy()
            
            # Combinar todos os outliers
            all_outliers = pd.concat([outliers_zscore, outliers_iqr, outliers_isolation]).drop_duplicates()
            all_outliers['metodo_deteccao'] = 'M√∫ltiplos'
            
            print(f"üéØ Outliers detectados:")
            print(f"   - Z-Score (>3): {len(outliers_zscore)} registros")
            print(f"   - IQR: {len(outliers_iqr)} registros")
            print(f"   - Isolation Forest: {len(outliers_isolation)} registros")
            print(f"   - Total √∫nicos: {len(all_outliers)} registros")
            
            # Salvar outliers
            all_outliers.to_excel(f'{deposito}/estudo_01_outliers_detectados.xlsx', index=False)
            print(f"üíæ Outliers salvos em: estudo_01_outliers_detectados.xlsx")
            
            # ============= AN√ÅLISE POR UNIDADE =============
            print(f"\nüöõ {colored('Analisando padr√µes por unidade...', 'blue')}")
            
            stats_por_unidade = df.groupby(['unidade_nome', 'empresa']).agg({
                'rpm': ['count', 'mean', 'std', 'min', 'max'],
                'velocidade': ['mean', 'std', 'min', 'max'],
                'altitude': ['mean', 'std', 'min', 'max'],
            }).round(2)
            
            # Achatar colunas multi-n√≠vel
            stats_por_unidade.columns = ['_'.join(col).strip() for col in stats_por_unidade.columns]
            stats_por_unidade = stats_por_unidade.reset_index()
            
            # Adicionar classifica√ß√µes
            stats_por_unidade['rpm_categoria'] = pd.cut(
                stats_por_unidade['rpm_mean'], 
                bins=[0, 800, 1300, 2000, float('inf')], 
                labels=['Baixo', 'Econ√¥mico', 'Normal', 'Alto']
            )
            
            stats_por_unidade['velocidade_categoria'] = pd.cut(
                stats_por_unidade['velocidade_mean'], 
                bins=[0, 40, 60, 80, float('inf')], 
                labels=['Baixa', 'Moderada', 'Alta', 'Muito Alta']
            )
            
            # Salvar an√°lise por unidade
            stats_por_unidade.to_excel(f'{deposito}/estudo_01_analise_por_unidade.xlsx', index=False)
            print(f"üíæ An√°lise por unidade salva em: estudo_01_analise_por_unidade.xlsx")
            
            # ============= AN√ÅLISE TEMPORAL =============
            print(f"\n‚è∞ {colored('Analisando padr√µes temporais...', 'blue')}")
            
            # Por hora do dia
            analise_hora = df.groupby('hora').agg({
                'rpm': ['mean', 'std', 'count'],
                'velocidade': ['mean', 'std'],
                'altitude': ['mean', 'std']
            }).round(2)
            analise_hora.columns = ['_'.join(col).strip() for col in analise_hora.columns]
            analise_hora = analise_hora.reset_index()
            
            # Por dia da semana
            dias_semana = ['Segunda', 'Ter√ßa', 'Quarta', 'Quinta', 'Sexta', 'S√°bado', 'Domingo']
            analise_dia_semana = df.groupby('dia_semana').agg({
                'rpm': ['mean', 'std', 'count'],
                'velocidade': ['mean', 'std'],
                'altitude': ['mean', 'std']
            }).round(2)
            analise_dia_semana.columns = ['_'.join(col).strip() for col in analise_dia_semana.columns]
            analise_dia_semana = analise_dia_semana.reset_index()
            analise_dia_semana['dia_nome'] = analise_dia_semana['dia_semana'].map(lambda x: dias_semana[x])
            
            # Por m√™s
            analise_mes = df.groupby('mes').agg({
                'rpm': ['mean', 'std', 'count'],
                'velocidade': ['mean', 'std'],
                'altitude': ['mean', 'std']
            }).round(2)
            analise_mes.columns = ['_'.join(col).strip() for col in analise_mes.columns]
            analise_mes = analise_mes.reset_index()
            
            # Salvar an√°lises temporais
            with pd.ExcelWriter(f'{deposito}/estudo_01_analise_temporal.xlsx') as writer:
                analise_hora.to_excel(writer, sheet_name='Por_Hora', index=False)
                analise_dia_semana.to_excel(writer, sheet_name='Por_Dia_Semana', index=False)
                analise_mes.to_excel(writer, sheet_name='Por_Mes', index=False)
            
            print(f"üíæ An√°lise temporal salva em: estudo_01_analise_temporal.xlsx")
            
            # ============= AN√ÅLISE DE CORRELA√á√ïES =============
            print(f"\nüîó {colored('Analisando correla√ß√µes...', 'blue')}")
            
            # Matriz de correla√ß√£o
            correlation_matrix = df[['rpm', 'velocidade', 'altitude', 'hora', 'dia_semana']].corr()
            
            # Salvar matriz de correla√ß√£o
            correlation_matrix.to_excel(f'{deposito}/estudo_01_matriz_correlacao.xlsx')
            print(f"üíæ Matriz de correla√ß√£o salva em: estudo_01_matriz_correlacao.xlsx")
            
            # ============= CLUSTERING AN√ÅLISE =============
            print(f"\nüéØ {colored('Realizando an√°lise de clusters...', 'blue')}")
            
            # Preparar dados para clustering
            features_clustering = df[['rpm', 'velocidade', 'altitude']].copy()
            
            # Normalizar dados
            scaler = StandardScaler()
            features_normalized = scaler.fit_transform(features_clustering)
            
            # K-Means com diferentes n√∫meros de clusters
            inertias = []
            K_range = range(2, 11)
            
            for k in K_range:
                kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
                kmeans.fit(features_normalized)
                inertias.append(kmeans.inertia_)
            
            # Escolher k=5 para an√°lise detalhada
            kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)
            clusters = kmeans.fit_predict(features_normalized)
            
            # Adicionar clusters ao DataFrame
            df_clusters = df.copy()
            df_clusters['cluster'] = clusters
            
            # Analisar caracter√≠sticas de cada cluster
            cluster_analysis = df_clusters.groupby('cluster').agg({
                'rpm': ['mean', 'std', 'min', 'max', 'count'],
                'velocidade': ['mean', 'std', 'min', 'max'],
                'altitude': ['mean', 'std', 'min', 'max'],
                'unidade_id': 'nunique'
            }).round(2)
            
            cluster_analysis.columns = ['_'.join(col).strip() for col in cluster_analysis.columns]
            cluster_analysis = cluster_analysis.reset_index()
            
            # Adicionar interpreta√ß√£o dos clusters
            def interpretar_cluster(row):
                rpm_mean = row['rpm_mean']
                vel_mean = row['velocidade_mean']
                
                if rpm_mean < 800:
                    rpm_cat = "Marcha Lenta"
                elif rpm_mean < 1300:
                    rpm_cat = "Econ√¥mico"
                elif rpm_mean < 2000:
                    rpm_cat = "Normal"
                else:
                    rpm_cat = "Alto"
                
                if vel_mean < 20:
                    vel_cat = "Parado/Lento"
                elif vel_mean < 50:
                    vel_cat = "Urbano"
                elif vel_mean < 80:
                    vel_cat = "Rodovi√°rio"
                else:
                    vel_cat = "Alto"
                
                return f"{rpm_cat} + {vel_cat}"
            
            cluster_analysis['interpretacao'] = cluster_analysis.apply(interpretar_cluster, axis=1)
            
            # Salvar an√°lise de clusters
            cluster_analysis.to_excel(f'{deposito}/estudo_01_analise_clusters.xlsx', index=False)
            print(f"üíæ An√°lise de clusters salva em: estudo_01_analise_clusters.xlsx")
            
            # ============= DETEC√á√ÉO DE PADR√ïES ESPEC√çFICOS =============
            print(f"\nüîç {colored('Detectando padr√µes espec√≠ficos...', 'blue')}")
            
            padroes_especificos = {}
            
            # 1. Padr√£o de marcha lenta excessiva
            marcha_lenta = df[df['rpm'] < 500]
            padroes_especificos['marcha_lenta_excessiva'] = {
                'total_registros': len(marcha_lenta),
                'unidades_afetadas': marcha_lenta['unidade_nome'].nunique(),
                'percentual_total': round(len(marcha_lenta) / len(df) * 100, 2)
            }
            
            # 2. Padr√£o de RPM muito alto (zona vermelha)
            rpm_alto = df[df['rpm'] > 2300]
            padroes_especificos['rpm_zona_vermelha'] = {
                'total_registros': len(rpm_alto),
                'unidades_afetadas': rpm_alto['unidade_nome'].nunique(),
                'percentual_total': round(len(rpm_alto) / len(df) * 100, 2)
            }
            
            # 3. Padr√£o de velocidade alta com RPM baixo (poss√≠vel descida)
            vel_alta_rpm_baixo = df[(df['velocidade'] > 60) & (df['rpm'] < 1000)]
            padroes_especificos['velocidade_alta_rpm_baixo'] = {
                'total_registros': len(vel_alta_rpm_baixo),
                'unidades_afetadas': vel_alta_rpm_baixo['unidade_nome'].nunique(),
                'percentual_total': round(len(vel_alta_rpm_baixo) / len(df) * 100, 2)
            }
            
            # 4. Padr√£o noturno (22h √†s 6h)
            periodo_noturno = df[(df['hora'] >= 22) | (df['hora'] <= 6)]
            padroes_especificos['atividade_noturna'] = {
                'total_registros': len(periodo_noturno),
                'unidades_afetadas': periodo_noturno['unidade_nome'].nunique(),
                'percentual_total': round(len(periodo_noturno) / len(df) * 100, 2)
            }
            
            # 5. Efici√™ncia por faixa de RPM
            df['faixa_rpm'] = pd.cut(
                df['rpm'], 
                bins=[0, 799, 1300, 2300, float('inf')], 
                labels=['Azul (350-799)', 'Verde (800-1300)', 'Amarela (1301-2300)', 'Vermelha (2301+)']
            )
            
            distribuicao_rpm = df['faixa_rpm'].value_counts().to_dict()
            padroes_especificos['distribuicao_faixas_rpm'] = distribuicao_rpm
            
            # Converter para DataFrame e salvar
            padroes_df = pd.DataFrame([padroes_especificos]).T
            padroes_df.to_excel(f'{deposito}/estudo_01_padroes_especificos.xlsx')
            print(f"üíæ Padr√µes espec√≠ficos salvos em: estudo_01_padroes_especificos.xlsx")
            
            # ============= GERAR GR√ÅFICOS =============
            print(f"\nüìä {colored('Gerando gr√°ficos de an√°lise...', 'blue')}")
            
            # Configurar estilo dos gr√°ficos
            plt.style.use('default')
            sns.set_palette("husl")
            
            # 1. Distribui√ß√µes das vari√°veis principais
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('Distribui√ß√µes das Vari√°veis Principais', fontsize=16, fontweight='bold')
            
            # RPM
            axes[0, 0].hist(df['rpm'], bins=50, alpha=0.7, color='blue')
            axes[0, 0].set_title('Distribui√ß√£o RPM')
            axes[0, 0].set_xlabel('RPM')
            axes[0, 0].set_ylabel('Frequ√™ncia')
            axes[0, 0].axvline(df['rpm'].mean(), color='red', linestyle='--', label=f'M√©dia: {df["rpm"].mean():.0f}')
            axes[0, 0].legend()
            
            # Velocidade
            axes[0, 1].hist(df['velocidade'], bins=50, alpha=0.7, color='green')
            axes[0, 1].set_title('Distribui√ß√£o Velocidade')
            axes[0, 1].set_xlabel('Velocidade (km/h)')
            axes[0, 1].set_ylabel('Frequ√™ncia')
            axes[0, 1].axvline(df['velocidade'].mean(), color='red', linestyle='--', label=f'M√©dia: {df["velocidade"].mean():.1f}')
            axes[0, 1].legend()
            
            # Altitude
            axes[1, 0].hist(df['altitude'], bins=50, alpha=0.7, color='orange')
            axes[1, 0].set_title('Distribui√ß√£o Altitude')
            axes[1, 0].set_xlabel('Altitude (m)')
            axes[1, 0].set_ylabel('Frequ√™ncia')
            axes[1, 0].axvline(df['altitude'].mean(), color='red', linestyle='--', label=f'M√©dia: {df["altitude"].mean():.1f}')
            axes[1, 0].legend()
            
            # Distribui√ß√£o por faixa de RPM
            faixa_counts = df['faixa_rpm'].value_counts()
            axes[1, 1].pie(faixa_counts.values, labels=faixa_counts.index, autopct='%1.1f%%')
            axes[1, 1].set_title('Distribui√ß√£o por Faixa de RPM')
            
            plt.tight_layout()
            plt.savefig(f'{deposito}/estudo_01_distribuicoes.png', dpi=300, bbox_inches='tight')
            plt.close()
            
            # 2. An√°lise temporal
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('An√°lise Temporal dos Dados', fontsize=16, fontweight='bold')
            
            # RPM por hora
            hourly_rpm = df.groupby('hora')['rpm'].mean()
            axes[0, 0].plot(hourly_rpm.index, hourly_rpm.values, marker='o', linewidth=2)
            axes[0, 0].set_title('RPM M√©dio por Hora do Dia')
            axes[0, 0].set_xlabel('Hora')
            axes[0, 0].set_ylabel('RPM M√©dio')
            axes[0, 0].grid(True, alpha=0.3)
            
            # Velocidade por hora
            hourly_vel = df.groupby('hora')['velocidade'].mean()
            axes[0, 1].plot(hourly_vel.index, hourly_vel.values, marker='s', color='green', linewidth=2)
            axes[0, 1].set_title('Velocidade M√©dia por Hora do Dia')
            axes[0, 1].set_xlabel('Hora')
            axes[0, 1].set_ylabel('Velocidade M√©dia (km/h)')
            axes[0, 1].grid(True, alpha=0.3)
            
            # RPM por dia da semana
            daily_rpm = df.groupby('dia_semana')['rpm'].mean()
            dias_nome = ['Seg', 'Ter', 'Qua', 'Qui', 'Sex', 'S√°b', 'Dom']
            axes[1, 0].bar(range(7), daily_rpm.values, color='purple', alpha=0.7)
            axes[1, 0].set_title('RPM M√©dio por Dia da Semana')
            axes[1, 0].set_xlabel('Dia da Semana')
            axes[1, 0].set_ylabel('RPM M√©dio')
            axes[1, 0].set_xticks(range(7))
            axes[1, 0].set_xticklabels(dias_nome)
            
            # Atividade por m√™s
            monthly_count = df.groupby('mes').size()
            axes[1, 1].bar(monthly_count.index, monthly_count.values, color='red', alpha=0.7)
            axes[1, 1].set_title('Atividade por M√™s')
            axes[1, 1].set_xlabel('M√™s')
            axes[1, 1].set_ylabel('N√∫mero de Registros')
            
            plt.tight_layout()
            plt.savefig(f'{deposito}/estudo_01_analise_temporal.png', dpi=300, bbox_inches='tight')
            plt.close()
            
            # 3. Scatter plots e correla√ß√µes
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('An√°lise de Correla√ß√µes', fontsize=16, fontweight='bold')
            
            # RPM vs Velocidade
            axes[0, 0].scatter(df['rpm'], df['velocidade'], alpha=0.1, s=1)
            axes[0, 0].set_title('RPM vs Velocidade')
            axes[0, 0].set_xlabel('RPM')
            axes[0, 0].set_ylabel('Velocidade (km/h)')
            
            # RPM vs Altitude
            axes[0, 1].scatter(df['rpm'], df['altitude'], alpha=0.1, s=1, color='green')
            axes[0, 1].set_title('RPM vs Altitude')
            axes[0, 1].set_xlabel('RPM')
            axes[0, 1].set_ylabel('Altitude (m)')
            
            # Velocidade vs Altitude
            axes[1, 0].scatter(df['velocidade'], df['altitude'], alpha=0.1, s=1, color='red')
            axes[1, 0].set_title('Velocidade vs Altitude')
            axes[1, 0].set_xlabel('Velocidade (km/h)')
            axes[1, 0].set_ylabel('Altitude (m)')
            
            # Heatmap de correla√ß√£o
            corr_data = df[['rpm', 'velocidade', 'altitude', 'hora']].corr()
            im = axes[1, 1].imshow(corr_data, cmap='coolwarm', aspect='auto')
            axes[1, 1].set_title('Matriz de Correla√ß√£o')
            axes[1, 1].set_xticks(range(len(corr_data.columns)))
            axes[1, 1].set_yticks(range(len(corr_data.columns)))
            axes[1, 1].set_xticklabels(corr_data.columns)
            axes[1, 1].set_yticklabels(corr_data.columns)
            
            plt.tight_layout()
            plt.savefig(f'{deposito}/estudo_01_correlacoes.png', dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"üíæ Gr√°ficos salvos em:")
            print(f"   - estudo_01_distribuicoes.png")
            print(f"   - estudo_01_analise_temporal.png")
            print(f"   - estudo_01_correlacoes.png")
            
            # ============= RELAT√ìRIO RESUMO =============
            print(f"\nüìã {colored('Gerando relat√≥rio resumo...', 'blue')}")
            
            resumo = {
                'data_analise': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'total_registros': len(df),
                'total_unidades': df['unidade_id'].nunique(),
                'total_empresas': df['empresa'].nunique(),
                'periodo_dados': f"{df['datetime'].min()} at√© {df['datetime'].max()}",
                'rpm_medio_geral': round(df['rpm'].mean(), 2),
                'rpm_desvio_padrao': round(df['rpm'].std(), 2),
                'velocidade_media_geral': round(df['velocidade'].mean(), 2),
                'altitude_media_geral': round(df['altitude'].mean(), 2),
                'outliers_detectados': len(all_outliers),
                'percentual_outliers': round(len(all_outliers) / len(df) * 100, 2),
                'distribuicao_faixas_rpm': dict(df['faixa_rpm'].value_counts()),
                'padroes_identificados': len(padroes_especificos),
            }
            
            # Salvar resumo
            resumo_df = pd.DataFrame([resumo]).T
            resumo_df.columns = ['Valor']
            resumo_df.to_excel(f'{deposito}/estudo_01_resumo_executivo.xlsx')
            
            # ============= RESULTADO FINAL =============
            print(colored("="*50, 'cyan'))
            print(colored("ESTUDO ESTAT√çSTICO CONCLU√çDO COM SUCESSO!", 'green'))
            print(colored("="*50, 'cyan'))
            
            print(f"üìä {colored('RESUMO DOS RESULTADOS:', 'yellow')}")
            print(f"   ‚Ä¢ Total de registros analisados: {colored(f'{len(df):,}', 'green')}")
            print(f"   ‚Ä¢ Unidades analisadas: {colored(df['unidade_id'].nunique(), 'green')}")
            print(f"   ‚Ä¢ Empresas envolvidas: {colored(df['empresa'].nunique(), 'green')}")
            print(f"   ‚Ä¢ Outliers detectados: {colored(f'{len(all_outliers):,}', 'red')} ({colored(f'{len(all_outliers)/len(df)*100:.1f}%', 'red')})")
            print(f"   ‚Ä¢ RPM m√©dio da frota: {colored(f'{df.rpm.mean():.0f}', 'blue')} RPM")
            print(f"   ‚Ä¢ Velocidade m√©dia: {colored(f'{df.velocidade.mean():.1f}', 'blue')} km/h")
            
            print(f"\nüìÅ {colored('ARQUIVOS GERADOS:', 'yellow')}")
            print(f"   ‚Ä¢ estudo_01_estatisticas_descritivas.xlsx")
            print(f"   ‚Ä¢ estudo_01_outliers_detectados.xlsx")
            print(f"   ‚Ä¢ estudo_01_analise_por_unidade.xlsx")
            print(f"   ‚Ä¢ estudo_01_analise_temporal.xlsx")
            print(f"   ‚Ä¢ estudo_01_matriz_correlacao.xlsx")
            print(f"   ‚Ä¢ estudo_01_analise_clusters.xlsx")
            print(f"   ‚Ä¢ estudo_01_padroes_especificos.xlsx")
            print(f"   ‚Ä¢ estudo_01_resumo_executivo.xlsx")
            print(f"   ‚Ä¢ estudo_01_distribuicoes.png")
            print(f"   ‚Ä¢ estudo_01_analise_temporal.png")
            print(f"   ‚Ä¢ estudo_01_correlacoes.png")
            
            print(f"\nüéØ {colored('PRINCIPAIS INSIGHTS:', 'yellow')}")
            print(f"   ‚Ä¢ Faixa de RPM mais comum: {colored(df['faixa_rpm'].mode().iloc[0], 'green')}")
            print(f"   ‚Ä¢ Hor√°rio de maior atividade: {colored(f'{hourly_rpm.idxmax()}h', 'green')}")
            print(f"   ‚Ä¢ Correla√ß√£o RPM-Velocidade: {colored(f'{df.rpm.corr(df.velocidade):.3f}', 'blue')}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå {colored(f'Erro durante a an√°lise: {str(e)}', 'red')}")
            import traceback
            traceback.print_exc()
            return False

    def ESTUDO_02(self):
        """
        An√°lise estat√≠stica completa dos dados de Viagem_eco
        - Detec√ß√£o de outliers
        - An√°lise de padr√µes
        - Estat√≠sticas descritivas
        - Correla√ß√µes entre vari√°veis
        - An√°lise temporal
        - An√°lise por marca e modelo
        """
        print(colored("="*50, 'cyan'))
        print(colored("INICIANDO ESTUDO ESTAT√çSTICO COMPLETO", 'yellow'))
        print(colored("="*50, 'cyan'))
        
        # Importa√ß√µes necess√°rias
        import numpy as np
        import matplotlib.pyplot as plt
        import seaborn as sns
        from scipy import stats
        from sklearn.preprocessing import StandardScaler
        from sklearn.cluster import KMeans
        from sklearn.ensemble import IsolationForest
        import warnings
        warnings.filterwarnings('ignore')
        
        # Configurar matplotlib para n√£o mostrar gr√°ficos
        plt.ioff()
        
        try:
            # ============= COLETA DE DADOS =============
            print(f"üìä {colored('Coletando dados do banco...', 'blue')}")
            
            # Buscar todos os dados de Viagem_eco com informa√ß√µes dos ve√≠culos
            viagens_eco = Viagem_eco.objects.all().select_related('unidade__empresa')
            
            if not viagens_eco.exists():
                print(f"‚ùå {colored('Nenhum dado encontrado na tabela Viagem_eco', 'red')}")
                return
            
            # Converter para DataFrame
            data_list = []
            for viagem in viagens_eco:
                try:
                    # Converter timestamp unix para datetime
                    timestamp_int = int(viagem.timestamp)
                    dt = datetime.fromtimestamp(timestamp_int)
                    
                    # Filtrar apenas dados com RPM v√°lidos (acima de 300)
                    if viagem.rpm and float(viagem.rpm) >= 300:
                        data_list.append({
                            'timestamp': timestamp_int,
                            'datetime': dt,
                            'unidade_id': viagem.unidade.id,
                            'unidade_nome': viagem.unidade.nm,
                            'empresa': viagem.unidade.empresa.nome if viagem.unidade.empresa else 'N/A',
                            'marca': viagem.unidade.marca if hasattr(viagem.unidade, 'marca') and viagem.unidade.marca else 'N/I',
                            'modelo': viagem.unidade.modelo if hasattr(viagem.unidade, 'modelo') and viagem.unidade.modelo else 'N/I',
                            'cor': viagem.unidade.cor if hasattr(viagem.unidade, 'cor') and viagem.unidade.cor else 'N/I',
                            'placa': viagem.unidade.placa if hasattr(viagem.unidade, 'placa') and viagem.unidade.placa else 'N/I',
                            'rpm': float(viagem.rpm),
                            'velocidade': float(viagem.velocidade) if viagem.velocidade else 0.0,
                            'altitude': float(viagem.altitude) if viagem.altitude else 0.0,
                            'hora': dt.hour,
                            'dia_semana': dt.weekday(),
                            'mes': dt.month,
                            'ano': dt.year,
                        })
                except (ValueError, TypeError, OSError):
                    continue
            
            if not data_list:
                print(f"‚ùå {colored('Nenhum dado v√°lido encontrado', 'red')}")
                return
            
            df = pd.DataFrame(data_list)
            print(f"‚úÖ {colored(f'Dados coletados: {len(df)} registros de {df.unidade_id.nunique()} unidades', 'green')}")
            print(f"üìã {colored(f'Marcas encontradas: {df.marca.nunique()} ({list(df.marca.unique())})', 'blue')}")
            print(f"üöó {colored(f'Modelos encontrados: {df.modelo.nunique()}', 'blue')}")
            
            # ============= AN√ÅLISE DESCRITIVA B√ÅSICA =============
            print(f"\nüìà {colored('Gerando estat√≠sticas descritivas...', 'blue')}")
            
            stats_desc = df[['rpm', 'velocidade', 'altitude']].describe()
            
            # Fun√ß√£o para calcular MAD (Mean Absolute Deviation) manualmente
            def calculate_mad(series):
                """Calcula o desvio absoluto mediano"""
                median = series.median()
                return (series - median).abs().median()
            
            # Adicionar estat√≠sticas extras
            stats_extras = pd.DataFrame({
                'rpm': [
                    df['rpm'].var(),
                    df['rpm'].skew(),
                    df['rpm'].kurtosis(),
                    calculate_mad(df['rpm'])
                ],
                'velocidade': [
                    df['velocidade'].var(),
                    df['velocidade'].skew(),
                    df['velocidade'].kurtosis(),
                    calculate_mad(df['velocidade'])
                ],
                'altitude': [
                    df['altitude'].var(),
                    df['altitude'].skew(),
                    df['altitude'].kurtosis(),
                    calculate_mad(df['altitude'])
                ]
            }, index=['variancia', 'assimetria', 'curtose', 'desvio_abs_mediano'])
            
            stats_completas = pd.concat([stats_desc, stats_extras])
            
            # Salvar estat√≠sticas descritivas
            stats_completas.to_excel(f'{deposito}/estudo_01_estatisticas_descritivas.xlsx')
            print(f"üíæ Estat√≠sticas descritivas salvas em: estudo_01_estatisticas_descritivas.xlsx")
            
            # ============= DETEC√á√ÉO DE OUTLIERS =============
            print(f"\nüîç {colored('Detectando outliers...', 'blue')}")
            
            # M√©todo 1: Z-Score
            z_scores = np.abs(stats.zscore(df[['rpm', 'velocidade', 'altitude']]))
            outliers_zscore = df[(z_scores > 3).any(axis=1)].copy()
            
            # M√©todo 2: IQR (Interquartile Range)
            outliers_iqr = pd.DataFrame()
            for coluna in ['rpm', 'velocidade', 'altitude']:
                Q1 = df[coluna].quantile(0.25)
                Q3 = df[coluna].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                outliers_col = df[(df[coluna] < lower_bound) | (df[coluna] > upper_bound)]
                outliers_iqr = pd.concat([outliers_iqr, outliers_col]).drop_duplicates()
            
            # M√©todo 3: Isolation Forest
            iso_forest = IsolationForest(contamination=0.1, random_state=42)
            outliers_iso = iso_forest.fit_predict(df[['rpm', 'velocidade', 'altitude']])
            outliers_isolation = df[outliers_iso == -1].copy()
            
            # Combinar todos os outliers
            all_outliers = pd.concat([outliers_zscore, outliers_iqr, outliers_isolation]).drop_duplicates()
            all_outliers['metodo_deteccao'] = 'M√∫ltiplos'
            
            print(f"üéØ Outliers detectados:")
            print(f"   - Z-Score (>3): {len(outliers_zscore)} registros")
            print(f"   - IQR: {len(outliers_iqr)} registros")
            print(f"   - Isolation Forest: {len(outliers_isolation)} registros")
            print(f"   - Total √∫nicos: {len(all_outliers)} registros")
            
            # Salvar outliers
            all_outliers.to_excel(f'{deposito}/estudo_01_outliers_detectados.xlsx', index=False)
            print(f"üíæ Outliers salvos em: estudo_01_outliers_detectados.xlsx")
            
            # ============= AN√ÅLISE POR UNIDADE =============
            print(f"\nüöõ {colored('Analisando padr√µes por unidade...', 'blue')}")
            
            stats_por_unidade = df.groupby(['unidade_nome', 'empresa', 'marca', 'modelo', 'placa']).agg({
                'rpm': ['count', 'mean', 'std', 'min', 'max'],
                'velocidade': ['mean', 'std', 'min', 'max'],
                'altitude': ['mean', 'std', 'min', 'max'],
            }).round(2)
            
            # Achatar colunas multi-n√≠vel
            stats_por_unidade.columns = ['_'.join(col).strip() for col in stats_por_unidade.columns]
            stats_por_unidade = stats_por_unidade.reset_index()
            
            # Adicionar classifica√ß√µes
            stats_por_unidade['rpm_categoria'] = pd.cut(
                stats_por_unidade['rpm_mean'], 
                bins=[0, 800, 1300, 2000, float('inf')], 
                labels=['Baixo', 'Econ√¥mico', 'Normal', 'Alto']
            )
            
            stats_por_unidade['velocidade_categoria'] = pd.cut(
                stats_por_unidade['velocidade_mean'], 
                bins=[0, 40, 60, 80, float('inf')], 
                labels=['Baixa', 'Moderada', 'Alta', 'Muito Alta']
            )
            
            # Salvar an√°lise por unidade
            stats_por_unidade.to_excel(f'{deposito}/estudo_01_analise_por_unidade.xlsx', index=False)
            print(f"üíæ An√°lise por unidade salva em: estudo_01_analise_por_unidade.xlsx")
            
            # ============= AN√ÅLISE POR MARCA =============
            print(f"\nüè≠ {colored('Analisando padr√µes por marca...', 'blue')}")
            
            stats_por_marca = df.groupby('marca').agg({
                'rpm': ['count', 'mean', 'std', 'min', 'max'],
                'velocidade': ['mean', 'std', 'min', 'max'],
                'altitude': ['mean', 'std', 'min', 'max'],
                'unidade_id': 'nunique'
            }).round(2)
            
            stats_por_marca.columns = ['_'.join(col).strip() for col in stats_por_marca.columns]
            stats_por_marca = stats_por_marca.reset_index()
            
            # Adicionar classifica√ß√£o de efici√™ncia por marca
            stats_por_marca['eficiencia_rpm'] = pd.cut(
                stats_por_marca['rpm_mean'], 
                bins=[0, 800, 1300, 2000, float('inf')], 
                labels=['Muito Eficiente', 'Eficiente', 'Normal', 'Ineficiente']
            )
            
            # Calcular ranking de efici√™ncia
            stats_por_marca['ranking_eficiencia'] = stats_por_marca['rpm_mean'].rank(ascending=True)
            
            # Salvar an√°lise por marca
            stats_por_marca.to_excel(f'{deposito}/estudo_01_analise_por_marca.xlsx', index=False)
            print(f"üíæ An√°lise por marca salva em: estudo_01_analise_por_marca.xlsx")
            
            # ============= AN√ÅLISE POR MODELO =============
            print(f"\nüöó {colored('Analisando padr√µes por modelo...', 'blue')}")
            
            stats_por_modelo = df.groupby(['marca', 'modelo']).agg({
                'rpm': ['count', 'mean', 'std', 'min', 'max'],
                'velocidade': ['mean', 'std', 'min', 'max'],
                'altitude': ['mean', 'std', 'min', 'max'],
                'unidade_id': 'nunique'
            }).round(2)
            
            stats_por_modelo.columns = ['_'.join(col).strip() for col in stats_por_modelo.columns]
            stats_por_modelo = stats_por_modelo.reset_index()
            
            # Adicionar classifica√ß√£o de performance
            stats_por_modelo['performance_rpm'] = pd.cut(
                stats_por_modelo['rpm_mean'], 
                bins=[0, 800, 1300, 2000, float('inf')], 
                labels=['Excelente', 'Boa', 'Regular', 'Ruim']
            )
            
            stats_por_modelo['performance_velocidade'] = pd.cut(
                stats_por_modelo['velocidade_mean'], 
                bins=[0, 40, 60, 80, float('inf')], 
                labels=['Urbano', 'Misto', 'Rodovi√°rio', 'Alto']
            )
            
            # Salvar an√°lise por modelo
            stats_por_modelo.to_excel(f'{deposito}/estudo_01_analise_por_modelo.xlsx', index=False)
            print(f"üíæ An√°lise por modelo salva em: estudo_01_analise_por_modelo.xlsx")
            
            # ============= COMPARATIVO ENTRE MARCAS =============
            print(f"\n‚öñÔ∏è {colored('Gerando comparativo entre marcas...', 'blue')}")
            
            comparativo_marcas = {}
            
            for marca in df['marca'].unique():
                if marca != 'N/I':  # Ignora registros sem marca
                    dados_marca = df[df['marca'] == marca]
                    
                    comparativo_marcas[marca] = {
                        'total_registros': len(dados_marca),
                        'total_unidades': dados_marca['unidade_id'].nunique(),
                        'rpm_medio': dados_marca['rpm'].mean(),
                        'rpm_desvio': dados_marca['rpm'].std(),
                        'velocidade_media': dados_marca['velocidade'].mean(),
                        'altitude_media': dados_marca['altitude'].mean(),
                        'percentual_zona_verde': len(dados_marca[(dados_marca['rpm'] >= 800) & (dados_marca['rpm'] <= 1300)]) / len(dados_marca) * 100,
                        'percentual_zona_vermelha': len(dados_marca[dados_marca['rpm'] > 2300]) / len(dados_marca) * 100,
                        'empresas': list(dados_marca['empresa'].unique())
                    }
            
            # Converter para DataFrame
            comparativo_df = pd.DataFrame(comparativo_marcas).T
            comparativo_df = comparativo_df.round(2)
            comparativo_df = comparativo_df.sort_values('rpm_medio')  # Ordenar por efici√™ncia
            
            # Salvar comparativo
            comparativo_df.to_excel(f'{deposito}/estudo_01_comparativo_marcas.xlsx')
            print(f"üíæ Comparativo entre marcas salvo em: estudo_01_comparativo_marcas.xlsx")
            
            # ============= AN√ÅLISE TEMPORAL =============
            print(f"\n‚è∞ {colored('Analisando padr√µes temporais...', 'blue')}")
            
            # Por hora do dia
            analise_hora = df.groupby('hora').agg({
                'rpm': ['mean', 'std', 'count'],
                'velocidade': ['mean', 'std'],
                'altitude': ['mean', 'std']
            }).round(2)
            analise_hora.columns = ['_'.join(col).strip() for col in analise_hora.columns]
            analise_hora = analise_hora.reset_index()
            
            # Por dia da semana
            dias_semana = ['Segunda', 'Ter√ßa', 'Quarta', 'Quinta', 'Sexta', 'S√°bado', 'Domingo']
            analise_dia_semana = df.groupby('dia_semana').agg({
                'rpm': ['mean', 'std', 'count'],
                'velocidade': ['mean', 'std'],
                'altitude': ['mean', 'std']
            }).round(2)
            analise_dia_semana.columns = ['_'.join(col).strip() for col in analise_dia_semana.columns]
            analise_dia_semana = analise_dia_semana.reset_index()
            analise_dia_semana['dia_nome'] = analise_dia_semana['dia_semana'].map(lambda x: dias_semana[x])
            
            # Por m√™s
            analise_mes = df.groupby('mes').agg({
                'rpm': ['mean', 'std', 'count'],
                'velocidade': ['mean', 'std'],
                'altitude': ['mean', 'std']
            }).round(2)
            analise_mes.columns = ['_'.join(col).strip() for col in analise_mes.columns]
            analise_mes = analise_mes.reset_index()
            
            # An√°lise temporal por marca
            analise_temporal_marca = df.groupby(['marca', 'hora']).agg({
                'rpm': 'mean',
                'velocidade': 'mean'
            }).round(2).reset_index()
            
            # Salvar an√°lises temporais
            with pd.ExcelWriter(f'{deposito}/estudo_01_analise_temporal.xlsx') as writer:
                analise_hora.to_excel(writer, sheet_name='Por_Hora', index=False)
                analise_dia_semana.to_excel(writer, sheet_name='Por_Dia_Semana', index=False)
                analise_mes.to_excel(writer, sheet_name='Por_Mes', index=False)
                analise_temporal_marca.to_excel(writer, sheet_name='Marca_por_Hora', index=False)
            
            print(f"üíæ An√°lise temporal salva em: estudo_01_analise_temporal.xlsx")
            
            # ============= AN√ÅLISE DE CORRELA√á√ïES =============
            print(f"\nüîó {colored('Analisando correla√ß√µes...', 'blue')}")
            
            # Matriz de correla√ß√£o geral
            correlation_matrix = df[['rpm', 'velocidade', 'altitude', 'hora', 'dia_semana']].corr()
            
            # Correla√ß√µes por marca (se houver dados suficientes)
            correlacoes_por_marca = {}
            for marca in df['marca'].unique():
                if marca != 'N/I':
                    dados_marca = df[df['marca'] == marca]
                    if len(dados_marca) > 50:  # S√≥ calcula se houver dados suficientes
                        correlacoes_por_marca[marca] = dados_marca[['rpm', 'velocidade', 'altitude']].corr()
            
            # Salvar correla√ß√µes
            with pd.ExcelWriter(f'{deposito}/estudo_01_matriz_correlacao.xlsx') as writer:
                correlation_matrix.to_excel(writer, sheet_name='Geral')
                for marca, corr_matrix in correlacoes_por_marca.items():
                    corr_matrix.to_excel(writer, sheet_name=f'Marca_{marca}')
            
            print(f"üíæ Matriz de correla√ß√£o salva em: estudo_01_matriz_correlacao.xlsx")
            
            # ============= CLUSTERING AN√ÅLISE =============
            print(f"\nüéØ {colored('Realizando an√°lise de clusters...', 'blue')}")
            
            # Preparar dados para clustering
            features_clustering = df[['rpm', 'velocidade', 'altitude']].copy()
            
            # Normalizar dados
            scaler = StandardScaler()
            features_normalized = scaler.fit_transform(features_clustering)
            
            # K-Means com k=5
            kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)
            clusters = kmeans.fit_predict(features_normalized)
            
            # Adicionar clusters ao DataFrame
            df_clusters = df.copy()
            df_clusters['cluster'] = clusters
            
            # Analisar caracter√≠sticas de cada cluster
            cluster_analysis = df_clusters.groupby('cluster').agg({
                'rpm': ['mean', 'std', 'min', 'max', 'count'],
                'velocidade': ['mean', 'std', 'min', 'max'],
                'altitude': ['mean', 'std', 'min', 'max'],
                'unidade_id': 'nunique'
            }).round(2)
            
            cluster_analysis.columns = ['_'.join(col).strip() for col in cluster_analysis.columns]
            cluster_analysis = cluster_analysis.reset_index()
            
            # An√°lise de clusters por marca
            cluster_por_marca = df_clusters.groupby(['marca', 'cluster']).size().reset_index(name='count')
            cluster_por_marca_pivot = cluster_por_marca.pivot(index='marca', columns='cluster', values='count').fillna(0)
            
            # Adicionar interpreta√ß√£o dos clusters
            def interpretar_cluster(row):
                rpm_mean = row['rpm_mean']
                vel_mean = row['velocidade_mean']
                
                if rpm_mean < 800:
                    rpm_cat = "Marcha Lenta"
                elif rpm_mean < 1300:
                    rpm_cat = "Econ√¥mico"
                elif rpm_mean < 2000:
                    rpm_cat = "Normal"
                else:
                    rpm_cat = "Alto"
                
                if vel_mean < 20:
                    vel_cat = "Parado/Lento"
                elif vel_mean < 50:
                    vel_cat = "Urbano"
                elif vel_mean < 80:
                    vel_cat = "Rodovi√°rio"
                else:
                    vel_cat = "Alto"
                
                return f"{rpm_cat} + {vel_cat}"
            
            cluster_analysis['interpretacao'] = cluster_analysis.apply(interpretar_cluster, axis=1)
            
            # Salvar an√°lise de clusters
            with pd.ExcelWriter(f'{deposito}/estudo_01_analise_clusters.xlsx') as writer:
                cluster_analysis.to_excel(writer, sheet_name='Clusters_Geral', index=False)
                cluster_por_marca_pivot.to_excel(writer, sheet_name='Clusters_por_Marca')
            
            print(f"üíæ An√°lise de clusters salva em: estudo_01_analise_clusters.xlsx")
            
            # ============= DETEC√á√ÉO DE PADR√ïES ESPEC√çFICOS =============
            print(f"\nüîç {colored('Detectando padr√µes espec√≠ficos...', 'blue')}")
            
            padroes_especificos = {}
            
            # 1. Padr√£o de marcha lenta excessiva
            marcha_lenta = df[df['rpm'] < 500]
            padroes_especificos['marcha_lenta_excessiva'] = {
                'total_registros': len(marcha_lenta),
                'unidades_afetadas': marcha_lenta['unidade_nome'].nunique(),
                'percentual_total': round(len(marcha_lenta) / len(df) * 100, 2),
                'por_marca': dict(marcha_lenta['marca'].value_counts())
            }
            
            # 2. Padr√£o de RPM muito alto (zona vermelha)
            rpm_alto = df[df['rpm'] > 2300]
            padroes_especificos['rpm_zona_vermelha'] = {
                'total_registros': len(rpm_alto),
                'unidades_afetadas': rpm_alto['unidade_nome'].nunique(),
                'percentual_total': round(len(rpm_alto) / len(df) * 100, 2),
                'por_marca': dict(rpm_alto['marca'].value_counts())
            }
            
            # 3. Padr√£o de velocidade alta com RPM baixo
            vel_alta_rpm_baixo = df[(df['velocidade'] > 60) & (df['rpm'] < 1000)]
            padroes_especificos['velocidade_alta_rpm_baixo'] = {
                'total_registros': len(vel_alta_rpm_baixo),
                'unidades_afetadas': vel_alta_rpm_baixo['unidade_nome'].nunique(),
                'percentual_total': round(len(vel_alta_rpm_baixo) / len(df) * 100, 2),
                'por_marca': dict(vel_alta_rpm_baixo['marca'].value_counts())
            }
            
            # 4. Padr√£o noturno (22h √†s 6h)
            periodo_noturno = df[(df['hora'] >= 22) | (df['hora'] <= 6)]
            padroes_especificos['atividade_noturna'] = {
                'total_registros': len(periodo_noturno),
                'unidades_afetadas': periodo_noturno['unidade_nome'].nunique(),
                'percentual_total': round(len(periodo_noturno) / len(df) * 100, 2),
                'por_marca': dict(periodo_noturno['marca'].value_counts())
            }
            
            # 5. Efici√™ncia por faixa de RPM
            df['faixa_rpm'] = pd.cut(
                df['rpm'], 
                bins=[0, 799, 1300, 2300, float('inf')], 
                labels=['Azul (350-799)', 'Verde (800-1300)', 'Amarela (1301-2300)', 'Vermelha (2301+)']
            )
            
            distribuicao_rpm = df['faixa_rpm'].value_counts().to_dict()
            distribuicao_rpm_por_marca = df.groupby(['marca', 'faixa_rpm']).size().unstack(fill_value=0)
            
            padroes_especificos['distribuicao_faixas_rpm'] = distribuicao_rpm
            
            # Salvar padr√µes espec√≠ficos
            with pd.ExcelWriter(f'{deposito}/estudo_01_padroes_especificos.xlsx') as writer:
                # Sheet com resumo dos padr√µes
                padroes_resumo = pd.DataFrame([padroes_especificos]).T
                padroes_resumo.to_excel(writer, sheet_name='Resumo_Padroes')
                
                # Sheet com distribui√ß√£o RPM por marca
                distribuicao_rpm_por_marca.to_excel(writer, sheet_name='RPM_por_Marca')
            
            print(f"üíæ Padr√µes espec√≠ficos salvos em: estudo_01_padroes_especificos.xlsx")
            
            # ============= GERAR GR√ÅFICOS =============
            print(f"\nüìä {colored('Gerando gr√°ficos de an√°lise...', 'blue')}")
            
            # Configurar estilo dos gr√°ficos
            plt.style.use('default')
            sns.set_palette("husl")
            
            # 1. Distribui√ß√µes das vari√°veis principais
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('Distribui√ß√µes das Vari√°veis Principais', fontsize=16, fontweight='bold')
            
            # RPM
            axes[0, 0].hist(df['rpm'], bins=50, alpha=0.7, color='blue')
            axes[0, 0].set_title('Distribui√ß√£o RPM')
            axes[0, 0].set_xlabel('RPM')
            axes[0, 0].set_ylabel('Frequ√™ncia')
            axes[0, 0].axvline(df['rpm'].mean(), color='red', linestyle='--', label=f'M√©dia: {df["rpm"].mean():.0f}')
            axes[0, 0].legend()
            
            # Velocidade
            axes[0, 1].hist(df['velocidade'], bins=50, alpha=0.7, color='green')
            axes[0, 1].set_title('Distribui√ß√£o Velocidade')
            axes[0, 1].set_xlabel('Velocidade (km/h)')
            axes[0, 1].set_ylabel('Frequ√™ncia')
            axes[0, 1].axvline(df['velocidade'].mean(), color='red', linestyle='--', label=f'M√©dia: {df["velocidade"].mean():.1f}')
            axes[0, 1].legend()
            
            # Altitude
            axes[1, 0].hist(df['altitude'], bins=50, alpha=0.7, color='orange')
            axes[1, 0].set_title('Distribui√ß√£o Altitude')
            axes[1, 0].set_xlabel('Altitude (m)')
            axes[1, 0].set_ylabel('Frequ√™ncia')
            axes[1, 0].axvline(df['altitude'].mean(), color='red', linestyle='--', label=f'M√©dia: {df["altitude"].mean():.1f}')
            axes[1, 0].legend()
            
            # Distribui√ß√£o por faixa de RPM
            faixa_counts = df['faixa_rpm'].value_counts()
            axes[1, 1].pie(faixa_counts.values, labels=faixa_counts.index, autopct='%1.1f%%')
            axes[1, 1].set_title('Distribui√ß√£o por Faixa de RPM')
            
            plt.tight_layout()
            plt.savefig(f'{deposito}/estudo_01_distribuicoes.png', dpi=300, bbox_inches='tight')
            plt.close()
            
            # 2. An√°lise por marca
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('An√°lise por Marca', fontsize=16, fontweight='bold')
            
            # RPM m√©dio por marca
            marca_rpm = df.groupby('marca')['rpm'].mean().sort_values()
            axes[0, 0].bar(range(len(marca_rpm)), marca_rpm.values, color='skyblue')
            axes[0, 0].set_title('RPM M√©dio por Marca')
            axes[0, 0].set_xlabel('Marca')
            axes[0, 0].set_ylabel('RPM M√©dio')
            axes[0, 0].set_xticks(range(len(marca_rpm)))
            axes[0, 0].set_xticklabels(marca_rpm.index, rotation=45)
            
            # Velocidade m√©dia por marca
            marca_vel = df.groupby('marca')['velocidade'].mean().sort_values()
            axes[0, 1].bar(range(len(marca_vel)), marca_vel.values, color='lightgreen')
            axes[0, 1].set_title('Velocidade M√©dia por Marca')
            axes[0, 1].set_xlabel('Marca')
            axes[0, 1].set_ylabel('Velocidade M√©dia (km/h)')
            axes[0, 1].set_xticks(range(len(marca_vel)))
            axes[0, 1].set_xticklabels(marca_vel.index, rotation=45)
            
            # Distribui√ß√£o de registros por marca
            marca_count = df['marca'].value_counts()
            axes[1, 0].pie(marca_count.values, labels=marca_count.index, autopct='%1.1f%%')
            axes[1, 0].set_title('Distribui√ß√£o de Registros por Marca')
            
            # Boxplot RPM por marca
            marcas_com_dados = [marca for marca in df['marca'].unique() if len(df[df['marca'] == marca]) > 100]
            if len(marcas_com_dados) > 1:
                dados_boxplot = [df[df['marca'] == marca]['rpm'] for marca in marcas_com_dados]
                axes[1, 1].boxplot(dados_boxplot, labels=marcas_com_dados)
                axes[1, 1].set_title('Distribui√ß√£o RPM por Marca')
                axes[1, 1].set_xlabel('Marca')
                axes[1, 1].set_ylabel('RPM')
                axes[1, 1].tick_params(axis='x', rotation=45)
            
            plt.tight_layout()
            plt.savefig(f'{deposito}/estudo_01_analise_marcas.png', dpi=300, bbox_inches='tight')
            plt.close()
            
            # 3. An√°lise temporal
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('An√°lise Temporal dos Dados', fontsize=16, fontweight='bold')
            
            # RPM por hora
            hourly_rpm = df.groupby('hora')['rpm'].mean()
            axes[0, 0].plot(hourly_rpm.index, hourly_rpm.values, marker='o', linewidth=2)
            axes[0, 0].set_title('RPM M√©dio por Hora do Dia')
            axes[0, 0].set_xlabel('Hora')
            axes[0, 0].set_ylabel('RPM M√©dio')
            axes[0, 0].grid(True, alpha=0.3)
            
            # Velocidade por hora
            hourly_vel = df.groupby('hora')['velocidade'].mean()
            axes[0, 1].plot(hourly_vel.index, hourly_vel.values, marker='s', color='green', linewidth=2)
            axes[0, 1].set_title('Velocidade M√©dia por Hora do Dia')
            axes[0, 1].set_xlabel('Hora')
            axes[0, 1].set_ylabel('Velocidade M√©dia (km/h)')
            axes[0, 1].grid(True, alpha=0.3)
            
            # RPM por dia da semana
            daily_rpm = df.groupby('dia_semana')['rpm'].mean()
            dias_nome = ['Seg', 'Ter', 'Qua', 'Qui', 'Sex', 'S√°b', 'Dom']
            axes[1, 0].bar(range(7), daily_rpm.values, color='purple', alpha=0.7)
            axes[1, 0].set_title('RPM M√©dio por Dia da Semana')
            axes[1, 0].set_xlabel('Dia da Semana')
            axes[1, 0].set_ylabel('RPM M√©dio')
            axes[1, 0].set_xticks(range(7))
            axes[1, 0].set_xticklabels(dias_nome)
            
            # Atividade por m√™s
            monthly_count = df.groupby('mes').size()
            axes[1, 1].bar(monthly_count.index, monthly_count.values, color='red', alpha=0.7)
            axes[1, 1].set_title('Atividade por M√™s')
            axes[1, 1].set_xlabel('M√™s')
            axes[1, 1].set_ylabel('N√∫mero de Registros')
            
            plt.tight_layout()
            plt.savefig(f'{deposito}/estudo_01_analise_temporal.png', dpi=300, bbox_inches='tight')
            plt.close()
            
            # 4. Scatter plots e correla√ß√µes
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('An√°lise de Correla√ß√µes', fontsize=16, fontweight='bold')
            
            # RPM vs Velocidade
            axes[0, 0].scatter(df['rpm'], df['velocidade'], alpha=0.1, s=1)
            axes[0, 0].set_title('RPM vs Velocidade')
            axes[0, 0].set_xlabel('RPM')
            axes[0, 0].set_ylabel('Velocidade (km/h)')
            
            # RPM vs Altitude
            axes[0, 1].scatter(df['rpm'], df['altitude'], alpha=0.1, s=1, color='green')
            axes[0, 1].set_title('RPM vs Altitude')
            axes[0, 1].set_xlabel('RPM')
            axes[0, 1].set_ylabel('Altitude (m)')
            
            # Velocidade vs Altitude
            axes[1, 0].scatter(df['velocidade'], df['altitude'], alpha=0.1, s=1, color='red')
            axes[1, 0].set_title('Velocidade vs Altitude')
            axes[1, 0].set_xlabel('Velocidade (km/h)')
            axes[1, 0].set_ylabel('Altitude (m)')
            
            # Heatmap de correla√ß√£o
            corr_data = df[['rpm', 'velocidade', 'altitude', 'hora']].corr()
            im = axes[1, 1].imshow(corr_data, cmap='coolwarm', aspect='auto')
            axes[1, 1].set_title('Matriz de Correla√ß√£o')
            axes[1, 1].set_xticks(range(len(corr_data.columns)))
            axes[1, 1].set_yticks(range(len(corr_data.columns)))
            axes[1, 1].set_xticklabels(corr_data.columns)
            axes[1, 1].set_yticklabels(corr_data.columns)
            
            plt.tight_layout()
            plt.savefig(f'{deposito}/estudo_01_correlacoes.png', dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"üíæ Gr√°ficos salvos em:")
            print(f"   - estudo_01_distribuicoes.png")
            print(f"   - estudo_01_analise_marcas.png")
            print(f"   - estudo_01_analise_temporal.png")
            print(f"   - estudo_01_correlacoes.png")
            
            # ============= RELAT√ìRIO RESUMO =============
            print(f"\nüìã {colored('Gerando relat√≥rio resumo...', 'blue')}")
            
            resumo = {
                'data_analise': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'total_registros': len(df),
                'total_unidades': df['unidade_id'].nunique(),
                'total_empresas': df['empresa'].nunique(),
                'total_marcas': df['marca'].nunique(),
                'total_modelos': df['modelo'].nunique(),
                'periodo_dados': f"{df['datetime'].min()} at√© {df['datetime'].max()}",
                'rpm_medio_geral': round(df['rpm'].mean(), 2),
                'rpm_desvio_padrao': round(df['rpm'].std(), 2),
                'velocidade_media_geral': round(df['velocidade'].mean(), 2),
                'altitude_media_geral': round(df['altitude'].mean(), 2),
                'outliers_detectados': len(all_outliers),
                'percentual_outliers': round(len(all_outliers) / len(df) * 100, 2),
                'distribuicao_faixas_rpm': dict(df['faixa_rpm'].value_counts()),
                'marca_mais_eficiente': marca_rpm.index[0] if len(marca_rpm) > 0 else 'N/A',
                'marca_menos_eficiente': marca_rpm.index[-1] if len(marca_rpm) > 0 else 'N/A',
                'padroes_identificados': len(padroes_especificos),
            }
            
            # Salvar resumo
            resumo_df = pd.DataFrame([resumo]).T
            resumo_df.columns = ['Valor']
            resumo_df.to_excel(f'{deposito}/estudo_01_resumo_executivo.xlsx')
            
            # ============= RESULTADO FINAL =============
            print(colored("="*50, 'cyan'))
            print(colored("ESTUDO ESTAT√çSTICO CONCLU√çDO COM SUCESSO!", 'green'))
            print(colored("="*50, 'cyan'))
            
            print(f"üìä {colored('RESUMO DOS RESULTADOS:', 'yellow')}")
            print(f"   ‚Ä¢ Total de registros analisados: {colored(f'{len(df):,}', 'green')}")
            print(f"   ‚Ä¢ Unidades analisadas: {colored(df['unidade_id'].nunique(), 'green')}")
            print(f"   ‚Ä¢ Empresas envolvidas: {colored(df['empresa'].nunique(), 'green')}")
            print(f"   ‚Ä¢ Marcas analisadas: {colored(df['marca'].nunique(), 'blue')}")
            print(f"   ‚Ä¢ Modelos analisados: {colored(df['modelo'].nunique(), 'blue')}")
            print(f"   ‚Ä¢ Outliers detectados: {colored(f'{len(all_outliers):,}', 'red')} ({colored(f'{len(all_outliers)/len(df)*100:.1f}%', 'red')})")
            print(f"   ‚Ä¢ RPM m√©dio da frota: {colored(f'{df.rpm.mean():.0f}', 'blue')} RPM")
            print(f"   ‚Ä¢ Velocidade m√©dia: {colored(f'{df.velocidade.mean():.1f}', 'blue')} km/h")
            
            print(f"\nüè≠ {colored('AN√ÅLISE POR MARCA:', 'yellow')}")
            if len(marca_rpm) > 0:
                print(f"   ‚Ä¢ Marca mais eficiente: {colored(marca_rpm.index[0], 'green')} ({colored(f'{marca_rpm.iloc[0]:.0f}', 'green')} RPM)")
                print(f"   ‚Ä¢ Marca menos eficiente: {colored(marca_rpm.index[-1], 'red')} ({colored(f'{marca_rpm.iloc[-1]:.0f}', 'red')} RPM)")
            
            print(f"\nüìÅ {colored('ARQUIVOS GERADOS:', 'yellow')}")
            print(f"   ‚Ä¢ estudo_01_estatisticas_descritivas.xlsx")
            print(f"   ‚Ä¢ estudo_01_outliers_detectados.xlsx") 
            print(f"   ‚Ä¢ estudo_01_analise_por_unidade.xlsx")
            print(f"   ‚Ä¢ estudo_01_analise_por_marca.xlsx")
            print(f"   ‚Ä¢ estudo_01_analise_por_modelo.xlsx")
            print(f"   ‚Ä¢ estudo_01_comparativo_marcas.xlsx")
            print(f"   ‚Ä¢ estudo_01_analise_temporal.xlsx")
            print(f"   ‚Ä¢ estudo_01_matriz_correlacao.xlsx")
            print(f"   ‚Ä¢ estudo_01_analise_clusters.xlsx")
            print(f"   ‚Ä¢ estudo_01_padroes_especificos.xlsx")
            print(f"   ‚Ä¢ estudo_01_resumo_executivo.xlsx")
            print(f"   ‚Ä¢ estudo_01_distribuicoes.png")
            print(f"   ‚Ä¢ estudo_01_analise_marcas.png")
            print(f"   ‚Ä¢ estudo_01_analise_temporal.png")
            print(f"   ‚Ä¢ estudo_01_correlacoes.png")
            
            print(f"\nüéØ {colored('PRINCIPAIS INSIGHTS:', 'yellow')}")
            print(f"   ‚Ä¢ Faixa de RPM mais comum: {colored(df['faixa_rpm'].mode().iloc[0], 'green')}")
            print(f"   ‚Ä¢ Hor√°rio de maior atividade: {colored(f'{hourly_rpm.idxmax()}h', 'green')}")
            print(f"   ‚Ä¢ Correla√ß√£o RPM-Velocidade: {colored(f'{df.rpm.corr(df.velocidade):.3f}', 'blue')}")
            if len(marca_rpm) > 1:
                print(f"   ‚Ä¢ Diferen√ßa de efici√™ncia entre marcas: {colored(f'{marca_rpm.iloc[-1] - marca_rpm.iloc[0]:.0f}', 'yellow')} RPM")
            
            return True
            
        except Exception as e:
            print(f"‚ùå {colored(f'Erro durante a an√°lise: {str(e)}', 'red')}")
            import traceback
            traceback.print_exc()
            return False


    def ESTUDO_03(self):
        """
        An√°lise estat√≠stica completa dos dados de Viagem_eco
        - Detec√ß√£o de outliers
        - An√°lise de padr√µes
        - Estat√≠sticas descritivas
        - Correla√ß√µes entre vari√°veis
        - An√°lise temporal
        - An√°lise por marca e modelo
        - NOVO: An√°lises de dispers√£o RPM detalhadas
        """
        print(colored("="*50, 'cyan'))
        print(colored("INICIANDO ESTUDO ESTAT√çSTICO COMPLETO V2", 'yellow'))
        print(colored("="*50, 'cyan'))
        
        # Importa√ß√µes necess√°rias
        import numpy as np
        import matplotlib.pyplot as plt
        import seaborn as sns
        from scipy import stats
        from sklearn.preprocessing import StandardScaler
        from sklearn.cluster import KMeans
        from sklearn.ensemble import IsolationForest
        import warnings
        warnings.filterwarnings('ignore')
        
        # Configurar matplotlib para n√£o mostrar gr√°ficos
        plt.ioff()
        
        try:
            # ============= COLETA DE DADOS =============
            print(f"üìä {colored('Coletando dados do banco...', 'blue')}")
            
            # Buscar todos os dados de Viagem_eco com informa√ß√µes dos ve√≠culos
            viagens_eco = Viagem_eco.objects.all().select_related('unidade__empresa')
            
            if not viagens_eco.exists():
                print(f"‚ùå {colored('Nenhum dado encontrado na tabela Viagem_eco', 'red')}")
                return
            
            # Converter para DataFrame
            data_list = []
            for viagem in viagens_eco:
                try:
                    # Converter timestamp unix para datetime
                    timestamp_int = int(viagem.timestamp)
                    dt = datetime.fromtimestamp(timestamp_int)
                    
                    # Filtrar apenas dados com RPM v√°lidos (acima de 300)
                    if viagem.rpm and float(viagem.rpm) >= 300:
                        data_list.append({
                            'timestamp': timestamp_int,
                            'datetime': dt,
                            'unidade_id': viagem.unidade.id,
                            'unidade_nome': viagem.unidade.nm,
                            'empresa': viagem.unidade.empresa.nome if viagem.unidade.empresa else 'N/A',
                            'marca': viagem.unidade.marca if hasattr(viagem.unidade, 'marca') and viagem.unidade.marca else 'N/I',
                            'modelo': viagem.unidade.modelo if hasattr(viagem.unidade, 'modelo') and viagem.unidade.modelo else 'N/I',
                            'cor': viagem.unidade.cor if hasattr(viagem.unidade, 'cor') and viagem.unidade.cor else 'N/I',
                            'placa': viagem.unidade.placa if hasattr(viagem.unidade, 'placa') and viagem.unidade.placa else 'N/I',
                            'rpm': float(viagem.rpm),
                            'velocidade': float(viagem.velocidade) if viagem.velocidade else 0.0,
                            'altitude': float(viagem.altitude) if viagem.altitude else 0.0,
                            'hora': dt.hour,
                            'dia_semana': dt.weekday(),
                            'mes': dt.month,
                            'ano': dt.year,
                        })
                except (ValueError, TypeError, OSError):
                    continue
            
            if not data_list:
                print(f"‚ùå {colored('Nenhum dado v√°lido encontrado', 'red')}")
                return
            
            df = pd.DataFrame(data_list)
            print(f"‚úÖ {colored(f'Dados coletados: {len(df)} registros de {df.unidade_id.nunique()} unidades', 'green')}")
            print(f"üìã {colored(f'Marcas encontradas: {df.marca.nunique()} ({list(df.marca.unique())})', 'blue')}")
            print(f"üöó {colored(f'Modelos encontrados: {df.modelo.nunique()}', 'blue')}")
            
            # ============= AN√ÅLISE DESCRITIVA B√ÅSICA =============
            print(f"\nüìà {colored('Gerando estat√≠sticas descritivas...', 'blue')}")
            
            stats_desc = df[['rpm', 'velocidade', 'altitude']].describe()
            
            # Fun√ß√£o para calcular MAD (Mean Absolute Deviation) manualmente
            def calculate_mad(series):
                """Calcula o desvio absoluto mediano"""
                median = series.median()
                return (series - median).abs().median()
            
            # Adicionar estat√≠sticas extras
            stats_extras = pd.DataFrame({
                'rpm': [
                    df['rpm'].var(),
                    df['rpm'].skew(),
                    df['rpm'].kurtosis(),
                    calculate_mad(df['rpm'])
                ],
                'velocidade': [
                    df['velocidade'].var(),
                    df['velocidade'].skew(),
                    df['velocidade'].kurtosis(),
                    calculate_mad(df['velocidade'])
                ],
                'altitude': [
                    df['altitude'].var(),
                    df['altitude'].skew(),
                    df['altitude'].kurtosis(),
                    calculate_mad(df['altitude'])
                ]
            }, index=['variancia', 'assimetria', 'curtose', 'desvio_abs_mediano'])
            
            stats_completas = pd.concat([stats_desc, stats_extras])
            
            # Salvar estat√≠sticas descritivas
            stats_completas.to_excel(f'{deposito}/estudo_02_estatisticas_descritivas.xlsx')
            print(f"üíæ Estat√≠sticas descritivas salvas em: estudo_02_estatisticas_descritivas.xlsx")
            
            # ============= DETEC√á√ÉO DE OUTLIERS =============
            print(f"\nüîç {colored('Detectando outliers...', 'blue')}")
            
            # M√©todo 1: Z-Score
            z_scores = np.abs(stats.zscore(df[['rpm', 'velocidade', 'altitude']]))
            outliers_zscore = df[(z_scores > 3).any(axis=1)].copy()
            
            # M√©todo 2: IQR (Interquartile Range)
            outliers_iqr = pd.DataFrame()
            for coluna in ['rpm', 'velocidade', 'altitude']:
                Q1 = df[coluna].quantile(0.25)
                Q3 = df[coluna].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                outliers_col = df[(df[coluna] < lower_bound) | (df[coluna] > upper_bound)]
                outliers_iqr = pd.concat([outliers_iqr, outliers_col]).drop_duplicates()
            
            # M√©todo 3: Isolation Forest
            iso_forest = IsolationForest(contamination=0.1, random_state=42)
            outliers_iso = iso_forest.fit_predict(df[['rpm', 'velocidade', 'altitude']])
            outliers_isolation = df[outliers_iso == -1].copy()
            
            # Combinar todos os outliers
            all_outliers = pd.concat([outliers_zscore, outliers_iqr, outliers_isolation]).drop_duplicates()
            all_outliers['metodo_deteccao'] = 'M√∫ltiplos'
            
            print(f"üéØ Outliers detectados:")
            print(f"   - Z-Score (>3): {len(outliers_zscore)} registros")
            print(f"   - IQR: {len(outliers_iqr)} registros")
            print(f"   - Isolation Forest: {len(outliers_isolation)} registros")
            print(f"   - Total √∫nicos: {len(all_outliers)} registros")
            
            # Salvar outliers
            all_outliers.to_excel(f'{deposito}/estudo_02_outliers_detectados.xlsx', index=False)
            print(f"üíæ Outliers salvos em: estudo_02_outliers_detectados.xlsx")
            
            # ============= AN√ÅLISE POR UNIDADE =============
            print(f"\nüöõ {colored('Analisando padr√µes por unidade...', 'blue')}")
            
            stats_por_unidade = df.groupby(['unidade_nome', 'empresa', 'marca', 'modelo', 'placa']).agg({
                'rpm': ['count', 'mean', 'std', 'min', 'max'],
                'velocidade': ['mean', 'std', 'min', 'max'],
                'altitude': ['mean', 'std', 'min', 'max'],
            }).round(2)
            
            # Achatar colunas multi-n√≠vel
            stats_por_unidade.columns = ['_'.join(col).strip() for col in stats_por_unidade.columns]
            stats_por_unidade = stats_por_unidade.reset_index()
            
            # Adicionar classifica√ß√µes
            stats_por_unidade['rpm_categoria'] = pd.cut(
                stats_por_unidade['rpm_mean'], 
                bins=[0, 800, 1300, 2000, float('inf')], 
                labels=['Baixo', 'Econ√¥mico', 'Normal', 'Alto']
            )
            
            stats_por_unidade['velocidade_categoria'] = pd.cut(
                stats_por_unidade['velocidade_mean'], 
                bins=[0, 40, 60, 80, float('inf')], 
                labels=['Baixa', 'Moderada', 'Alta', 'Muito Alta']
            )
            
            # Salvar an√°lise por unidade
            stats_por_unidade.to_excel(f'{deposito}/estudo_02_analise_por_unidade.xlsx', index=False)
            print(f"üíæ An√°lise por unidade salva em: estudo_02_analise_por_unidade.xlsx")
            
            # ============= AN√ÅLISE POR MARCA =============
            print(f"\nüè≠ {colored('Analisando padr√µes por marca...', 'blue')}")
            
            stats_por_marca = df.groupby('marca').agg({
                'rpm': ['count', 'mean', 'std', 'min', 'max'],
                'velocidade': ['mean', 'std', 'min', 'max'],
                'altitude': ['mean', 'std', 'min', 'max'],
                'unidade_id': 'nunique'
            }).round(2)
            
            stats_por_marca.columns = ['_'.join(col).strip() for col in stats_por_marca.columns]
            stats_por_marca = stats_por_marca.reset_index()
            
            # Adicionar classifica√ß√£o de efici√™ncia por marca
            stats_por_marca['eficiencia_rpm'] = pd.cut(
                stats_por_marca['rpm_mean'], 
                bins=[0, 800, 1300, 2000, float('inf')], 
                labels=['Muito Eficiente', 'Eficiente', 'Normal', 'Ineficiente']
            )
            
            # Calcular ranking de efici√™ncia
            stats_por_marca['ranking_eficiencia'] = stats_por_marca['rpm_mean'].rank(ascending=True)
            
            # Salvar an√°lise por marca
            stats_por_marca.to_excel(f'{deposito}/estudo_02_analise_por_marca.xlsx', index=False)
            print(f"üíæ An√°lise por marca salva em: estudo_02_analise_por_marca.xlsx")
            
            # ============= AN√ÅLISE POR MODELO =============
            print(f"\nüöó {colored('Analisando padr√µes por modelo...', 'blue')}")
            
            stats_por_modelo = df.groupby(['marca', 'modelo']).agg({
                'rpm': ['count', 'mean', 'std', 'min', 'max'],
                'velocidade': ['mean', 'std', 'min', 'max'],
                'altitude': ['mean', 'std', 'min', 'max'],
                'unidade_id': 'nunique'
            }).round(2)
            
            stats_por_modelo.columns = ['_'.join(col).strip() for col in stats_por_modelo.columns]
            stats_por_modelo = stats_por_modelo.reset_index()
            
            # Adicionar classifica√ß√£o de performance
            stats_por_modelo['performance_rpm'] = pd.cut(
                stats_por_modelo['rpm_mean'], 
                bins=[0, 800, 1300, 2000, float('inf')], 
                labels=['Excelente', 'Boa', 'Regular', 'Ruim']
            )
            
            stats_por_modelo['performance_velocidade'] = pd.cut(
                stats_por_modelo['velocidade_mean'], 
                bins=[0, 40, 60, 80, float('inf')], 
                labels=['Urbano', 'Misto', 'Rodovi√°rio', 'Alto']
            )
            
            # Salvar an√°lise por modelo
            stats_por_modelo.to_excel(f'{deposito}/estudo_02_analise_por_modelo.xlsx', index=False)
            print(f"üíæ An√°lise por modelo salva em: estudo_02_analise_por_modelo.xlsx")
            
            # ============= AN√ÅLISE DE DISPERS√ÉO RPM AVAN√áADA =============
            print(f"\nüìä {colored('Analisando dispers√£o RPM por marca e modelo...', 'blue')}")
            
            # An√°lise de desvio por marca
            desvios_por_marca = {}
            
            for marca in df['marca'].unique():
                if marca != 'N/I':
                    dados_marca = df[df['marca'] == marca]
                    
                    if len(dados_marca) > 50:  # S√≥ analisa marcas com dados suficientes
                        rpm_mean = dados_marca['rpm'].mean()
                        rpm_std = dados_marca['rpm'].std()
                        
                        # Identificar unidades fora do padr√£o da marca (> 2 desvios padr√£o)
                        unidades_fora_padrao = []
                        
                        for unidade in dados_marca['unidade_nome'].unique():
                            dados_unidade = dados_marca[dados_marca['unidade_nome'] == unidade]
                            rpm_unidade = dados_unidade['rpm'].mean()
                            
                            # Calcular z-score em rela√ß√£o √† marca
                            z_score = abs(rpm_unidade - rpm_mean) / rpm_std if rpm_std > 0 else 0
                            
                            if z_score > 2:  # Fora do padr√£o
                                unidades_fora_padrao.append({
                                    'unidade': unidade,
                                    'rpm_unidade': rpm_unidade,
                                    'z_score': z_score,
                                    'desvio_absoluto': rpm_unidade - rpm_mean,
                                    'status': 'Acima' if rpm_unidade > rpm_mean else 'Abaixo'
                                })
                        
                        desvios_por_marca[marca] = {
                            'rpm_medio_marca': rpm_mean,
                            'rpm_desvio_marca': rpm_std,
                            'total_unidades': dados_marca['unidade_nome'].nunique(),
                            'unidades_fora_padrao': len(unidades_fora_padrao),
                            'percentual_fora_padrao': (len(unidades_fora_padrao) / dados_marca['unidade_nome'].nunique()) * 100,
                            'detalhes_unidades': unidades_fora_padrao
                        }
            
            # Salvar an√°lise de desvios
            desvios_detalhados = []
            for marca, dados in desvios_por_marca.items():
                for unidade in dados['detalhes_unidades']:
                    desvios_detalhados.append({
                        'marca': marca,
                        'unidade': unidade['unidade'],
                        'rpm_unidade': unidade['rpm_unidade'],
                        'rpm_medio_marca': dados['rpm_medio_marca'],
                        'desvio_absoluto': unidade['desvio_absoluto'],
                        'z_score': unidade['z_score'],
                        'status': unidade['status']
                    })
            
            df_desvios = pd.DataFrame(desvios_detalhados)
            df_desvios.to_excel(f'{deposito}/estudo_02_unidades_fora_padrao.xlsx', index=False)
            print(f"üíæ An√°lise de unidades fora do padr√£o salva em: estudo_02_unidades_fora_padrao.xlsx")
            
            # An√°lise de dispers√£o por modelo dentro da marca
            dispersao_modelo = []
            
            for marca in df['marca'].unique():
                if marca != 'N/I':
                    dados_marca = df[df['marca'] == marca]
                    modelos_marca = dados_marca['modelo'].unique()
                    
                    if len(modelos_marca) > 1:  # S√≥ analisa se h√° m√∫ltiplos modelos
                        for modelo in modelos_marca:
                            dados_modelo = dados_marca[dados_marca['modelo'] == modelo]
                            
                            if len(dados_modelo) > 20:  # Dados suficientes
                                dispersao_modelo.append({
                                    'marca': marca,
                                    'modelo': modelo,
                                    'rpm_medio': dados_modelo['rpm'].mean(),
                                    'rpm_desvio': dados_modelo['rpm'].std(),
                                    'rpm_min': dados_modelo['rpm'].min(),
                                    'rpm_max': dados_modelo['rpm'].max(),
                                    'coef_variacao': (dados_modelo['rpm'].std() / dados_modelo['rpm'].mean()) * 100,
                                    'total_registros': len(dados_modelo),
                                    'total_unidades': dados_modelo['unidade_nome'].nunique()
                                })
            
            df_dispersao = pd.DataFrame(dispersao_modelo)
            df_dispersao = df_dispersao.sort_values(['marca', 'coef_variacao'])
            df_dispersao.to_excel(f'{deposito}/estudo_02_dispersao_por_modelo.xlsx', index=False)
            print(f"üíæ An√°lise de dispers√£o por modelo salva em: estudo_02_dispersao_por_modelo.xlsx")
            
            # ============= COMPARATIVO ENTRE MARCAS =============
            print(f"\n‚öñÔ∏è {colored('Gerando comparativo entre marcas...', 'blue')}")
            
            comparativo_marcas = {}
            
            for marca in df['marca'].unique():
                if marca != 'N/I':  # Ignora registros sem marca
                    dados_marca = df[df['marca'] == marca]
                    
                    comparativo_marcas[marca] = {
                        'total_registros': len(dados_marca),
                        'total_unidades': dados_marca['unidade_id'].nunique(),
                        'rpm_medio': dados_marca['rpm'].mean(),
                        'rpm_desvio': dados_marca['rpm'].std(),
                        'velocidade_media': dados_marca['velocidade'].mean(),
                        'altitude_media': dados_marca['altitude'].mean(),
                        'percentual_zona_verde': len(dados_marca[(dados_marca['rpm'] >= 800) & (dados_marca['rpm'] <= 1300)]) / len(dados_marca) * 100,
                        'percentual_zona_vermelha': len(dados_marca[dados_marca['rpm'] > 2300]) / len(dados_marca) * 100,
                        'coef_variacao_rpm': (dados_marca['rpm'].std() / dados_marca['rpm'].mean()) * 100,
                        'empresas': list(dados_marca['empresa'].unique())
                    }
            
            # Converter para DataFrame
            comparativo_df = pd.DataFrame(comparativo_marcas).T
            comparativo_df = comparativo_df.round(2)
            comparativo_df = comparativo_df.sort_values('rpm_medio')  # Ordenar por efici√™ncia
            
            # Salvar comparativo
            comparativo_df.to_excel(f'{deposito}/estudo_02_comparativo_marcas.xlsx')
            print(f"üíæ Comparativo entre marcas salvo em: estudo_02_comparativo_marcas.xlsx")
            
            # ============= AN√ÅLISE TEMPORAL =============
            print(f"\n‚è∞ {colored('Analisando padr√µes temporais...', 'blue')}")
            
            # Por hora do dia
            analise_hora = df.groupby('hora').agg({
                'rpm': ['mean', 'std', 'count'],
                'velocidade': ['mean', 'std'],
                'altitude': ['mean', 'std']
            }).round(2)
            analise_hora.columns = ['_'.join(col).strip() for col in analise_hora.columns]
            analise_hora = analise_hora.reset_index()
            
            # Por dia da semana
            dias_semana = ['Segunda', 'Ter√ßa', 'Quarta', 'Quinta', 'Sexta', 'S√°bado', 'Domingo']
            analise_dia_semana = df.groupby('dia_semana').agg({
                'rpm': ['mean', 'std', 'count'],
                'velocidade': ['mean', 'std'],
                'altitude': ['mean', 'std']
            }).round(2)
            analise_dia_semana.columns = ['_'.join(col).strip() for col in analise_dia_semana.columns]
            analise_dia_semana = analise_dia_semana.reset_index()
            analise_dia_semana['dia_nome'] = analise_dia_semana['dia_semana'].map(lambda x: dias_semana[x])
            
            # Por m√™s
            analise_mes = df.groupby('mes').agg({
                'rpm': ['mean', 'std', 'count'],
                'velocidade': ['mean', 'std'],
                'altitude': ['mean', 'std']
            }).round(2)
            analise_mes.columns = ['_'.join(col).strip() for col in analise_mes.columns]
            analise_mes = analise_mes.reset_index()
            
            # An√°lise temporal por marca
            analise_temporal_marca = df.groupby(['marca', 'hora']).agg({
                'rpm': 'mean',
                'velocidade': 'mean'
            }).round(2).reset_index()
            
            # Salvar an√°lises temporais
            with pd.ExcelWriter(f'{deposito}/estudo_02_analise_temporal.xlsx') as writer:
                analise_hora.to_excel(writer, sheet_name='Por_Hora', index=False)
                analise_dia_semana.to_excel(writer, sheet_name='Por_Dia_Semana', index=False)
                analise_mes.to_excel(writer, sheet_name='Por_Mes', index=False)
                analise_temporal_marca.to_excel(writer, sheet_name='Marca_por_Hora', index=False)
            
            print(f"üíæ An√°lise temporal salva em: estudo_02_analise_temporal.xlsx")
            
            # ============= AN√ÅLISE DE CORRELA√á√ïES =============
            print(f"\nüîó {colored('Analisando correla√ß√µes...', 'blue')}")
            
            # Matriz de correla√ß√£o geral
            correlation_matrix = df[['rpm', 'velocidade', 'altitude', 'hora', 'dia_semana']].corr()
            
            # Correla√ß√µes por marca (se houver dados suficientes)
            correlacoes_por_marca = {}
            for marca in df['marca'].unique():
                if marca != 'N/I':
                    dados_marca = df[df['marca'] == marca]
                    if len(dados_marca) > 50:  # S√≥ calcula se houver dados suficientes
                        correlacoes_por_marca[marca] = dados_marca[['rpm', 'velocidade', 'altitude']].corr()
            
            # Salvar correla√ß√µes
            with pd.ExcelWriter(f'{deposito}/estudo_02_matriz_correlacao.xlsx') as writer:
                correlation_matrix.to_excel(writer, sheet_name='Geral')
                for marca, corr_matrix in correlacoes_por_marca.items():
                    corr_matrix.to_excel(writer, sheet_name=f'Marca_{marca}')
            
            print(f"üíæ Matriz de correla√ß√£o salva em: estudo_02_matriz_correlacao.xlsx")
            
            # ============= CLUSTERING AN√ÅLISE =============
            print(f"\nüéØ {colored('Realizando an√°lise de clusters...', 'blue')}")
            
            # Preparar dados para clustering
            features_clustering = df[['rpm', 'velocidade', 'altitude']].copy()
            
            # Normalizar dados
            scaler = StandardScaler()
            features_normalized = scaler.fit_transform(features_clustering)
            
            # K-Means com k=5
            kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)
            clusters = kmeans.fit_predict(features_normalized)
            
            # Adicionar clusters ao DataFrame
            df_clusters = df.copy()
            df_clusters['cluster'] = clusters
            
            # Analisar caracter√≠sticas de cada cluster
            cluster_analysis = df_clusters.groupby('cluster').agg({
                'rpm': ['mean', 'std', 'min', 'max', 'count'],
                'velocidade': ['mean', 'std', 'min', 'max'],
                'altitude': ['mean', 'std', 'min', 'max'],
                'unidade_id': 'nunique'
            }).round(2)
            
            cluster_analysis.columns = ['_'.join(col).strip() for col in cluster_analysis.columns]
            cluster_analysis = cluster_analysis.reset_index()
            
            # An√°lise de clusters por marca
            cluster_por_marca = df_clusters.groupby(['marca', 'cluster']).size().reset_index(name='count')
            cluster_por_marca_pivot = cluster_por_marca.pivot(index='marca', columns='cluster', values='count').fillna(0)
            
            # Adicionar interpreta√ß√£o dos clusters
            def interpretar_cluster(row):
                rpm_mean = row['rpm_mean']
                vel_mean = row['velocidade_mean']
                
                if rpm_mean < 800:
                    rpm_cat = "Marcha Lenta"
                elif rpm_mean < 1300:
                    rpm_cat = "Econ√¥mico"
                elif rpm_mean < 2000:
                    rpm_cat = "Normal"
                else:
                    rpm_cat = "Alto"
                
                if vel_mean < 20:
                    vel_cat = "Parado/Lento"
                elif vel_mean < 50:
                    vel_cat = "Urbano"
                elif vel_mean < 80:
                    vel_cat = "Rodovi√°rio"
                else:
                    vel_cat = "Alto"
                
                return f"{rpm_cat} + {vel_cat}"
            
            cluster_analysis['interpretacao'] = cluster_analysis.apply(interpretar_cluster, axis=1)
            
            # Salvar an√°lise de clusters
            with pd.ExcelWriter(f'{deposito}/estudo_02_analise_clusters.xlsx') as writer:
                cluster_analysis.to_excel(writer, sheet_name='Clusters_Geral', index=False)
                cluster_por_marca_pivot.to_excel(writer, sheet_name='Clusters_por_Marca')
            
            print(f"üíæ An√°lise de clusters salva em: estudo_02_analise_clusters.xlsx")
            
            # ============= DETEC√á√ÉO DE PADR√ïES ESPEC√çFICOS =============
            print(f"\nüîç {colored('Detectando padr√µes espec√≠ficos...', 'blue')}")
            
            padroes_especificos = {}
            
            # 1. Padr√£o de marcha lenta excessiva
            marcha_lenta = df[df['rpm'] < 500]
            padroes_especificos['marcha_lenta_excessiva'] = {
                'total_registros': len(marcha_lenta),
                'unidades_afetadas': marcha_lenta['unidade_nome'].nunique(),
                'percentual_total': round(len(marcha_lenta) / len(df) * 100, 2),
                'por_marca': dict(marcha_lenta['marca'].value_counts())
            }
            
            # 2. Padr√£o de RPM muito alto (zona vermelha)
            rpm_alto = df[df['rpm'] > 2300]
            padroes_especificos['rpm_zona_vermelha'] = {
                'total_registros': len(rpm_alto),
                'unidades_afetadas': rpm_alto['unidade_nome'].nunique(),
                'percentual_total': round(len(rpm_alto) / len(df) * 100, 2),
                'por_marca': dict(rpm_alto['marca'].value_counts())
            }
            
            # 3. Padr√£o de velocidade alta com RPM baixo
            vel_alta_rpm_baixo = df[(df['velocidade'] > 60) & (df['rpm'] < 1000)]
            padroes_especificos['velocidade_alta_rpm_baixo'] = {
                'total_registros': len(vel_alta_rpm_baixo),
                'unidades_afetadas': vel_alta_rpm_baixo['unidade_nome'].nunique(),
                'percentual_total': round(len(vel_alta_rpm_baixo) / len(df) * 100, 2),
                'por_marca': dict(vel_alta_rpm_baixo['marca'].value_counts())
            }
            
            # 4. Padr√£o noturno (22h √†s 6h)
            periodo_noturno = df[(df['hora'] >= 22) | (df['hora'] <= 6)]
            padroes_especificos['atividade_noturna'] = {
                'total_registros': len(periodo_noturno),
                'unidades_afetadas': periodo_noturno['unidade_nome'].nunique(),
                'percentual_total': round(len(periodo_noturno) / len(df) * 100, 2),
                'por_marca': dict(periodo_noturno['marca'].value_counts())
            }
            
            # 5. Efici√™ncia por faixa de RPM
            df['faixa_rpm'] = pd.cut(
                df['rpm'], 
                bins=[0, 799, 1300, 2300, float('inf')], 
                labels=['Azul (350-799)', 'Verde (800-1300)', 'Amarela (1301-2300)', 'Vermelha (2301+)']
            )
            
            distribuicao_rpm = df['faixa_rpm'].value_counts().to_dict()
            distribuicao_rpm_por_marca = df.groupby(['marca', 'faixa_rpm']).size().unstack(fill_value=0)
            
            padroes_especificos['distribuicao_faixas_rpm'] = distribuicao_rpm
            
            # Salvar padr√µes espec√≠ficos
            with pd.ExcelWriter(f'{deposito}/estudo_02_padroes_especificos.xlsx') as writer:
                # Sheet com resumo dos padr√µes
                padroes_resumo = pd.DataFrame([padroes_especificos]).T
                padroes_resumo.to_excel(writer, sheet_name='Resumo_Padroes')
                
                # Sheet com distribui√ß√£o RPM por marca
                distribuicao_rpm_por_marca.to_excel(writer, sheet_name='RPM_por_Marca')
            
            print(f"üíæ Padr√µes espec√≠ficos salvos em: estudo_02_padroes_especificos.xlsx")
            
            # ============= GERAR GR√ÅFICOS =============
            print(f"\nüìä {colored('Gerando gr√°ficos de an√°lise...', 'blue')}")
            
            # Configurar estilo dos gr√°ficos
            plt.style.use('default')
            sns.set_palette("husl")
            
            # 1. Distribui√ß√µes das vari√°veis principais
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('Distribui√ß√µes das Vari√°veis Principais', fontsize=16, fontweight='bold')
            
            # RPM
            axes[0, 0].hist(df['rpm'], bins=50, alpha=0.7, color='blue')
            axes[0, 0].set_title('Distribui√ß√£o RPM')
            axes[0, 0].set_xlabel('RPM')
            axes[0, 0].set_ylabel('Frequ√™ncia')
            axes[0, 0].axvline(df['rpm'].mean(), color='red', linestyle='--', label=f'M√©dia: {df["rpm"].mean():.0f}')
            axes[0, 0].legend()
            
            # Velocidade
            axes[0, 1].hist(df['velocidade'], bins=50, alpha=0.7, color='green')
            axes[0, 1].set_title('Distribui√ß√£o Velocidade')
            axes[0, 1].set_xlabel('Velocidade (km/h)')
            axes[0, 1].set_ylabel('Frequ√™ncia')
            axes[0, 1].axvline(df['velocidade'].mean(), color='red', linestyle='--', label=f'M√©dia: {df["velocidade"].mean():.1f}')
            axes[0, 1].legend()
            
            # Altitude
            axes[1, 0].hist(df['altitude'], bins=50, alpha=0.7, color='orange')
            axes[1, 0].set_title('Distribui√ß√£o Altitude')
            axes[1, 0].set_xlabel('Altitude (m)')
            axes[1, 0].set_ylabel('Frequ√™ncia')
            axes[1, 0].axvline(df['altitude'].mean(), color='red', linestyle='--', label=f'M√©dia: {df["altitude"].mean():.1f}')
            axes[1, 0].legend()
            
            # Distribui√ß√£o por faixa de RPM
            faixa_counts = df['faixa_rpm'].value_counts()
            axes[1, 1].pie(faixa_counts.values, labels=faixa_counts.index, autopct='%1.1f%%')
            axes[1, 1].set_title('Distribui√ß√£o por Faixa de RPM')
            
            plt.tight_layout()
            plt.savefig(f'{deposito}/estudo_02_distribuicoes.png', dpi=300, bbox_inches='tight')
            plt.close()
            
            # ============= GR√ÅFICOS DE DISPERS√ÉO RPM AVAN√áADOS =============
            print(f"\nüìà {colored('Gerando gr√°ficos de dispers√£o RPM avan√ßados...', 'blue')}")
            
            # 2. Gr√°fico de dispers√£o RPM por marca (com identifica√ß√£o de outliers)
            marcas_validas = [marca for marca in df['marca'].unique() if marca != 'N/I']
            
            if len(marcas_validas) > 1:
                # Gr√°fico 1: Dispers√£o RPM por marca com boxplots
                fig, axes = plt.subplots(2, 2, figsize=(20, 16))
                fig.suptitle('An√°lise de Dispers√£o RPM por Marca', fontsize=16, fontweight='bold')
                
                # Subplot 1: Boxplot RPM por marca
                dados_boxplot = [df[df['marca'] == marca]['rpm'] for marca in marcas_validas if len(df[df['marca'] == marca]) > 100]
                marcas_boxplot = [marca for marca in marcas_validas if len(df[df['marca'] == marca]) > 100]
                
                if dados_boxplot:
                    axes[0, 0].boxplot(dados_boxplot, labels=marcas_boxplot, patch_artist=True)
                    axes[0, 0].set_title('Distribui√ß√£o RPM por Marca (Boxplot)')
                    axes[0, 0].set_xlabel('Marca')
                    axes[0, 0].set_ylabel('RPM')
                    axes[0, 0].tick_params(axis='x', rotation=45)
                    axes[0, 0].grid(True, alpha=0.3)
                    
                    # Adicionar linhas de refer√™ncia
                    axes[0, 0].axhline(800, color='green', linestyle='--', alpha=0.7, label='Zona Verde (800)')
                    axes[0, 0].axhline(1300, color='green', linestyle='--', alpha=0.7, label='Zona Verde (1300)')
                    axes[0, 0].axhline(2300, color='red', linestyle='--', alpha=0.7, label='Zona Vermelha (2300)')
                    axes[0, 0].legend()
                
                # Subplot 2: Violin plot para mostrar distribui√ß√£o completa
                df_plot = df[df['marca'].isin(marcas_boxplot)]
                import seaborn as sns
                sns.violinplot(data=df_plot, x='marca', y='rpm', ax=axes[0, 1])
                axes[0, 1].set_title('Distribui√ß√£o RPM por Marca (Violin Plot)')
                axes[0, 1].set_xlabel('Marca')
                axes[0, 1].set_ylabel('RPM')
                axes[0, 1].tick_params(axis='x', rotation=45)
                
                # Subplot 3: Scatter plot RPM vs Velocidade colorido por marca
                cores_marca = plt.cm.Set1(np.linspace(0, 1, len(marcas_validas)))
                for i, marca in enumerate(marcas_validas):
                    dados_marca = df[df['marca'] == marca]
                    axes[1, 0].scatter(dados_marca['rpm'], dados_marca['velocidade'], 
                                    alpha=0.3, s=1, label=marca, c=[cores_marca[i]])
                
                axes[1, 0].set_title('RPM vs Velocidade por Marca')
                axes[1, 0].set_xlabel('RPM')
                axes[1, 0].set_ylabel('Velocidade (km/h)')
                axes[1, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')
                axes[1, 0].grid(True, alpha=0.3)
                
                # Subplot 4: M√©dia RPM por marca com barras de erro
                marca_stats = []
                for marca in marcas_validas:
                    dados_marca = df[df['marca'] == marca]
                    if len(dados_marca) > 50:
                        marca_stats.append({
                            'marca': marca,
                            'rpm_mean': dados_marca['rpm'].mean(),
                            'rpm_std': dados_marca['rpm'].std()
                        })
                
                if marca_stats:
                    df_stats = pd.DataFrame(marca_stats).sort_values('rpm_mean')
                    axes[1, 1].bar(df_stats['marca'], df_stats['rpm_mean'], 
                                yerr=df_stats['rpm_std'], capsize=5, alpha=0.7)
                    axes[1, 1].set_title('RPM M√©dio por Marca (com Desvio Padr√£o)')
                    axes[1, 1].set_xlabel('Marca')
                    axes[1, 1].set_ylabel('RPM M√©dio')
                    axes[1, 1].tick_params(axis='x', rotation=45)
                    axes[1, 1].grid(True, alpha=0.3)
                    
                    # Adicionar linhas de refer√™ncia
                    axes[1, 1].axhline(1050, color='green', linestyle='-', alpha=0.7, label='Zona Verde M√©dia')
                    axes[1, 1].legend()
                
                plt.tight_layout()
                plt.savefig(f'{deposito}/estudo_02_dispersao_rpm_marcas.png', dpi=300, bbox_inches='tight')
                plt.close()
            
            # 3. Gr√°fico de unidades fora do padr√£o por marca
            if desvios_detalhados:
                fig, axes = plt.subplots(2, 2, figsize=(20, 16))
                fig.suptitle('An√°lise de Unidades Fora do Padr√£o por Marca', fontsize=16, fontweight='bold')
                
                # Subplot 1: N√∫mero de unidades fora do padr√£o por marca
                marca_desvios = {}
                for marca, dados in desvios_por_marca.items():
                    marca_desvios[marca] = dados['unidades_fora_padrao']
                
                marcas = list(marca_desvios.keys())
                valores = list(marca_desvios.values())
                
                axes[0, 0].bar(marcas, valores, color='red', alpha=0.7)
                axes[0, 0].set_title('Unidades Fora do Padr√£o por Marca')
                axes[0, 0].set_xlabel('Marca')
                axes[0, 0].set_ylabel('N√∫mero de Unidades Fora do Padr√£o')
                axes[0, 0].tick_params(axis='x', rotation=45)
                
                # Subplot 2: Percentual de unidades fora do padr√£o
                percentuais = [desvios_por_marca[marca]['percentual_fora_padrao'] for marca in marcas]
                axes[0, 1].bar(marcas, percentuais, color='orange', alpha=0.7)
                axes[0, 1].set_title('Percentual de Unidades Fora do Padr√£o')
                axes[0, 1].set_xlabel('Marca')
                axes[0, 1].set_ylabel('Percentual (%)')
                axes[0, 1].tick_params(axis='x', rotation=45)
                
                # Subplot 3: Scatter plot dos desvios
                if desvios_detalhados:
                    df_desvios_plot = pd.DataFrame(desvios_detalhados)
                    cores = ['red' if status == 'Acima' else 'blue' for status in df_desvios_plot['status']]
                    
                    axes[1, 0].scatter(df_desvios_plot['rpm_medio_marca'], df_desvios_plot['rpm_unidade'], 
                                    c=cores, alpha=0.6, s=50)
                    axes[1, 0].plot([400, 2500], [400, 2500], 'k--', alpha=0.5, label='Linha de Igualdade')
                    axes[1, 0].set_title('RPM Unidade vs RPM M√©dio da Marca')
                    axes[1, 0].set_xlabel('RPM M√©dio da Marca')
                    axes[1, 0].set_ylabel('RPM da Unidade')
                    axes[1, 0].legend()
                    axes[1, 0].grid(True, alpha=0.3)
                
                # Subplot 4: Histograma dos Z-scores
                if desvios_detalhados:
                    z_scores = [item['z_score'] for item in desvios_detalhados]
                    axes[1, 1].hist(z_scores, bins=20, alpha=0.7, color='purple')
                    axes[1, 1].axvline(2, color='red', linestyle='--', label='Limite Z-Score = 2')
                    axes[1, 1].set_title('Distribui√ß√£o dos Z-Scores das Unidades Fora do Padr√£o')
                    axes[1, 1].set_xlabel('Z-Score')
                    axes[1, 1].set_ylabel('Frequ√™ncia')
                    axes[1, 1].legend()
                    axes[1, 1].grid(True, alpha=0.3)
                
                plt.tight_layout()
                plt.savefig(f'{deposito}/estudo_02_unidades_fora_padrao_graficos.png', dpi=300, bbox_inches='tight')
                plt.close()
            
            # 4. An√°lise temporal de dispers√£o
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('An√°lise Temporal dos Dados', fontsize=16, fontweight='bold')
            
            # RPM por hora
            hourly_rpm = df.groupby('hora')['rpm'].mean()
            axes[0, 0].plot(hourly_rpm.index, hourly_rpm.values, marker='o', linewidth=2)
            axes[0, 0].set_title('RPM M√©dio por Hora do Dia')
            axes[0, 0].set_xlabel('Hora')
            axes[0, 0].set_ylabel('RPM M√©dio')
            axes[0, 0].grid(True, alpha=0.3)
            
            # Velocidade por hora
            hourly_vel = df.groupby('hora')['velocidade'].mean()
            axes[0, 1].plot(hourly_vel.index, hourly_vel.values, marker='s', color='green', linewidth=2)
            axes[0, 1].set_title('Velocidade M√©dia por Hora do Dia')
            axes[0, 1].set_xlabel('Hora')
            axes[0, 1].set_ylabel('Velocidade M√©dia (km/h)')
            axes[0, 1].grid(True, alpha=0.3)
            
            # RPM por dia da semana
            daily_rpm = df.groupby('dia_semana')['rpm'].mean()
            dias_nome = ['Seg', 'Ter', 'Qua', 'Qui', 'Sex', 'S√°b', 'Dom']
            axes[1, 0].bar(range(7), daily_rpm.values, color='purple', alpha=0.7)
            axes[1, 0].set_title('RPM M√©dio por Dia da Semana')
            axes[1, 0].set_xlabel('Dia da Semana')
            axes[1, 0].set_ylabel('RPM M√©dio')
            axes[1, 0].set_xticks(range(7))
            axes[1, 0].set_xticklabels(dias_nome)
            
            # Atividade por m√™s
            monthly_count = df.groupby('mes').size()
            axes[1, 1].bar(monthly_count.index, monthly_count.values, color='red', alpha=0.7)
            axes[1, 1].set_title('Atividade por M√™s')
            axes[1, 1].set_xlabel('M√™s')
            axes[1, 1].set_ylabel('N√∫mero de Registros')
            
            plt.tight_layout()
            plt.savefig(f'{deposito}/estudo_02_analise_temporal.png', dpi=300, bbox_inches='tight')
            plt.close()
            
            # 5. Scatter plots e correla√ß√µes
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('An√°lise de Correla√ß√µes', fontsize=16, fontweight='bold')
            
            # RPM vs Velocidade
            axes[0, 0].scatter(df['rpm'], df['velocidade'], alpha=0.1, s=1)
            axes[0, 0].set_title('RPM vs Velocidade')
            axes[0, 0].set_xlabel('RPM')
            axes[0, 0].set_ylabel('Velocidade (km/h)')
            
            # RPM vs Altitude
            axes[0, 1].scatter(df['rpm'], df['altitude'], alpha=0.1, s=1, color='green')
            axes[0, 1].set_title('RPM vs Altitude')
            axes[0, 1].set_xlabel('RPM')
            axes[0, 1].set_ylabel('Altitude (m)')
            
            # Velocidade vs Altitude
            axes[1, 0].scatter(df['velocidade'], df['altitude'], alpha=0.1, s=1, color='red')
            axes[1, 0].set_title('Velocidade vs Altitude')
            axes[1, 0].set_xlabel('Velocidade (km/h)')
            axes[1, 0].set_ylabel('Altitude (m)')
            
            # Heatmap de correla√ß√£o
            corr_data = df[['rpm', 'velocidade', 'altitude', 'hora']].corr()
            im = axes[1, 1].imshow(corr_data, cmap='coolwarm', aspect='auto')
            axes[1, 1].set_title('Matriz de Correla√ß√£o')
            axes[1, 1].set_xticks(range(len(corr_data.columns)))
            axes[1, 1].set_yticks(range(len(corr_data.columns)))
            axes[1, 1].set_xticklabels(corr_data.columns)
            axes[1, 1].set_yticklabels(corr_data.columns)
            
            plt.tight_layout()
            plt.savefig(f'{deposito}/estudo_02_correlacoes.png', dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"üíæ Gr√°ficos salvos em:")
            print(f"   - estudo_02_distribuicoes.png")
            print(f"   - estudo_02_dispersao_rpm_marcas.png")
            print(f"   - estudo_02_unidades_fora_padrao_graficos.png")
            print(f"   - estudo_02_analise_temporal.png")
            print(f"   - estudo_02_correlacoes.png")
            
            # ============= RELAT√ìRIO RESUMO =============
            print(f"\nüìã {colored('Gerando relat√≥rio resumo...', 'blue')}")
            
            marca_rpm = df.groupby('marca')['rpm'].mean().sort_values()
            
            resumo = {
                'data_analise': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'total_registros': len(df),
                'total_unidades': df['unidade_id'].nunique(),
                'total_empresas': df['empresa'].nunique(),
                'total_marcas': df['marca'].nunique(),
                'total_modelos': df['modelo'].nunique(),
                'periodo_dados': f"{df['datetime'].min()} at√© {df['datetime'].max()}",
                'rpm_medio_geral': round(df['rpm'].mean(), 2),
                'rpm_desvio_padrao': round(df['rpm'].std(), 2),
                'velocidade_media_geral': round(df['velocidade'].mean(), 2),
                'altitude_media_geral': round(df['altitude'].mean(), 2),
                'outliers_detectados': len(all_outliers),
                'percentual_outliers': round(len(all_outliers) / len(df) * 100, 2),
                'distribuicao_faixas_rpm': dict(df['faixa_rpm'].value_counts()),
                'marca_mais_eficiente': marca_rpm.index[0] if len(marca_rpm) > 0 else 'N/A',
                'marca_menos_eficiente': marca_rpm.index[-1] if len(marca_rpm) > 0 else 'N/A',
                'padroes_identificados': len(padroes_especificos),
                'unidades_fora_padrao_total': len(desvios_detalhados),
                'marcas_analisadas_dispersao': len(desvios_por_marca),
            }
            
            # Salvar resumo
            resumo_df = pd.DataFrame([resumo]).T
            resumo_df.columns = ['Valor']
            resumo_df.to_excel(f'{deposito}/estudo_02_resumo_executivo.xlsx')
            
            # ============= RESULTADO FINAL =============
            print(colored("="*50, 'cyan'))
            print(colored("ESTUDO ESTAT√çSTICO AVAN√áADO CONCLU√çDO COM SUCESSO!", 'green'))
            print(colored("="*50, 'cyan'))
            
            print(f"üìä {colored('RESUMO DOS RESULTADOS:', 'yellow')}")
            print(f"   ‚Ä¢ Total de registros analisados: {colored(f'{len(df):,}', 'green')}")
            print(f"   ‚Ä¢ Unidades analisadas: {colored(df['unidade_id'].nunique(), 'green')}")
            print(f"   ‚Ä¢ Empresas envolvidas: {colored(df['empresa'].nunique(), 'green')}")
            print(f"   ‚Ä¢ Marcas analisadas: {colored(df['marca'].nunique(), 'blue')}")
            print(f"   ‚Ä¢ Modelos analisados: {colored(df['modelo'].nunique(), 'blue')}")
            print(f"   ‚Ä¢ Outliers detectados: {colored(f'{len(all_outliers):,}', 'red')} ({colored(f'{len(all_outliers)/len(df)*100:.1f}%', 'red')})")
            print(f"   ‚Ä¢ RPM m√©dio da frota: {colored(f'{df.rpm.mean():.0f}', 'blue')} RPM")
            print(f"   ‚Ä¢ Velocidade m√©dia: {colored(f'{df.velocidade.mean():.1f}', 'blue')} km/h")
            
            print(f"\nüè≠ {colored('AN√ÅLISE POR MARCA:', 'yellow')}")
            if len(marca_rpm) > 0:
                print(f"   ‚Ä¢ Marca mais eficiente: {colored(marca_rpm.index[0], 'green')} ({colored(f'{marca_rpm.iloc[0]:.0f}', 'green')} RPM)")
                print(f"   ‚Ä¢ Marca menos eficiente: {colored(marca_rpm.index[-1], 'red')} ({colored(f'{marca_rpm.iloc[-1]:.0f}', 'red')} RPM)")
            
            print(f"\nüéØ {colored('AN√ÅLISE DE DISPERS√ÉO:', 'yellow')}")
            print(f"   ‚Ä¢ Unidades fora do padr√£o: {colored(len(desvios_detalhados), 'red')}")
            print(f"   ‚Ä¢ Marcas com an√°lise de dispers√£o: {colored(len(desvios_por_marca), 'blue')}")
            
            if desvios_por_marca:
                marca_mais_problemas = max(desvios_por_marca, key=lambda x: desvios_por_marca[x]['percentual_fora_padrao'])
                print(f"   ‚Ä¢ Marca com mais unidades fora do padr√£o: {colored(marca_mais_problemas, 'red')} ({colored(f'{desvios_por_marca[marca_mais_problemas]['percentual_fora_padrao']:.1f}%', 'red')})")
            
            print(f"\nüìÅ {colored('ARQUIVOS GERADOS:', 'yellow')}")
            print(f"   ‚Ä¢ estudo_02_estatisticas_descritivas.xlsx")
            print(f"   ‚Ä¢ estudo_02_outliers_detectados.xlsx") 
            print(f"   ‚Ä¢ estudo_02_analise_por_unidade.xlsx")
            print(f"   ‚Ä¢ estudo_02_analise_por_marca.xlsx")
            print(f"   ‚Ä¢ estudo_02_analise_por_modelo.xlsx")
            print(f"   ‚Ä¢ estudo_02_comparativo_marcas.xlsx")
            print(f"   ‚Ä¢ estudo_02_unidades_fora_padrao.xlsx")
            print(f"   ‚Ä¢ estudo_02_dispersao_por_modelo.xlsx")
            print(f"   ‚Ä¢ estudo_02_analise_temporal.xlsx")
            print(f"   ‚Ä¢ estudo_02_matriz_correlacao.xlsx")
            print(f"   ‚Ä¢ estudo_02_analise_clusters.xlsx")
            print(f"   ‚Ä¢ estudo_02_padroes_especificos.xlsx")
            print(f"   ‚Ä¢ estudo_02_resumo_executivo.xlsx")
            print(f"   ‚Ä¢ estudo_02_distribuicoes.png")
            print(f"   ‚Ä¢ estudo_02_dispersao_rpm_marcas.png")
            print(f"   ‚Ä¢ estudo_02_unidades_fora_padrao_graficos.png")
            print(f"   ‚Ä¢ estudo_02_analise_temporal.png")
            print(f"   ‚Ä¢ estudo_02_correlacoes.png")
            
            print(f"\nüéØ {colored('PRINCIPAIS INSIGHTS:', 'yellow')}")
            print(f"   ‚Ä¢ Faixa de RPM mais comum: {colored(df['faixa_rpm'].mode().iloc[0], 'green')}")
            print(f"   ‚Ä¢ Hor√°rio de maior atividade: {colored(f'{hourly_rpm.idxmax()}h', 'green')}")
            print(f"   ‚Ä¢ Correla√ß√£o RPM-Velocidade: {colored(f'{df.rpm.corr(df.velocidade):.3f}', 'blue')}")
            if len(marca_rpm) > 1:
                print(f"   ‚Ä¢ Diferen√ßa de efici√™ncia entre marcas: {colored(f'{marca_rpm.iloc[-1] - marca_rpm.iloc[0]:.0f}', 'yellow')} RPM")
            
            return True
            
        except Exception as e:
            print(f"‚ùå {colored(f'Erro durante a an√°lise: {str(e)}', 'red')}")
            import traceback
            traceback.print_exc()
            return False


    ############################################################################################
    ###+---------------------------------------------------------------------------------------------+
    # DEMOLI√á√ÉO #
    def CLTDR_UMBRELLA(self):
        def comm(msg):
            print(colored("="*30, "blue"))
            print(colored("CLTDR_UMBRELLA:","green"))
            print(f"{msg}")
            print(colored("="*30, "blue"))
        
        comm("Iniciando processamento global...")
        sid = Wialon.authenticate_with_wialon(WIALON_TOKEN_UMBR)
        if not sid:
                self.stdout.write(self.style.ERROR('Falha ao iniciar sess√£o Wialon.'))
                return

        #Wialon.set_locale()

        ###__UNIDADES__TODAS__###
        comm("Processando Unidades...")
        processamento_df = pd.DataFrame()

        ###


        ###__CARGO__POLO__###
        # VE√çCULOS
        self.CARGO_POLO_veiculos(sid, processamento_df)
        processamento_df = pd.DataFrame()

        #motoristas
        self.CARGO_POLO_motoristas(sid, processamento_df)
        processamento_df = pd.DataFrame()

        self.CARGO_POLO(sid)

        ###__PLACIDO__###
        # VE√çCULOS
        self.PLACIDO_veiculos(sid, processamento_df)
        processamento_df = pd.DataFrame()

        #Motoristas
        self.PLACIDO_motoristas(sid, processamento_df)
        processamento_df = pd.DataFrame()

        ###__SFRESGATE__###
        # VE√çCULOS
        self.SFRESGATE_veiculos(sid, processamento_df)
        processamento_df = pd.DataFrame()
        
        #motoristas 
        self.SFRESGATE_motoristas(sid, processamento_df)
        processamento_df = pd.DataFrame()

        ###__checkpoints e infra√ß√µes__###
        self.CLTDR_CP_01(sid, processamento_df, recurso=401755650, template=1, flag=16777218, Objeto=401946382, dias=30)
        processamento_df = pd.DataFrame()   

        self.CLTDR_INFRA_01(sid, processamento_df, recurso=401872803, template=7, flag=16777218, Objeto=401929585, dias=30)
        processamento_df = pd.DataFrame()

        Wialon.wialon_logout(sid)

    def SFRESGATE_motoristas(self, sid, processamento_df):
        self.CLTDR_MOT_02(sid, processamento_df, recurso=401872803, template=48, Objeto=401872803, flag=16777218, dias=1, periodo="Ontem")
        self.CLTDR_MOT_02(sid, processamento_df, recurso=401872803, template=48, Objeto=401872803, flag=16777220, dias=1, periodo="√öltimos 7 dias")
        self.CLTDR_MOT_02(sid, processamento_df, recurso=401872803, template=48, Objeto=401872803, flag=16777224, dias=1, periodo="√öltimos 30 dias")

    def SFRESGATE_veiculos(self, sid, processamento_df):
        self.CLTDR_03(sid, processamento_df, recurso=401756219, template=59, flag=16777218, Objeto=frt_sfre, dias=1, periodo="Ontem")
        self.CLTDR_03(sid, processamento_df, recurso=401756219, template=59, flag=16777218, Objeto=frt_sfre, dias=7, periodo="√öltimos 7 dias")
        self.CLTDR_03(sid, processamento_df, recurso=401756219, template=59, flag=16777218, Objeto=frt_sfre, dias=30, periodo="√öltimos 30 dias")

    def PLACIDO_motoristas(self, sid, processamento_df):
        self.CLTDR_MOT_02(sid, processamento_df, recurso=401768999, template=48, Objeto=401768999, flag=16777218, dias=1, periodo="Ontem")
        self.CLTDR_MOT_02(sid, processamento_df, recurso=401768999, template=48, Objeto=401768999, flag=16777220, dias=1, periodo="√öltimos 7 dias")
        self.CLTDR_MOT_02(sid, processamento_df, recurso=401768999, template=48, Objeto=401768999, flag=16777224, dias=1, periodo="√öltimos 30 dias")

    def PLACIDO_veiculos(self, sid, processamento_df):
        self.CLTDR_03(sid, processamento_df, recurso=401756219, template=59, flag=16777218, Objeto=frt_plac, dias=1, periodo="Ontem")
        self.CLTDR_03(sid, processamento_df, recurso=401756219, template=59, flag=16777218, Objeto=frt_plac, dias=7, periodo="√öltimos 7 dias")
        self.CLTDR_03(sid, processamento_df, recurso=401756219, template=59, flag=16777218, Objeto=frt_plac, dias=30, periodo="√öltimos 30 dias")

    def CARGO_POLO_motoristas(self, sid, processamento_df):
        self.CLTDR_MOT_01(sid, processamento_df, Objeto=401756219, flag=16777218, dias=1, periodo="Ontem")
        self.CLTDR_MOT_01(sid, processamento_df, Objeto=401756219, flag=16777220, dias=1, periodo="√öltimos 7 dias")
        self.CLTDR_MOT_01(sid, processamento_df, Objeto=401756219, flag=16777224, dias=1, periodo="√öltimos 30 dias")

    def CARGO_POLO_veiculos(self, sid, processamento_df):
        self.CLTDR_04(sid, processamento_df, recurso=401756219, template=9, flag=16777218, Objeto=frt_cpbr, dias=1, periodo="Ontem")
        self.CLTDR_04(sid, processamento_df, recurso=401756219, template=9, flag=16777218, Objeto=frt_cpbr, dias=7, periodo="√öltimos 7 dias")
        self.CLTDR_04(sid, processamento_df, recurso=401756219, template=9, flag=16777218, Objeto=frt_cpbr, dias=30, periodo="√öltimos 30 dias")
    # DEMOLI√á√ÉO #
    ###+---------------------------------------------------------------------------------------------+
    ############################################################################################